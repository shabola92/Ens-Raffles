/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
(self["webpackChunkdapp"] = self["webpackChunkdapp"] || []).push([["vendors-node_modules_dns-packet_index_js"],{

/***/ "./node_modules/dns-packet/classes.js":
/*!********************************************!*\
  !*** ./node_modules/dns-packet/classes.js ***!
  \********************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nexports.toString = function (klass) {\n  switch (klass) {\n    case 1: return 'IN'\n    case 2: return 'CS'\n    case 3: return 'CH'\n    case 4: return 'HS'\n    case 255: return 'ANY'\n  }\n  return 'UNKNOWN_' + klass\n}\n\nexports.toClass = function (name) {\n  switch (name.toUpperCase()) {\n    case 'IN': return 1\n    case 'CS': return 2\n    case 'CH': return 3\n    case 'HS': return 4\n    case 'ANY': return 255\n  }\n  return 0\n}\n\n\n//# sourceURL=webpack://dapp/./node_modules/dns-packet/classes.js?");

/***/ }),

/***/ "./node_modules/dns-packet/index.js":
/*!******************************************!*\
  !*** ./node_modules/dns-packet/index.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nconst Buffer = (__webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\").Buffer)\nconst types = __webpack_require__(/*! ./types */ \"./node_modules/dns-packet/types.js\")\nconst rcodes = __webpack_require__(/*! ./rcodes */ \"./node_modules/dns-packet/rcodes.js\")\nconst opcodes = __webpack_require__(/*! ./opcodes */ \"./node_modules/dns-packet/opcodes.js\")\nconst classes = __webpack_require__(/*! ./classes */ \"./node_modules/dns-packet/classes.js\")\nconst optioncodes = __webpack_require__(/*! ./optioncodes */ \"./node_modules/dns-packet/optioncodes.js\")\nconst ip = __webpack_require__(/*! @leichtgewicht/ip-codec */ \"./node_modules/@leichtgewicht/ip-codec/index.cjs\")\n\nconst QUERY_FLAG = 0\nconst RESPONSE_FLAG = 1 << 15\nconst FLUSH_MASK = 1 << 15\nconst NOT_FLUSH_MASK = ~FLUSH_MASK\nconst QU_MASK = 1 << 15\nconst NOT_QU_MASK = ~QU_MASK\n\nconst name = exports.name = {}\n\nname.encode = function (str, buf, offset) {\n  if (!buf) buf = Buffer.alloc(name.encodingLength(str))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  // strip leading and trailing .\n  const n = str.replace(/^\\.|\\.$/gm, '')\n  if (n.length) {\n    const list = n.split('.')\n\n    for (let i = 0; i < list.length; i++) {\n      const len = buf.write(list[i], offset + 1)\n      buf[offset] = len\n      offset += len + 1\n    }\n  }\n\n  buf[offset++] = 0\n\n  name.encode.bytes = offset - oldOffset\n  return buf\n}\n\nname.encode.bytes = 0\n\nname.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const list = []\n  let oldOffset = offset\n  let totalLength = 0\n  let consumedBytes = 0\n  let jumped = false\n\n  while (true) {\n    if (offset >= buf.length) {\n      throw new Error('Cannot decode name (buffer overflow)')\n    }\n    const len = buf[offset++]\n    consumedBytes += jumped ? 0 : 1\n\n    if (len === 0) {\n      break\n    } else if ((len & 0xc0) === 0) {\n      if (offset + len > buf.length) {\n        throw new Error('Cannot decode name (buffer overflow)')\n      }\n      totalLength += len + 1\n      if (totalLength > 254) {\n        throw new Error('Cannot decode name (name too long)')\n      }\n      list.push(buf.toString('utf-8', offset, offset + len))\n      offset += len\n      consumedBytes += jumped ? 0 : len\n    } else if ((len & 0xc0) === 0xc0) {\n      if (offset + 1 > buf.length) {\n        throw new Error('Cannot decode name (buffer overflow)')\n      }\n      const jumpOffset = buf.readUInt16BE(offset - 1) - 0xc000\n      if (jumpOffset >= oldOffset) {\n        // Allow only pointers to prior data. RFC 1035, section 4.1.4 states:\n        // \"[...] an entire domain name or a list of labels at the end of a domain name\n        // is replaced with a pointer to a prior occurance (sic) of the same name.\"\n        throw new Error('Cannot decode name (bad pointer)')\n      }\n      offset = jumpOffset\n      oldOffset = jumpOffset\n      consumedBytes += jumped ? 0 : 1\n      jumped = true\n    } else {\n      throw new Error('Cannot decode name (bad label)')\n    }\n  }\n\n  name.decode.bytes = consumedBytes\n  return list.length === 0 ? '.' : list.join('.')\n}\n\nname.decode.bytes = 0\n\nname.encodingLength = function (n) {\n  if (n === '.' || n === '..') return 1\n  return Buffer.byteLength(n.replace(/^\\.|\\.$/gm, '')) + 2\n}\n\nconst string = {}\n\nstring.encode = function (s, buf, offset) {\n  if (!buf) buf = Buffer.alloc(string.encodingLength(s))\n  if (!offset) offset = 0\n\n  const len = buf.write(s, offset + 1)\n  buf[offset] = len\n  string.encode.bytes = len + 1\n  return buf\n}\n\nstring.encode.bytes = 0\n\nstring.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const len = buf[offset]\n  const s = buf.toString('utf-8', offset + 1, offset + 1 + len)\n  string.decode.bytes = len + 1\n  return s\n}\n\nstring.decode.bytes = 0\n\nstring.encodingLength = function (s) {\n  return Buffer.byteLength(s) + 1\n}\n\nconst header = {}\n\nheader.encode = function (h, buf, offset) {\n  if (!buf) buf = header.encodingLength(h)\n  if (!offset) offset = 0\n\n  const flags = (h.flags || 0) & 32767\n  const type = h.type === 'response' ? RESPONSE_FLAG : QUERY_FLAG\n\n  buf.writeUInt16BE(h.id || 0, offset)\n  buf.writeUInt16BE(flags | type, offset + 2)\n  buf.writeUInt16BE(h.questions.length, offset + 4)\n  buf.writeUInt16BE(h.answers.length, offset + 6)\n  buf.writeUInt16BE(h.authorities.length, offset + 8)\n  buf.writeUInt16BE(h.additionals.length, offset + 10)\n\n  return buf\n}\n\nheader.encode.bytes = 12\n\nheader.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  if (buf.length < 12) throw new Error('Header must be 12 bytes')\n  const flags = buf.readUInt16BE(offset + 2)\n\n  return {\n    id: buf.readUInt16BE(offset),\n    type: flags & RESPONSE_FLAG ? 'response' : 'query',\n    flags: flags & 32767,\n    flag_qr: ((flags >> 15) & 0x1) === 1,\n    opcode: opcodes.toString((flags >> 11) & 0xf),\n    flag_aa: ((flags >> 10) & 0x1) === 1,\n    flag_tc: ((flags >> 9) & 0x1) === 1,\n    flag_rd: ((flags >> 8) & 0x1) === 1,\n    flag_ra: ((flags >> 7) & 0x1) === 1,\n    flag_z: ((flags >> 6) & 0x1) === 1,\n    flag_ad: ((flags >> 5) & 0x1) === 1,\n    flag_cd: ((flags >> 4) & 0x1) === 1,\n    rcode: rcodes.toString(flags & 0xf),\n    questions: new Array(buf.readUInt16BE(offset + 4)),\n    answers: new Array(buf.readUInt16BE(offset + 6)),\n    authorities: new Array(buf.readUInt16BE(offset + 8)),\n    additionals: new Array(buf.readUInt16BE(offset + 10))\n  }\n}\n\nheader.decode.bytes = 12\n\nheader.encodingLength = function () {\n  return 12\n}\n\nconst runknown = exports.unknown = {}\n\nrunknown.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.alloc(runknown.encodingLength(data))\n  if (!offset) offset = 0\n\n  buf.writeUInt16BE(data.length, offset)\n  data.copy(buf, offset + 2)\n\n  runknown.encode.bytes = data.length + 2\n  return buf\n}\n\nrunknown.encode.bytes = 0\n\nrunknown.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const len = buf.readUInt16BE(offset)\n  const data = buf.slice(offset + 2, offset + 2 + len)\n  runknown.decode.bytes = len + 2\n  return data\n}\n\nrunknown.decode.bytes = 0\n\nrunknown.encodingLength = function (data) {\n  return data.length + 2\n}\n\nconst rns = exports.ns = {}\n\nrns.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.alloc(rns.encodingLength(data))\n  if (!offset) offset = 0\n\n  name.encode(data, buf, offset + 2)\n  buf.writeUInt16BE(name.encode.bytes, offset)\n  rns.encode.bytes = name.encode.bytes + 2\n  return buf\n}\n\nrns.encode.bytes = 0\n\nrns.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const len = buf.readUInt16BE(offset)\n  const dd = name.decode(buf, offset + 2)\n\n  rns.decode.bytes = len + 2\n  return dd\n}\n\nrns.decode.bytes = 0\n\nrns.encodingLength = function (data) {\n  return name.encodingLength(data) + 2\n}\n\nconst rsoa = exports.soa = {}\n\nrsoa.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.alloc(rsoa.encodingLength(data))\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n  offset += 2\n  name.encode(data.mname, buf, offset)\n  offset += name.encode.bytes\n  name.encode(data.rname, buf, offset)\n  offset += name.encode.bytes\n  buf.writeUInt32BE(data.serial || 0, offset)\n  offset += 4\n  buf.writeUInt32BE(data.refresh || 0, offset)\n  offset += 4\n  buf.writeUInt32BE(data.retry || 0, offset)\n  offset += 4\n  buf.writeUInt32BE(data.expire || 0, offset)\n  offset += 4\n  buf.writeUInt32BE(data.minimum || 0, offset)\n  offset += 4\n\n  buf.writeUInt16BE(offset - oldOffset - 2, oldOffset)\n  rsoa.encode.bytes = offset - oldOffset\n  return buf\n}\n\nrsoa.encode.bytes = 0\n\nrsoa.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n\n  const data = {}\n  offset += 2\n  data.mname = name.decode(buf, offset)\n  offset += name.decode.bytes\n  data.rname = name.decode(buf, offset)\n  offset += name.decode.bytes\n  data.serial = buf.readUInt32BE(offset)\n  offset += 4\n  data.refresh = buf.readUInt32BE(offset)\n  offset += 4\n  data.retry = buf.readUInt32BE(offset)\n  offset += 4\n  data.expire = buf.readUInt32BE(offset)\n  offset += 4\n  data.minimum = buf.readUInt32BE(offset)\n  offset += 4\n\n  rsoa.decode.bytes = offset - oldOffset\n  return data\n}\n\nrsoa.decode.bytes = 0\n\nrsoa.encodingLength = function (data) {\n  return 22 + name.encodingLength(data.mname) + name.encodingLength(data.rname)\n}\n\nconst rtxt = exports.txt = {}\n\nrtxt.encode = function (data, buf, offset) {\n  if (!Array.isArray(data)) data = [data]\n  for (let i = 0; i < data.length; i++) {\n    if (typeof data[i] === 'string') {\n      data[i] = Buffer.from(data[i])\n    }\n    if (!Buffer.isBuffer(data[i])) {\n      throw new Error('Must be a Buffer')\n    }\n  }\n\n  if (!buf) buf = Buffer.alloc(rtxt.encodingLength(data))\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n  offset += 2\n\n  data.forEach(function (d) {\n    buf[offset++] = d.length\n    d.copy(buf, offset, 0, d.length)\n    offset += d.length\n  })\n\n  buf.writeUInt16BE(offset - oldOffset - 2, oldOffset)\n  rtxt.encode.bytes = offset - oldOffset\n  return buf\n}\n\nrtxt.encode.bytes = 0\n\nrtxt.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n  let remaining = buf.readUInt16BE(offset)\n  offset += 2\n\n  let data = []\n  while (remaining > 0) {\n    const len = buf[offset++]\n    --remaining\n    if (remaining < len) {\n      throw new Error('Buffer overflow')\n    }\n    data.push(buf.slice(offset, offset + len))\n    offset += len\n    remaining -= len\n  }\n\n  rtxt.decode.bytes = offset - oldOffset\n  return data\n}\n\nrtxt.decode.bytes = 0\n\nrtxt.encodingLength = function (data) {\n  if (!Array.isArray(data)) data = [data]\n  let length = 2\n  data.forEach(function (buf) {\n    if (typeof buf === 'string') {\n      length += Buffer.byteLength(buf) + 1\n    } else {\n      length += buf.length + 1\n    }\n  })\n  return length\n}\n\nconst rnull = exports[\"null\"] = {}\n\nrnull.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.alloc(rnull.encodingLength(data))\n  if (!offset) offset = 0\n\n  if (typeof data === 'string') data = Buffer.from(data)\n  if (!data) data = Buffer.alloc(0)\n\n  const oldOffset = offset\n  offset += 2\n\n  const len = data.length\n  data.copy(buf, offset, 0, len)\n  offset += len\n\n  buf.writeUInt16BE(offset - oldOffset - 2, oldOffset)\n  rnull.encode.bytes = offset - oldOffset\n  return buf\n}\n\nrnull.encode.bytes = 0\n\nrnull.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n  const len = buf.readUInt16BE(offset)\n\n  offset += 2\n\n  const data = buf.slice(offset, offset + len)\n  offset += len\n\n  rnull.decode.bytes = offset - oldOffset\n  return data\n}\n\nrnull.decode.bytes = 0\n\nrnull.encodingLength = function (data) {\n  if (!data) return 2\n  return (Buffer.isBuffer(data) ? data.length : Buffer.byteLength(data)) + 2\n}\n\nconst rhinfo = exports.hinfo = {}\n\nrhinfo.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.alloc(rhinfo.encodingLength(data))\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n  offset += 2\n  string.encode(data.cpu, buf, offset)\n  offset += string.encode.bytes\n  string.encode(data.os, buf, offset)\n  offset += string.encode.bytes\n  buf.writeUInt16BE(offset - oldOffset - 2, oldOffset)\n  rhinfo.encode.bytes = offset - oldOffset\n  return buf\n}\n\nrhinfo.encode.bytes = 0\n\nrhinfo.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n\n  const data = {}\n  offset += 2\n  data.cpu = string.decode(buf, offset)\n  offset += string.decode.bytes\n  data.os = string.decode(buf, offset)\n  offset += string.decode.bytes\n  rhinfo.decode.bytes = offset - oldOffset\n  return data\n}\n\nrhinfo.decode.bytes = 0\n\nrhinfo.encodingLength = function (data) {\n  return string.encodingLength(data.cpu) + string.encodingLength(data.os) + 2\n}\n\nconst rptr = exports.ptr = {}\nconst rcname = exports.cname = rptr\nconst rdname = exports.dname = rptr\n\nrptr.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.alloc(rptr.encodingLength(data))\n  if (!offset) offset = 0\n\n  name.encode(data, buf, offset + 2)\n  buf.writeUInt16BE(name.encode.bytes, offset)\n  rptr.encode.bytes = name.encode.bytes + 2\n  return buf\n}\n\nrptr.encode.bytes = 0\n\nrptr.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const data = name.decode(buf, offset + 2)\n  rptr.decode.bytes = name.decode.bytes + 2\n  return data\n}\n\nrptr.decode.bytes = 0\n\nrptr.encodingLength = function (data) {\n  return name.encodingLength(data) + 2\n}\n\nconst rsrv = exports.srv = {}\n\nrsrv.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.alloc(rsrv.encodingLength(data))\n  if (!offset) offset = 0\n\n  buf.writeUInt16BE(data.priority || 0, offset + 2)\n  buf.writeUInt16BE(data.weight || 0, offset + 4)\n  buf.writeUInt16BE(data.port || 0, offset + 6)\n  name.encode(data.target, buf, offset + 8)\n\n  const len = name.encode.bytes + 6\n  buf.writeUInt16BE(len, offset)\n\n  rsrv.encode.bytes = len + 2\n  return buf\n}\n\nrsrv.encode.bytes = 0\n\nrsrv.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const len = buf.readUInt16BE(offset)\n\n  const data = {}\n  data.priority = buf.readUInt16BE(offset + 2)\n  data.weight = buf.readUInt16BE(offset + 4)\n  data.port = buf.readUInt16BE(offset + 6)\n  data.target = name.decode(buf, offset + 8)\n\n  rsrv.decode.bytes = len + 2\n  return data\n}\n\nrsrv.decode.bytes = 0\n\nrsrv.encodingLength = function (data) {\n  return 8 + name.encodingLength(data.target)\n}\n\nconst rcaa = exports.caa = {}\n\nrcaa.ISSUER_CRITICAL = 1 << 7\n\nrcaa.encode = function (data, buf, offset) {\n  const len = rcaa.encodingLength(data)\n\n  if (!buf) buf = Buffer.alloc(rcaa.encodingLength(data))\n  if (!offset) offset = 0\n\n  if (data.issuerCritical) {\n    data.flags = rcaa.ISSUER_CRITICAL\n  }\n\n  buf.writeUInt16BE(len - 2, offset)\n  offset += 2\n  buf.writeUInt8(data.flags || 0, offset)\n  offset += 1\n  string.encode(data.tag, buf, offset)\n  offset += string.encode.bytes\n  buf.write(data.value, offset)\n  offset += Buffer.byteLength(data.value)\n\n  rcaa.encode.bytes = len\n  return buf\n}\n\nrcaa.encode.bytes = 0\n\nrcaa.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const len = buf.readUInt16BE(offset)\n  offset += 2\n\n  const oldOffset = offset\n  const data = {}\n  data.flags = buf.readUInt8(offset)\n  offset += 1\n  data.tag = string.decode(buf, offset)\n  offset += string.decode.bytes\n  data.value = buf.toString('utf-8', offset, oldOffset + len)\n\n  data.issuerCritical = !!(data.flags & rcaa.ISSUER_CRITICAL)\n\n  rcaa.decode.bytes = len + 2\n\n  return data\n}\n\nrcaa.decode.bytes = 0\n\nrcaa.encodingLength = function (data) {\n  return string.encodingLength(data.tag) + string.encodingLength(data.value) + 2\n}\n\nconst rmx = exports.mx = {}\n\nrmx.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.alloc(rmx.encodingLength(data))\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n  offset += 2\n  buf.writeUInt16BE(data.preference || 0, offset)\n  offset += 2\n  name.encode(data.exchange, buf, offset)\n  offset += name.encode.bytes\n\n  buf.writeUInt16BE(offset - oldOffset - 2, oldOffset)\n  rmx.encode.bytes = offset - oldOffset\n  return buf\n}\n\nrmx.encode.bytes = 0\n\nrmx.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n\n  const data = {}\n  offset += 2\n  data.preference = buf.readUInt16BE(offset)\n  offset += 2\n  data.exchange = name.decode(buf, offset)\n  offset += name.decode.bytes\n\n  rmx.decode.bytes = offset - oldOffset\n  return data\n}\n\nrmx.encodingLength = function (data) {\n  return 4 + name.encodingLength(data.exchange)\n}\n\nconst ra = exports.a = {}\n\nra.encode = function (host, buf, offset) {\n  if (!buf) buf = Buffer.alloc(ra.encodingLength(host))\n  if (!offset) offset = 0\n\n  buf.writeUInt16BE(4, offset)\n  offset += 2\n  ip.v4.encode(host, buf, offset)\n  ra.encode.bytes = 6\n  return buf\n}\n\nra.encode.bytes = 0\n\nra.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  offset += 2\n  const host = ip.v4.decode(buf, offset)\n  ra.decode.bytes = 6\n  return host\n}\n\nra.decode.bytes = 0\n\nra.encodingLength = function () {\n  return 6\n}\n\nconst raaaa = exports.aaaa = {}\n\nraaaa.encode = function (host, buf, offset) {\n  if (!buf) buf = Buffer.alloc(raaaa.encodingLength(host))\n  if (!offset) offset = 0\n\n  buf.writeUInt16BE(16, offset)\n  offset += 2\n  ip.v6.encode(host, buf, offset)\n  raaaa.encode.bytes = 18\n  return buf\n}\n\nraaaa.encode.bytes = 0\n\nraaaa.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  offset += 2\n  const host = ip.v6.decode(buf, offset)\n  raaaa.decode.bytes = 18\n  return host\n}\n\nraaaa.decode.bytes = 0\n\nraaaa.encodingLength = function () {\n  return 18\n}\n\nconst roption = exports.option = {}\n\nroption.encode = function (option, buf, offset) {\n  if (!buf) buf = Buffer.alloc(roption.encodingLength(option))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const code = optioncodes.toCode(option.code)\n  buf.writeUInt16BE(code, offset)\n  offset += 2\n  if (option.data) {\n    buf.writeUInt16BE(option.data.length, offset)\n    offset += 2\n    option.data.copy(buf, offset)\n    offset += option.data.length\n  } else {\n    switch (code) {\n      // case 3: NSID.  No encode makes sense.\n      // case 5,6,7: Not implementable\n      case 8: // ECS\n        // note: do IP math before calling\n        const spl = option.sourcePrefixLength || 0\n        const fam = option.family || ip.familyOf(option.ip)\n        const ipBuf = ip.encode(option.ip, Buffer.alloc)\n        const ipLen = Math.ceil(spl / 8)\n        buf.writeUInt16BE(ipLen + 4, offset)\n        offset += 2\n        buf.writeUInt16BE(fam, offset)\n        offset += 2\n        buf.writeUInt8(spl, offset++)\n        buf.writeUInt8(option.scopePrefixLength || 0, offset++)\n\n        ipBuf.copy(buf, offset, 0, ipLen)\n        offset += ipLen\n        break\n      // case 9: EXPIRE (experimental)\n      // case 10: COOKIE.  No encode makes sense.\n      case 11: // KEEP-ALIVE\n        if (option.timeout) {\n          buf.writeUInt16BE(2, offset)\n          offset += 2\n          buf.writeUInt16BE(option.timeout, offset)\n          offset += 2\n        } else {\n          buf.writeUInt16BE(0, offset)\n          offset += 2\n        }\n        break\n      case 12: // PADDING\n        const len = option.length || 0\n        buf.writeUInt16BE(len, offset)\n        offset += 2\n        buf.fill(0, offset, offset + len)\n        offset += len\n        break\n      // case 13:  CHAIN.  Experimental.\n      case 14: // KEY-TAG\n        const tagsLen = option.tags.length * 2\n        buf.writeUInt16BE(tagsLen, offset)\n        offset += 2\n        for (const tag of option.tags) {\n          buf.writeUInt16BE(tag, offset)\n          offset += 2\n        }\n        break\n      default:\n        throw new Error(`Unknown roption code: ${option.code}`)\n    }\n  }\n\n  roption.encode.bytes = offset - oldOffset\n  return buf\n}\n\nroption.encode.bytes = 0\n\nroption.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const option = {}\n  option.code = buf.readUInt16BE(offset)\n  option.type = optioncodes.toString(option.code)\n  offset += 2\n  const len = buf.readUInt16BE(offset)\n  offset += 2\n  option.data = buf.slice(offset, offset + len)\n  switch (option.code) {\n    // case 3: NSID.  No decode makes sense.\n    case 8: // ECS\n      option.family = buf.readUInt16BE(offset)\n      offset += 2\n      option.sourcePrefixLength = buf.readUInt8(offset++)\n      option.scopePrefixLength = buf.readUInt8(offset++)\n      const padded = Buffer.alloc((option.family === 1) ? 4 : 16)\n      buf.copy(padded, 0, offset, offset + len - 4)\n      option.ip = ip.decode(padded)\n      break\n    // case 12: Padding.  No decode makes sense.\n    case 11: // KEEP-ALIVE\n      if (len > 0) {\n        option.timeout = buf.readUInt16BE(offset)\n        offset += 2\n      }\n      break\n    case 14:\n      option.tags = []\n      for (let i = 0; i < len; i += 2) {\n        option.tags.push(buf.readUInt16BE(offset))\n        offset += 2\n      }\n    // don't worry about default.  caller will use data if desired\n  }\n\n  roption.decode.bytes = len + 4\n  return option\n}\n\nroption.decode.bytes = 0\n\nroption.encodingLength = function (option) {\n  if (option.data) {\n    return option.data.length + 4\n  }\n  const code = optioncodes.toCode(option.code)\n  switch (code) {\n    case 8: // ECS\n      const spl = option.sourcePrefixLength || 0\n      return Math.ceil(spl / 8) + 8\n    case 11: // KEEP-ALIVE\n      return (typeof option.timeout === 'number') ? 6 : 4\n    case 12: // PADDING\n      return option.length + 4\n    case 14: // KEY-TAG\n      return 4 + (option.tags.length * 2)\n  }\n  throw new Error(`Unknown roption code: ${option.code}`)\n}\n\nconst ropt = exports.opt = {}\n\nropt.encode = function (options, buf, offset) {\n  if (!buf) buf = Buffer.alloc(ropt.encodingLength(options))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const rdlen = encodingLengthList(options, roption)\n  buf.writeUInt16BE(rdlen, offset)\n  offset = encodeList(options, roption, buf, offset + 2)\n\n  ropt.encode.bytes = offset - oldOffset\n  return buf\n}\n\nropt.encode.bytes = 0\n\nropt.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const options = []\n  let rdlen = buf.readUInt16BE(offset)\n  offset += 2\n  let o = 0\n  while (rdlen > 0) {\n    options[o++] = roption.decode(buf, offset)\n    offset += roption.decode.bytes\n    rdlen -= roption.decode.bytes\n  }\n  ropt.decode.bytes = offset - oldOffset\n  return options\n}\n\nropt.decode.bytes = 0\n\nropt.encodingLength = function (options) {\n  return 2 + encodingLengthList(options || [], roption)\n}\n\nconst rdnskey = exports.dnskey = {}\n\nrdnskey.PROTOCOL_DNSSEC = 3\nrdnskey.ZONE_KEY = 0x80\nrdnskey.SECURE_ENTRYPOINT = 0x8000\n\nrdnskey.encode = function (key, buf, offset) {\n  if (!buf) buf = Buffer.alloc(rdnskey.encodingLength(key))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const keydata = key.key\n  if (!Buffer.isBuffer(keydata)) {\n    throw new Error('Key must be a Buffer')\n  }\n\n  offset += 2 // Leave space for length\n  buf.writeUInt16BE(key.flags, offset)\n  offset += 2\n  buf.writeUInt8(rdnskey.PROTOCOL_DNSSEC, offset)\n  offset += 1\n  buf.writeUInt8(key.algorithm, offset)\n  offset += 1\n  keydata.copy(buf, offset, 0, keydata.length)\n  offset += keydata.length\n\n  rdnskey.encode.bytes = offset - oldOffset\n  buf.writeUInt16BE(rdnskey.encode.bytes - 2, oldOffset)\n  return buf\n}\n\nrdnskey.encode.bytes = 0\n\nrdnskey.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  var key = {}\n  var length = buf.readUInt16BE(offset)\n  offset += 2\n  key.flags = buf.readUInt16BE(offset)\n  offset += 2\n  if (buf.readUInt8(offset) !== rdnskey.PROTOCOL_DNSSEC) {\n    throw new Error('Protocol must be 3')\n  }\n  offset += 1\n  key.algorithm = buf.readUInt8(offset)\n  offset += 1\n  key.key = buf.slice(offset, oldOffset + length + 2)\n  offset += key.key.length\n  rdnskey.decode.bytes = offset - oldOffset\n  return key\n}\n\nrdnskey.decode.bytes = 0\n\nrdnskey.encodingLength = function (key) {\n  return 6 + Buffer.byteLength(key.key)\n}\n\nconst rrrsig = exports.rrsig = {}\n\nrrrsig.encode = function (sig, buf, offset) {\n  if (!buf) buf = Buffer.alloc(rrrsig.encodingLength(sig))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const signature = sig.signature\n  if (!Buffer.isBuffer(signature)) {\n    throw new Error('Signature must be a Buffer')\n  }\n\n  offset += 2 // Leave space for length\n  buf.writeUInt16BE(types.toType(sig.typeCovered), offset)\n  offset += 2\n  buf.writeUInt8(sig.algorithm, offset)\n  offset += 1\n  buf.writeUInt8(sig.labels, offset)\n  offset += 1\n  buf.writeUInt32BE(sig.originalTTL, offset)\n  offset += 4\n  buf.writeUInt32BE(sig.expiration, offset)\n  offset += 4\n  buf.writeUInt32BE(sig.inception, offset)\n  offset += 4\n  buf.writeUInt16BE(sig.keyTag, offset)\n  offset += 2\n  name.encode(sig.signersName, buf, offset)\n  offset += name.encode.bytes\n  signature.copy(buf, offset, 0, signature.length)\n  offset += signature.length\n\n  rrrsig.encode.bytes = offset - oldOffset\n  buf.writeUInt16BE(rrrsig.encode.bytes - 2, oldOffset)\n  return buf\n}\n\nrrrsig.encode.bytes = 0\n\nrrrsig.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  var sig = {}\n  var length = buf.readUInt16BE(offset)\n  offset += 2\n  sig.typeCovered = types.toString(buf.readUInt16BE(offset))\n  offset += 2\n  sig.algorithm = buf.readUInt8(offset)\n  offset += 1\n  sig.labels = buf.readUInt8(offset)\n  offset += 1\n  sig.originalTTL = buf.readUInt32BE(offset)\n  offset += 4\n  sig.expiration = buf.readUInt32BE(offset)\n  offset += 4\n  sig.inception = buf.readUInt32BE(offset)\n  offset += 4\n  sig.keyTag = buf.readUInt16BE(offset)\n  offset += 2\n  sig.signersName = name.decode(buf, offset)\n  offset += name.decode.bytes\n  sig.signature = buf.slice(offset, oldOffset + length + 2)\n  offset += sig.signature.length\n  rrrsig.decode.bytes = offset - oldOffset\n  return sig\n}\n\nrrrsig.decode.bytes = 0\n\nrrrsig.encodingLength = function (sig) {\n  return 20 +\n    name.encodingLength(sig.signersName) +\n    Buffer.byteLength(sig.signature)\n}\n\nconst rrp = exports.rp = {}\n\nrrp.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.alloc(rrp.encodingLength(data))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  offset += 2 // Leave space for length\n  name.encode(data.mbox || '.', buf, offset)\n  offset += name.encode.bytes\n  name.encode(data.txt || '.', buf, offset)\n  offset += name.encode.bytes\n  rrp.encode.bytes = offset - oldOffset\n  buf.writeUInt16BE(rrp.encode.bytes - 2, oldOffset)\n  return buf\n}\n\nrrp.encode.bytes = 0\n\nrrp.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const data = {}\n  offset += 2\n  data.mbox = name.decode(buf, offset) || '.'\n  offset += name.decode.bytes\n  data.txt = name.decode(buf, offset) || '.'\n  offset += name.decode.bytes\n  rrp.decode.bytes = offset - oldOffset\n  return data\n}\n\nrrp.decode.bytes = 0\n\nrrp.encodingLength = function (data) {\n  return 2 + name.encodingLength(data.mbox || '.') + name.encodingLength(data.txt || '.')\n}\n\nconst typebitmap = {}\n\ntypebitmap.encode = function (typelist, buf, offset) {\n  if (!buf) buf = Buffer.alloc(typebitmap.encodingLength(typelist))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  var typesByWindow = []\n  for (var i = 0; i < typelist.length; i++) {\n    var typeid = types.toType(typelist[i])\n    if (typesByWindow[typeid >> 8] === undefined) {\n      typesByWindow[typeid >> 8] = []\n    }\n    typesByWindow[typeid >> 8][(typeid >> 3) & 0x1F] |= 1 << (7 - (typeid & 0x7))\n  }\n\n  for (i = 0; i < typesByWindow.length; i++) {\n    if (typesByWindow[i] !== undefined) {\n      var windowBuf = Buffer.from(typesByWindow[i])\n      buf.writeUInt8(i, offset)\n      offset += 1\n      buf.writeUInt8(windowBuf.length, offset)\n      offset += 1\n      windowBuf.copy(buf, offset)\n      offset += windowBuf.length\n    }\n  }\n\n  typebitmap.encode.bytes = offset - oldOffset\n  return buf\n}\n\ntypebitmap.encode.bytes = 0\n\ntypebitmap.decode = function (buf, offset, length) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  var typelist = []\n  while (offset - oldOffset < length) {\n    var window = buf.readUInt8(offset)\n    offset += 1\n    var windowLength = buf.readUInt8(offset)\n    offset += 1\n    for (var i = 0; i < windowLength; i++) {\n      var b = buf.readUInt8(offset + i)\n      for (var j = 0; j < 8; j++) {\n        if (b & (1 << (7 - j))) {\n          var typeid = types.toString((window << 8) | (i << 3) | j)\n          typelist.push(typeid)\n        }\n      }\n    }\n    offset += windowLength\n  }\n\n  typebitmap.decode.bytes = offset - oldOffset\n  return typelist\n}\n\ntypebitmap.decode.bytes = 0\n\ntypebitmap.encodingLength = function (typelist) {\n  var extents = []\n  for (var i = 0; i < typelist.length; i++) {\n    var typeid = types.toType(typelist[i])\n    extents[typeid >> 8] = Math.max(extents[typeid >> 8] || 0, typeid & 0xFF)\n  }\n\n  var len = 0\n  for (i = 0; i < extents.length; i++) {\n    if (extents[i] !== undefined) {\n      len += 2 + Math.ceil((extents[i] + 1) / 8)\n    }\n  }\n\n  return len\n}\n\nconst rnsec = exports.nsec = {}\n\nrnsec.encode = function (record, buf, offset) {\n  if (!buf) buf = Buffer.alloc(rnsec.encodingLength(record))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  offset += 2 // Leave space for length\n  name.encode(record.nextDomain, buf, offset)\n  offset += name.encode.bytes\n  typebitmap.encode(record.rrtypes, buf, offset)\n  offset += typebitmap.encode.bytes\n\n  rnsec.encode.bytes = offset - oldOffset\n  buf.writeUInt16BE(rnsec.encode.bytes - 2, oldOffset)\n  return buf\n}\n\nrnsec.encode.bytes = 0\n\nrnsec.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  var record = {}\n  var length = buf.readUInt16BE(offset)\n  offset += 2\n  record.nextDomain = name.decode(buf, offset)\n  offset += name.decode.bytes\n  record.rrtypes = typebitmap.decode(buf, offset, length - (offset - oldOffset))\n  offset += typebitmap.decode.bytes\n\n  rnsec.decode.bytes = offset - oldOffset\n  return record\n}\n\nrnsec.decode.bytes = 0\n\nrnsec.encodingLength = function (record) {\n  return 2 +\n    name.encodingLength(record.nextDomain) +\n    typebitmap.encodingLength(record.rrtypes)\n}\n\nconst rnsec3 = exports.nsec3 = {}\n\nrnsec3.encode = function (record, buf, offset) {\n  if (!buf) buf = Buffer.alloc(rnsec3.encodingLength(record))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const salt = record.salt\n  if (!Buffer.isBuffer(salt)) {\n    throw new Error('salt must be a Buffer')\n  }\n\n  const nextDomain = record.nextDomain\n  if (!Buffer.isBuffer(nextDomain)) {\n    throw new Error('nextDomain must be a Buffer')\n  }\n\n  offset += 2 // Leave space for length\n  buf.writeUInt8(record.algorithm, offset)\n  offset += 1\n  buf.writeUInt8(record.flags, offset)\n  offset += 1\n  buf.writeUInt16BE(record.iterations, offset)\n  offset += 2\n  buf.writeUInt8(salt.length, offset)\n  offset += 1\n  salt.copy(buf, offset, 0, salt.length)\n  offset += salt.length\n  buf.writeUInt8(nextDomain.length, offset)\n  offset += 1\n  nextDomain.copy(buf, offset, 0, nextDomain.length)\n  offset += nextDomain.length\n  typebitmap.encode(record.rrtypes, buf, offset)\n  offset += typebitmap.encode.bytes\n\n  rnsec3.encode.bytes = offset - oldOffset\n  buf.writeUInt16BE(rnsec3.encode.bytes - 2, oldOffset)\n  return buf\n}\n\nrnsec3.encode.bytes = 0\n\nrnsec3.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  var record = {}\n  var length = buf.readUInt16BE(offset)\n  offset += 2\n  record.algorithm = buf.readUInt8(offset)\n  offset += 1\n  record.flags = buf.readUInt8(offset)\n  offset += 1\n  record.iterations = buf.readUInt16BE(offset)\n  offset += 2\n  const saltLength = buf.readUInt8(offset)\n  offset += 1\n  record.salt = buf.slice(offset, offset + saltLength)\n  offset += saltLength\n  const hashLength = buf.readUInt8(offset)\n  offset += 1\n  record.nextDomain = buf.slice(offset, offset + hashLength)\n  offset += hashLength\n  record.rrtypes = typebitmap.decode(buf, offset, length - (offset - oldOffset))\n  offset += typebitmap.decode.bytes\n\n  rnsec3.decode.bytes = offset - oldOffset\n  return record\n}\n\nrnsec3.decode.bytes = 0\n\nrnsec3.encodingLength = function (record) {\n  return 8 +\n    record.salt.length +\n    record.nextDomain.length +\n    typebitmap.encodingLength(record.rrtypes)\n}\n\nconst rds = exports.ds = {}\n\nrds.encode = function (digest, buf, offset) {\n  if (!buf) buf = Buffer.alloc(rds.encodingLength(digest))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const digestdata = digest.digest\n  if (!Buffer.isBuffer(digestdata)) {\n    throw new Error('Digest must be a Buffer')\n  }\n\n  offset += 2 // Leave space for length\n  buf.writeUInt16BE(digest.keyTag, offset)\n  offset += 2\n  buf.writeUInt8(digest.algorithm, offset)\n  offset += 1\n  buf.writeUInt8(digest.digestType, offset)\n  offset += 1\n  digestdata.copy(buf, offset, 0, digestdata.length)\n  offset += digestdata.length\n\n  rds.encode.bytes = offset - oldOffset\n  buf.writeUInt16BE(rds.encode.bytes - 2, oldOffset)\n  return buf\n}\n\nrds.encode.bytes = 0\n\nrds.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  var digest = {}\n  var length = buf.readUInt16BE(offset)\n  offset += 2\n  digest.keyTag = buf.readUInt16BE(offset)\n  offset += 2\n  digest.algorithm = buf.readUInt8(offset)\n  offset += 1\n  digest.digestType = buf.readUInt8(offset)\n  offset += 1\n  digest.digest = buf.slice(offset, oldOffset + length + 2)\n  offset += digest.digest.length\n  rds.decode.bytes = offset - oldOffset\n  return digest\n}\n\nrds.decode.bytes = 0\n\nrds.encodingLength = function (digest) {\n  return 6 + Buffer.byteLength(digest.digest)\n}\n\nconst rsshfp = exports.sshfp = {}\n\nrsshfp.getFingerprintLengthForHashType = function getFingerprintLengthForHashType (hashType) {\n  switch (hashType) {\n    case 1: return 20\n    case 2: return 32\n  }\n}\n\nrsshfp.encode = function encode (record, buf, offset) {\n  if (!buf) buf = Buffer.alloc(rsshfp.encodingLength(record))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  offset += 2 // The function call starts with the offset pointer at the RDLENGTH field, not the RDATA one\n  buf[offset] = record.algorithm\n  offset += 1\n  buf[offset] = record.hash\n  offset += 1\n\n  const fingerprintBuf = Buffer.from(record.fingerprint.toUpperCase(), 'hex')\n  if (fingerprintBuf.length !== rsshfp.getFingerprintLengthForHashType(record.hash)) {\n    throw new Error('Invalid fingerprint length')\n  }\n  fingerprintBuf.copy(buf, offset)\n  offset += fingerprintBuf.byteLength\n\n  rsshfp.encode.bytes = offset - oldOffset\n  buf.writeUInt16BE(rsshfp.encode.bytes - 2, oldOffset)\n\n  return buf\n}\n\nrsshfp.encode.bytes = 0\n\nrsshfp.decode = function decode (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const record = {}\n  offset += 2 // Account for the RDLENGTH field\n  record.algorithm = buf[offset]\n  offset += 1\n  record.hash = buf[offset]\n  offset += 1\n\n  const fingerprintLength = rsshfp.getFingerprintLengthForHashType(record.hash)\n  record.fingerprint = buf.slice(offset, offset + fingerprintLength).toString('hex').toUpperCase()\n  offset += fingerprintLength\n  rsshfp.decode.bytes = offset - oldOffset\n  return record\n}\n\nrsshfp.decode.bytes = 0\n\nrsshfp.encodingLength = function (record) {\n  return 4 + Buffer.from(record.fingerprint, 'hex').byteLength\n}\n\nconst rnaptr = exports.naptr = {}\n\nrnaptr.encode = function (data, buf, offset) {\n  if (!buf) buf = Buffer.alloc(rnaptr.encodingLength(data))\n  if (!offset) offset = 0\n  const oldOffset = offset\n  offset += 2\n  buf.writeUInt16BE(data.order || 0, offset)\n  offset += 2\n  buf.writeUInt16BE(data.preference || 0, offset)\n  offset += 2\n  string.encode(data.flags, buf, offset)\n  offset += string.encode.bytes\n  string.encode(data.services, buf, offset)\n  offset += string.encode.bytes\n  string.encode(data.regexp, buf, offset)\n  offset += string.encode.bytes\n  name.encode(data.replacement, buf, offset)\n  offset += name.encode.bytes\n  rnaptr.encode.bytes = offset - oldOffset\n  buf.writeUInt16BE(rnaptr.encode.bytes - 2, oldOffset)\n  return buf\n}\n\nrnaptr.encode.bytes = 0\n\nrnaptr.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n  const data = {}\n  offset += 2\n  data.order = buf.readUInt16BE(offset)\n  offset += 2\n  data.preference = buf.readUInt16BE(offset)\n  offset += 2\n  data.flags = string.decode(buf, offset)\n  offset += string.decode.bytes\n  data.services = string.decode(buf, offset)\n  offset += string.decode.bytes\n  data.regexp = string.decode(buf, offset)\n  offset += string.decode.bytes\n  data.replacement = name.decode(buf, offset)\n  offset += name.decode.bytes\n  rnaptr.decode.bytes = offset - oldOffset\n  return data\n}\n\nrnaptr.decode.bytes = 0\n\nrnaptr.encodingLength = function (data) {\n  return string.encodingLength(data.flags) +\n    string.encodingLength(data.services) +\n    string.encodingLength(data.regexp) +\n    name.encodingLength(data.replacement) + 6\n}\n\nconst rtlsa = exports.tlsa = {}\n\nrtlsa.encode = function (cert, buf, offset) {\n  if (!buf) buf = Buffer.alloc(rtlsa.encodingLength(cert))\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const certdata = cert.certificate\n  if (!Buffer.isBuffer(certdata)) {\n    throw new Error('Certificate must be a Buffer')\n  }\n\n  offset += 2 // Leave space for length\n  buf.writeUInt8(cert.usage, offset)\n  offset += 1\n  buf.writeUInt8(cert.selector, offset)\n  offset += 1\n  buf.writeUInt8(cert.matchingType, offset)\n  offset += 1\n  certdata.copy(buf, offset, 0, certdata.length)\n  offset += certdata.length\n\n  rtlsa.encode.bytes = offset - oldOffset\n  buf.writeUInt16BE(rtlsa.encode.bytes - 2, oldOffset)\n  return buf\n}\n\nrtlsa.encode.bytes = 0\n\nrtlsa.decode = function (buf, offset) {\n  if (!offset) offset = 0\n  const oldOffset = offset\n\n  const cert = {}\n  const length = buf.readUInt16BE(offset)\n  offset += 2\n  cert.usage = buf.readUInt8(offset)\n  offset += 1\n  cert.selector = buf.readUInt8(offset)\n  offset += 1\n  cert.matchingType = buf.readUInt8(offset)\n  offset += 1\n  cert.certificate = buf.slice(offset, oldOffset + length + 2)\n  offset += cert.certificate.length\n  rtlsa.decode.bytes = offset - oldOffset\n  return cert\n}\n\nrtlsa.decode.bytes = 0\n\nrtlsa.encodingLength = function (cert) {\n  return 5 + Buffer.byteLength(cert.certificate)\n}\n\nconst renc = exports.record = function (type) {\n  switch (type.toUpperCase()) {\n    case 'A': return ra\n    case 'PTR': return rptr\n    case 'CNAME': return rcname\n    case 'DNAME': return rdname\n    case 'TXT': return rtxt\n    case 'NULL': return rnull\n    case 'AAAA': return raaaa\n    case 'SRV': return rsrv\n    case 'HINFO': return rhinfo\n    case 'CAA': return rcaa\n    case 'NS': return rns\n    case 'SOA': return rsoa\n    case 'MX': return rmx\n    case 'OPT': return ropt\n    case 'DNSKEY': return rdnskey\n    case 'RRSIG': return rrrsig\n    case 'RP': return rrp\n    case 'NSEC': return rnsec\n    case 'NSEC3': return rnsec3\n    case 'SSHFP': return rsshfp\n    case 'DS': return rds\n    case 'NAPTR': return rnaptr\n    case 'TLSA': return rtlsa\n  }\n  return runknown\n}\n\nconst answer = exports.answer = {}\n\nanswer.encode = function (a, buf, offset) {\n  if (!buf) buf = Buffer.alloc(answer.encodingLength(a))\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n\n  name.encode(a.name, buf, offset)\n  offset += name.encode.bytes\n\n  buf.writeUInt16BE(types.toType(a.type), offset)\n\n  if (a.type.toUpperCase() === 'OPT') {\n    if (a.name !== '.') {\n      throw new Error('OPT name must be root.')\n    }\n    buf.writeUInt16BE(a.udpPayloadSize || 4096, offset + 2)\n    buf.writeUInt8(a.extendedRcode || 0, offset + 4)\n    buf.writeUInt8(a.ednsVersion || 0, offset + 5)\n    buf.writeUInt16BE(a.flags || 0, offset + 6)\n\n    offset += 8\n    ropt.encode(a.options || [], buf, offset)\n    offset += ropt.encode.bytes\n  } else {\n    let klass = classes.toClass(a.class === undefined ? 'IN' : a.class)\n    if (a.flush) klass |= FLUSH_MASK // the 1st bit of the class is the flush bit\n    buf.writeUInt16BE(klass, offset + 2)\n    buf.writeUInt32BE(a.ttl || 0, offset + 4)\n\n    offset += 8\n    const enc = renc(a.type)\n    enc.encode(a.data, buf, offset)\n    offset += enc.encode.bytes\n  }\n\n  answer.encode.bytes = offset - oldOffset\n  return buf\n}\n\nanswer.encode.bytes = 0\n\nanswer.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const a = {}\n  const oldOffset = offset\n\n  a.name = name.decode(buf, offset)\n  offset += name.decode.bytes\n  a.type = types.toString(buf.readUInt16BE(offset))\n  if (a.type === 'OPT') {\n    a.udpPayloadSize = buf.readUInt16BE(offset + 2)\n    a.extendedRcode = buf.readUInt8(offset + 4)\n    a.ednsVersion = buf.readUInt8(offset + 5)\n    a.flags = buf.readUInt16BE(offset + 6)\n    a.flag_do = ((a.flags >> 15) & 0x1) === 1\n    a.options = ropt.decode(buf, offset + 8)\n    offset += 8 + ropt.decode.bytes\n  } else {\n    const klass = buf.readUInt16BE(offset + 2)\n    a.ttl = buf.readUInt32BE(offset + 4)\n\n    a.class = classes.toString(klass & NOT_FLUSH_MASK)\n    a.flush = !!(klass & FLUSH_MASK)\n\n    const enc = renc(a.type)\n    a.data = enc.decode(buf, offset + 8)\n    offset += 8 + enc.decode.bytes\n  }\n\n  answer.decode.bytes = offset - oldOffset\n  return a\n}\n\nanswer.decode.bytes = 0\n\nanswer.encodingLength = function (a) {\n  const data = (a.data !== null && a.data !== undefined) ? a.data : a.options\n  return name.encodingLength(a.name) + 8 + renc(a.type).encodingLength(data)\n}\n\nconst question = exports.question = {}\n\nquestion.encode = function (q, buf, offset) {\n  if (!buf) buf = Buffer.alloc(question.encodingLength(q))\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n\n  name.encode(q.name, buf, offset)\n  offset += name.encode.bytes\n\n  buf.writeUInt16BE(types.toType(q.type), offset)\n  offset += 2\n\n  buf.writeUInt16BE(classes.toClass(q.class === undefined ? 'IN' : q.class), offset)\n  offset += 2\n\n  question.encode.bytes = offset - oldOffset\n  return q\n}\n\nquestion.encode.bytes = 0\n\nquestion.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n  const q = {}\n\n  q.name = name.decode(buf, offset)\n  offset += name.decode.bytes\n\n  q.type = types.toString(buf.readUInt16BE(offset))\n  offset += 2\n\n  q.class = classes.toString(buf.readUInt16BE(offset))\n  offset += 2\n\n  const qu = !!(q.class & QU_MASK)\n  if (qu) q.class &= NOT_QU_MASK\n\n  question.decode.bytes = offset - oldOffset\n  return q\n}\n\nquestion.decode.bytes = 0\n\nquestion.encodingLength = function (q) {\n  return name.encodingLength(q.name) + 4\n}\n\nexports.AUTHORITATIVE_ANSWER = 1 << 10\nexports.TRUNCATED_RESPONSE = 1 << 9\nexports.RECURSION_DESIRED = 1 << 8\nexports.RECURSION_AVAILABLE = 1 << 7\nexports.AUTHENTIC_DATA = 1 << 5\nexports.CHECKING_DISABLED = 1 << 4\nexports.DNSSEC_OK = 1 << 15\n\nexports.encode = function (result, buf, offset) {\n  const allocing = !buf\n\n  if (allocing) buf = Buffer.alloc(exports.encodingLength(result))\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n\n  if (!result.questions) result.questions = []\n  if (!result.answers) result.answers = []\n  if (!result.authorities) result.authorities = []\n  if (!result.additionals) result.additionals = []\n\n  header.encode(result, buf, offset)\n  offset += header.encode.bytes\n\n  offset = encodeList(result.questions, question, buf, offset)\n  offset = encodeList(result.answers, answer, buf, offset)\n  offset = encodeList(result.authorities, answer, buf, offset)\n  offset = encodeList(result.additionals, answer, buf, offset)\n\n  exports.encode.bytes = offset - oldOffset\n\n  // just a quick sanity check\n  if (allocing && exports.encode.bytes !== buf.length) {\n    return buf.slice(0, exports.encode.bytes)\n  }\n\n  return buf\n}\n\nexports.encode.bytes = 0\n\nexports.decode = function (buf, offset) {\n  if (!offset) offset = 0\n\n  const oldOffset = offset\n  const result = header.decode(buf, offset)\n  offset += header.decode.bytes\n\n  offset = decodeList(result.questions, question, buf, offset)\n  offset = decodeList(result.answers, answer, buf, offset)\n  offset = decodeList(result.authorities, answer, buf, offset)\n  offset = decodeList(result.additionals, answer, buf, offset)\n\n  exports.decode.bytes = offset - oldOffset\n\n  return result\n}\n\nexports.decode.bytes = 0\n\nexports.encodingLength = function (result) {\n  return header.encodingLength(result) +\n    encodingLengthList(result.questions || [], question) +\n    encodingLengthList(result.answers || [], answer) +\n    encodingLengthList(result.authorities || [], answer) +\n    encodingLengthList(result.additionals || [], answer)\n}\n\nexports.streamEncode = function (result) {\n  const buf = exports.encode(result)\n  const sbuf = Buffer.alloc(2)\n  sbuf.writeUInt16BE(buf.byteLength)\n  const combine = Buffer.concat([sbuf, buf])\n  exports.streamEncode.bytes = combine.byteLength\n  return combine\n}\n\nexports.streamEncode.bytes = 0\n\nexports.streamDecode = function (sbuf) {\n  const len = sbuf.readUInt16BE(0)\n  if (sbuf.byteLength < len + 2) {\n    // not enough data\n    return null\n  }\n  const result = exports.decode(sbuf.slice(2))\n  exports.streamDecode.bytes = exports.decode.bytes\n  return result\n}\n\nexports.streamDecode.bytes = 0\n\nfunction encodingLengthList (list, enc) {\n  let len = 0\n  for (let i = 0; i < list.length; i++) len += enc.encodingLength(list[i])\n  return len\n}\n\nfunction encodeList (list, enc, buf, offset) {\n  for (let i = 0; i < list.length; i++) {\n    enc.encode(list[i], buf, offset)\n    offset += enc.encode.bytes\n  }\n  return offset\n}\n\nfunction decodeList (list, enc, buf, offset) {\n  for (let i = 0; i < list.length; i++) {\n    list[i] = enc.decode(buf, offset)\n    offset += enc.decode.bytes\n  }\n  return offset\n}\n\n\n//# sourceURL=webpack://dapp/./node_modules/dns-packet/index.js?");

/***/ }),

/***/ "./node_modules/dns-packet/opcodes.js":
/*!********************************************!*\
  !*** ./node_modules/dns-packet/opcodes.js ***!
  \********************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\n/*\n * Traditional DNS header OPCODEs (4-bits) defined by IANA in\n * https://www.iana.org/assignments/dns-parameters/dns-parameters.xhtml#dns-parameters-5\n */\n\nexports.toString = function (opcode) {\n  switch (opcode) {\n    case 0: return 'QUERY'\n    case 1: return 'IQUERY'\n    case 2: return 'STATUS'\n    case 3: return 'OPCODE_3'\n    case 4: return 'NOTIFY'\n    case 5: return 'UPDATE'\n    case 6: return 'OPCODE_6'\n    case 7: return 'OPCODE_7'\n    case 8: return 'OPCODE_8'\n    case 9: return 'OPCODE_9'\n    case 10: return 'OPCODE_10'\n    case 11: return 'OPCODE_11'\n    case 12: return 'OPCODE_12'\n    case 13: return 'OPCODE_13'\n    case 14: return 'OPCODE_14'\n    case 15: return 'OPCODE_15'\n  }\n  return 'OPCODE_' + opcode\n}\n\nexports.toOpcode = function (code) {\n  switch (code.toUpperCase()) {\n    case 'QUERY': return 0\n    case 'IQUERY': return 1\n    case 'STATUS': return 2\n    case 'OPCODE_3': return 3\n    case 'NOTIFY': return 4\n    case 'UPDATE': return 5\n    case 'OPCODE_6': return 6\n    case 'OPCODE_7': return 7\n    case 'OPCODE_8': return 8\n    case 'OPCODE_9': return 9\n    case 'OPCODE_10': return 10\n    case 'OPCODE_11': return 11\n    case 'OPCODE_12': return 12\n    case 'OPCODE_13': return 13\n    case 'OPCODE_14': return 14\n    case 'OPCODE_15': return 15\n  }\n  return 0\n}\n\n\n//# sourceURL=webpack://dapp/./node_modules/dns-packet/opcodes.js?");

/***/ }),

/***/ "./node_modules/dns-packet/optioncodes.js":
/*!************************************************!*\
  !*** ./node_modules/dns-packet/optioncodes.js ***!
  \************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nexports.toString = function (type) {\n  switch (type) {\n    // list at\n    // https://www.iana.org/assignments/dns-parameters/dns-parameters.xhtml#dns-parameters-11\n    case 1: return 'LLQ'\n    case 2: return 'UL'\n    case 3: return 'NSID'\n    case 5: return 'DAU'\n    case 6: return 'DHU'\n    case 7: return 'N3U'\n    case 8: return 'CLIENT_SUBNET'\n    case 9: return 'EXPIRE'\n    case 10: return 'COOKIE'\n    case 11: return 'TCP_KEEPALIVE'\n    case 12: return 'PADDING'\n    case 13: return 'CHAIN'\n    case 14: return 'KEY_TAG'\n    case 26946: return 'DEVICEID'\n  }\n  if (type < 0) {\n    return null\n  }\n  return `OPTION_${type}`\n}\n\nexports.toCode = function (name) {\n  if (typeof name === 'number') {\n    return name\n  }\n  if (!name) {\n    return -1\n  }\n  switch (name.toUpperCase()) {\n    case 'OPTION_0': return 0\n    case 'LLQ': return 1\n    case 'UL': return 2\n    case 'NSID': return 3\n    case 'OPTION_4': return 4\n    case 'DAU': return 5\n    case 'DHU': return 6\n    case 'N3U': return 7\n    case 'CLIENT_SUBNET': return 8\n    case 'EXPIRE': return 9\n    case 'COOKIE': return 10\n    case 'TCP_KEEPALIVE': return 11\n    case 'PADDING': return 12\n    case 'CHAIN': return 13\n    case 'KEY_TAG': return 14\n    case 'DEVICEID': return 26946\n    case 'OPTION_65535': return 65535\n  }\n  const m = name.match(/_(\\d+)$/)\n  if (m) {\n    return parseInt(m[1], 10)\n  }\n  return -1\n}\n\n\n//# sourceURL=webpack://dapp/./node_modules/dns-packet/optioncodes.js?");

/***/ }),

/***/ "./node_modules/dns-packet/rcodes.js":
/*!*******************************************!*\
  !*** ./node_modules/dns-packet/rcodes.js ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\n/*\n * Traditional DNS header RCODEs (4-bits) defined by IANA in\n * https://www.iana.org/assignments/dns-parameters/dns-parameters.xhtml\n */\n\nexports.toString = function (rcode) {\n  switch (rcode) {\n    case 0: return 'NOERROR'\n    case 1: return 'FORMERR'\n    case 2: return 'SERVFAIL'\n    case 3: return 'NXDOMAIN'\n    case 4: return 'NOTIMP'\n    case 5: return 'REFUSED'\n    case 6: return 'YXDOMAIN'\n    case 7: return 'YXRRSET'\n    case 8: return 'NXRRSET'\n    case 9: return 'NOTAUTH'\n    case 10: return 'NOTZONE'\n    case 11: return 'RCODE_11'\n    case 12: return 'RCODE_12'\n    case 13: return 'RCODE_13'\n    case 14: return 'RCODE_14'\n    case 15: return 'RCODE_15'\n  }\n  return 'RCODE_' + rcode\n}\n\nexports.toRcode = function (code) {\n  switch (code.toUpperCase()) {\n    case 'NOERROR': return 0\n    case 'FORMERR': return 1\n    case 'SERVFAIL': return 2\n    case 'NXDOMAIN': return 3\n    case 'NOTIMP': return 4\n    case 'REFUSED': return 5\n    case 'YXDOMAIN': return 6\n    case 'YXRRSET': return 7\n    case 'NXRRSET': return 8\n    case 'NOTAUTH': return 9\n    case 'NOTZONE': return 10\n    case 'RCODE_11': return 11\n    case 'RCODE_12': return 12\n    case 'RCODE_13': return 13\n    case 'RCODE_14': return 14\n    case 'RCODE_15': return 15\n  }\n  return 0\n}\n\n\n//# sourceURL=webpack://dapp/./node_modules/dns-packet/rcodes.js?");

/***/ }),

/***/ "./node_modules/dns-packet/types.js":
/*!******************************************!*\
  !*** ./node_modules/dns-packet/types.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nexports.toString = function (type) {\n  switch (type) {\n    case 1: return 'A'\n    case 10: return 'NULL'\n    case 28: return 'AAAA'\n    case 18: return 'AFSDB'\n    case 42: return 'APL'\n    case 257: return 'CAA'\n    case 60: return 'CDNSKEY'\n    case 59: return 'CDS'\n    case 37: return 'CERT'\n    case 5: return 'CNAME'\n    case 49: return 'DHCID'\n    case 32769: return 'DLV'\n    case 39: return 'DNAME'\n    case 48: return 'DNSKEY'\n    case 43: return 'DS'\n    case 55: return 'HIP'\n    case 13: return 'HINFO'\n    case 45: return 'IPSECKEY'\n    case 25: return 'KEY'\n    case 36: return 'KX'\n    case 29: return 'LOC'\n    case 15: return 'MX'\n    case 35: return 'NAPTR'\n    case 2: return 'NS'\n    case 47: return 'NSEC'\n    case 50: return 'NSEC3'\n    case 51: return 'NSEC3PARAM'\n    case 12: return 'PTR'\n    case 46: return 'RRSIG'\n    case 17: return 'RP'\n    case 24: return 'SIG'\n    case 6: return 'SOA'\n    case 99: return 'SPF'\n    case 33: return 'SRV'\n    case 44: return 'SSHFP'\n    case 32768: return 'TA'\n    case 249: return 'TKEY'\n    case 52: return 'TLSA'\n    case 250: return 'TSIG'\n    case 16: return 'TXT'\n    case 252: return 'AXFR'\n    case 251: return 'IXFR'\n    case 41: return 'OPT'\n    case 255: return 'ANY'\n  }\n  return 'UNKNOWN_' + type\n}\n\nexports.toType = function (name) {\n  switch (name.toUpperCase()) {\n    case 'A': return 1\n    case 'NULL': return 10\n    case 'AAAA': return 28\n    case 'AFSDB': return 18\n    case 'APL': return 42\n    case 'CAA': return 257\n    case 'CDNSKEY': return 60\n    case 'CDS': return 59\n    case 'CERT': return 37\n    case 'CNAME': return 5\n    case 'DHCID': return 49\n    case 'DLV': return 32769\n    case 'DNAME': return 39\n    case 'DNSKEY': return 48\n    case 'DS': return 43\n    case 'HIP': return 55\n    case 'HINFO': return 13\n    case 'IPSECKEY': return 45\n    case 'KEY': return 25\n    case 'KX': return 36\n    case 'LOC': return 29\n    case 'MX': return 15\n    case 'NAPTR': return 35\n    case 'NS': return 2\n    case 'NSEC': return 47\n    case 'NSEC3': return 50\n    case 'NSEC3PARAM': return 51\n    case 'PTR': return 12\n    case 'RRSIG': return 46\n    case 'RP': return 17\n    case 'SIG': return 24\n    case 'SOA': return 6\n    case 'SPF': return 99\n    case 'SRV': return 33\n    case 'SSHFP': return 44\n    case 'TA': return 32768\n    case 'TKEY': return 249\n    case 'TLSA': return 52\n    case 'TSIG': return 250\n    case 'TXT': return 16\n    case 'AXFR': return 252\n    case 'IXFR': return 251\n    case 'OPT': return 41\n    case 'ANY': return 255\n    case '*': return 255\n  }\n  if (name.toUpperCase().startsWith('UNKNOWN_')) return parseInt(name.slice(8))\n  return 0\n}\n\n\n//# sourceURL=webpack://dapp/./node_modules/dns-packet/types.js?");

/***/ }),

/***/ "./node_modules/@leichtgewicht/ip-codec/index.cjs":
/*!********************************************************!*\
  !*** ./node_modules/@leichtgewicht/ip-codec/index.cjs ***!
  \********************************************************/
/***/ ((module, exports) => {

eval("var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;// GENERATED FILE. DO NOT EDIT.\nvar ipCodec = (function(exports) {\n  \"use strict\";\n  \n  Object.defineProperty(exports, \"__esModule\", {\n    value: true\n  });\n  exports.decode = decode;\n  exports.encode = encode;\n  exports.familyOf = familyOf;\n  exports.name = void 0;\n  exports.sizeOf = sizeOf;\n  exports.v6 = exports.v4 = void 0;\n  const v4Regex = /^(\\d{1,3}\\.){3,3}\\d{1,3}$/;\n  const v4Size = 4;\n  const v6Regex = /^(::)?(((\\d{1,3}\\.){3}(\\d{1,3}){1})?([0-9a-f]){0,4}:{0,2}){1,8}(::)?$/i;\n  const v6Size = 16;\n  const v4 = {\n    name: 'v4',\n    size: v4Size,\n    isFormat: ip => v4Regex.test(ip),\n  \n    encode(ip, buff, offset) {\n      offset = ~~offset;\n      buff = buff || new Uint8Array(offset + v4Size);\n      const max = ip.length;\n      let n = 0;\n  \n      for (let i = 0; i < max;) {\n        const c = ip.charCodeAt(i++);\n  \n        if (c === 46) {\n          // \".\"\n          buff[offset++] = n;\n          n = 0;\n        } else {\n          n = n * 10 + (c - 48);\n        }\n      }\n  \n      buff[offset] = n;\n      return buff;\n    },\n  \n    decode(buff, offset) {\n      offset = ~~offset;\n      return `${buff[offset++]}.${buff[offset++]}.${buff[offset++]}.${buff[offset]}`;\n    }\n  \n  };\n  exports.v4 = v4;\n  const v6 = {\n    name: 'v6',\n    size: v6Size,\n    isFormat: ip => ip.length > 0 && v6Regex.test(ip),\n  \n    encode(ip, buff, offset) {\n      offset = ~~offset;\n      let end = offset + v6Size;\n      let fill = -1;\n      let hexN = 0;\n      let decN = 0;\n      let prevColon = true;\n      let useDec = false;\n      buff = buff || new Uint8Array(offset + v6Size); // Note: This algorithm needs to check if the offset\n      // could exceed the buffer boundaries as it supports\n      // non-standard compliant encodings that may go beyond\n      // the boundary limits. if (offset < end) checks should\n      // not be necessary...\n  \n      for (let i = 0; i < ip.length; i++) {\n        let c = ip.charCodeAt(i);\n  \n        if (c === 58) {\n          // :\n          if (prevColon) {\n            if (fill !== -1) {\n              // Not Standard! (standard doesn't allow multiple ::)\n              // We need to treat\n              if (offset < end) buff[offset] = 0;\n              if (offset < end - 1) buff[offset + 1] = 0;\n              offset += 2;\n            } else if (offset < end) {\n              // :: in the middle\n              fill = offset;\n            }\n          } else {\n            // : ends the previous number\n            if (useDec === true) {\n              // Non-standard! (ipv4 should be at end only)\n              // A ipv4 address should not be found anywhere else but at\n              // the end. This codec also support putting characters\n              // after the ipv4 address..\n              if (offset < end) buff[offset] = decN;\n              offset++;\n            } else {\n              if (offset < end) buff[offset] = hexN >> 8;\n              if (offset < end - 1) buff[offset + 1] = hexN & 0xff;\n              offset += 2;\n            }\n  \n            hexN = 0;\n            decN = 0;\n          }\n  \n          prevColon = true;\n          useDec = false;\n        } else if (c === 46) {\n          // . indicates IPV4 notation\n          if (offset < end) buff[offset] = decN;\n          offset++;\n          decN = 0;\n          hexN = 0;\n          prevColon = false;\n          useDec = true;\n        } else {\n          prevColon = false;\n  \n          if (c >= 97) {\n            c -= 87; // a-f ... 97~102 -87 => 10~15\n          } else if (c >= 65) {\n            c -= 55; // A-F ... 65~70 -55 => 10~15\n          } else {\n            c -= 48; // 0-9 ... starting from charCode 48\n  \n            decN = decN * 10 + c;\n          } // We don't know yet if its a dec or hex number\n  \n  \n          hexN = (hexN << 4) + c;\n        }\n      }\n  \n      if (prevColon === false) {\n        // Commiting last number\n        if (useDec === true) {\n          if (offset < end) buff[offset] = decN;\n          offset++;\n        } else {\n          if (offset < end) buff[offset] = hexN >> 8;\n          if (offset < end - 1) buff[offset + 1] = hexN & 0xff;\n          offset += 2;\n        }\n      } else if (fill === 0) {\n        // Not Standard! (standard doesn't allow multiple ::)\n        // This means that a : was found at the start AND end which means the\n        // end needs to be treated as 0 entry...\n        if (offset < end) buff[offset] = 0;\n        if (offset < end - 1) buff[offset + 1] = 0;\n        offset += 2;\n      } else if (fill !== -1) {\n        // Non-standard! (standard doens't allow multiple ::)\n        // Here we find that there has been a :: somewhere in the middle\n        // and the end. To treat the end with priority we need to move all\n        // written data two bytes to the right.\n        offset += 2;\n  \n        for (let i = Math.min(offset - 1, end - 1); i >= fill + 2; i--) {\n          buff[i] = buff[i - 2];\n        }\n  \n        buff[fill] = 0;\n        buff[fill + 1] = 0;\n        fill = offset;\n      }\n  \n      if (fill !== offset && fill !== -1) {\n        // Move the written numbers to the end while filling the everything\n        // \"fill\" to the bytes with zeros.\n        if (offset > end - 2) {\n          // Non Standard support, when the cursor exceeds bounds.\n          offset = end - 2;\n        }\n  \n        while (end > fill) {\n          buff[--end] = offset < end && offset > fill ? buff[--offset] : 0;\n        }\n      } else {\n        // Fill the rest with zeros\n        while (offset < end) {\n          buff[offset++] = 0;\n        }\n      }\n  \n      return buff;\n    },\n  \n    decode(buff, offset) {\n      offset = ~~offset;\n      let result = '';\n  \n      for (let i = 0; i < v6Size; i += 2) {\n        if (i !== 0) {\n          result += ':';\n        }\n  \n        result += (buff[offset + i] << 8 | buff[offset + i + 1]).toString(16);\n      }\n  \n      return result.replace(/(^|:)0(:0)*:0(:|$)/, '$1::$3').replace(/:{3,4}/, '::');\n    }\n  \n  };\n  exports.v6 = v6;\n  const name = 'ip';\n  exports.name = name;\n  \n  function sizeOf(ip) {\n    if (v4.isFormat(ip)) return v4.size;\n    if (v6.isFormat(ip)) return v6.size;\n    throw Error(`Invalid ip address: ${ip}`);\n  }\n  \n  function familyOf(string) {\n    return sizeOf(string) === v4.size ? 1 : 2;\n  }\n  \n  function encode(ip, buff, offset) {\n    offset = ~~offset;\n    const size = sizeOf(ip);\n  \n    if (typeof buff === 'function') {\n      buff = buff(offset + size);\n    }\n  \n    if (size === v4.size) {\n      return v4.encode(ip, buff, offset);\n    }\n  \n    return v6.encode(ip, buff, offset);\n  }\n  \n  function decode(buff, offset, length) {\n    offset = ~~offset;\n    length = length || buff.length - offset;\n  \n    if (length === v4.size) {\n      return v4.decode(buff, offset, length);\n    }\n  \n    if (length === v6.size) {\n      return v6.decode(buff, offset, length);\n    }\n  \n    throw Error(`Invalid buffer size needs to be ${v4.size} for v4 or ${v6.size} for v6.`);\n  }\n  return \"default\" in exports ? exports.default : exports;\n})({});\nif (true) !(__WEBPACK_AMD_DEFINE_ARRAY__ = [], __WEBPACK_AMD_DEFINE_RESULT__ = (function() { return ipCodec; }).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\nelse {}\n\n\n//# sourceURL=webpack://dapp/./node_modules/@leichtgewicht/ip-codec/index.cjs?");

/***/ })

}]);