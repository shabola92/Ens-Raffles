/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
(self["webpackChunkdapp"] = self["webpackChunkdapp"] || []).push([["vendors-node_modules_cbor_lib_cbor_js"],{

/***/ "./node_modules/cbor/lib/cbor.js":
/*!***************************************!*\
  !*** ./node_modules/cbor/lib/cbor.js ***!
  \***************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nexports.Commented = __webpack_require__(/*! ./commented */ \"./node_modules/cbor/lib/commented.js\")\nexports.Diagnose = __webpack_require__(/*! ./diagnose */ \"./node_modules/cbor/lib/diagnose.js\")\nexports.Decoder = __webpack_require__(/*! ./decoder */ \"./node_modules/cbor/lib/decoder.js\")\nexports.Encoder = __webpack_require__(/*! ./encoder */ \"./node_modules/cbor/lib/encoder.js\")\nexports.Simple = __webpack_require__(/*! ./simple */ \"./node_modules/cbor/lib/simple.js\")\nexports.Tagged = __webpack_require__(/*! ./tagged */ \"./node_modules/cbor/lib/tagged.js\")\nexports.Map = __webpack_require__(/*! ./map */ \"./node_modules/cbor/lib/map.js\")\n\n/**\n * Convenience name for {@linkcode Commented.comment}.\n */\nexports.comment = exports.Commented.comment\n\n/**\n * Convenience name for {@linkcode Decoder.decodeAll}.\n */\nexports.decodeAll = exports.Decoder.decodeAll\n\n/**\n * Convenience name for {@linkcode Decoder.decodeFirst}.\n */\nexports.decodeFirst = exports.Decoder.decodeFirst\n\n/**\n * Convenience name for {@linkcode Decoder.decodeAllSync}.\n */\nexports.decodeAllSync = exports.Decoder.decodeAllSync\n\n/**\n * Convenience name for {@linkcode Decoder.decodeFirstSync}.\n */\nexports.decodeFirstSync = exports.Decoder.decodeFirstSync\n\n/**\n * Convenience name for {@linkcode Diagnose.diagnose}.\n */\nexports.diagnose = exports.Diagnose.diagnose\n\n/**\n * Convenience name for {@linkcode Encoder.encode}.\n */\nexports.encode = exports.Encoder.encode\n\n/**\n * Convenience name for {@linkcode Encoder.encodeCanonical}.\n */\nexports.encodeCanonical = exports.Encoder.encodeCanonical\n\n/**\n * Convenience name for {@linkcode Encoder.encodeOne}.\n */\nexports.encodeOne = exports.Encoder.encodeOne\n\n/**\n * Convenience name for {@linkcode Encoder.encodeAsync}.\n */\nexports.encodeAsync = exports.Encoder.encodeAsync\n\n/**\n * Convenience name for {@linkcode Decoder.decodeFirstSync}.\n */\nexports.decode = exports.Decoder.decodeFirstSync\n\n/**\n * The codec information for\n * {@link https://github.com/Level/encoding-down encoding-down}, which is a\n * codec framework for leveldb.  CBOR is a particularly convenient format for\n * both keys and values, as it can deal with a lot of types that JSON can't\n * handle without losing type information.\n *\n * @example\n * const level = require('level')\n * const cbor = require('cbor')\n *\n * async function putget() {\n *   const db = level('./db', {\n *     keyEncoding: cbor.leveldb,\n *     valueEncoding: cbor.leveldb,\n *   })\n *\n *   await db.put({a: 1}, 9857298342094820394820394820398234092834n)\n *   const val = await db.get({a: 1})\n * }\n */\nexports.leveldb = {\n  decode: exports.Decoder.decodeFirstSync,\n  encode: exports.Encoder.encode,\n  buffer: true,\n  name: 'cbor',\n}\n\n/**\n * Reset everything that we can predict a plugin might have altered in good\n * faith.  For now that includes the default set of tags that decoding and\n * encoding will use.\n */\nexports.reset = function reset() {\n  exports.Encoder.reset()\n  exports.Tagged.reset()\n}\n\n\n//# sourceURL=webpack://dapp/./node_modules/cbor/lib/cbor.js?");

/***/ }),

/***/ "./node_modules/cbor/lib/commented.js":
/*!********************************************!*\
  !*** ./node_modules/cbor/lib/commented.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst stream = __webpack_require__(/*! stream */ \"./node_modules/stream-browserify/index.js\")\nconst utils = __webpack_require__(/*! ./utils */ \"./node_modules/cbor/lib/utils.js\")\nconst Decoder = __webpack_require__(/*! ./decoder */ \"./node_modules/cbor/lib/decoder.js\")\nconst NoFilter = __webpack_require__(/*! nofilter */ \"./node_modules/nofilter/lib/index.js\")\nconst {MT, NUMBYTES, SYMS} = __webpack_require__(/*! ./constants */ \"./node_modules/cbor/lib/constants.js\")\nconst {Buffer} = __webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\")\n\nfunction plural(c) {\n  if (c > 1) {\n    return 's'\n  }\n  return ''\n}\n\n/**\n * @typedef CommentOptions\n * @property {number} [max_depth=10] How many times to indent\n *   the dashes.\n * @property {number} [depth=1] Initial indentation depth.\n * @property {boolean} [no_summary=false] If true, omit the summary\n *   of the full bytes read at the end.\n * @property {object} [tags] Mapping from tag number to function(v),\n *   where v is the decoded value that comes after the tag, and where the\n *   function returns the correctly-created value for that tag.\n * @property {boolean} [preferWeb=false] If true, prefer Uint8Arrays to\n *   be generated instead of node Buffers.  This might turn on some more\n *   changes in the future, so forward-compatibility is not guaranteed yet.\n * @property {BufferEncoding} [encoding='hex'] Encoding to use for input, if it\n *   is a string.\n */\n/**\n * @callback commentCallback\n * @param {Error} [error] If one was generated.\n * @param {string} [commented] The comment string.\n * @returns {void}\n */\n/**\n * Normalize inputs to the static functions.\n *\n * @param {CommentOptions|commentCallback|string|number} opts Encoding,\n *   max_depth, or callback.\n * @param {commentCallback} [cb] Called on completion.\n * @returns {{options: CommentOptions, cb: commentCallback}} Normalized value.\n * @throws {TypeError} Unknown option type.\n * @private\n */\nfunction normalizeOptions(opts, cb) {\n  switch (typeof opts) {\n    case 'function':\n      return {options: {}, cb: /** @type {commentCallback} */ (opts)}\n    case 'string':\n      return {options: {encoding: /** @type {BufferEncoding} */ (opts)}, cb}\n    case 'number':\n      return {options: {max_depth: opts}, cb}\n    case 'object':\n      return {options: opts || {}, cb}\n    default:\n      throw new TypeError('Unknown option type')\n  }\n}\n\n/**\n * Generate the expanded format of RFC 8949, section 3.2.2.\n *\n * @extends stream.Transform\n */\nclass Commented extends stream.Transform {\n  /**\n   * Create a CBOR commenter.\n   *\n   * @param {CommentOptions} [options={}] Stream options.\n   */\n  constructor(options = {}) {\n    const {\n      depth = 1,\n      max_depth = 10,\n      no_summary = false,\n      // Decoder options\n      tags = {},\n      preferWeb,\n      encoding,\n      // Stream.Transform options\n      ...superOpts\n    } = options\n\n    super({\n      ...superOpts,\n      readableObjectMode: false,\n      writableObjectMode: false,\n    })\n\n    this.depth = depth\n    this.max_depth = max_depth\n    this.all = new NoFilter()\n\n    if (!tags[24]) {\n      tags[24] = this._tag_24.bind(this)\n    }\n    this.parser = new Decoder({\n      tags,\n      max_depth,\n      preferWeb,\n      encoding,\n    })\n    this.parser.on('value', this._on_value.bind(this))\n    this.parser.on('start', this._on_start.bind(this))\n    this.parser.on('start-string', this._on_start_string.bind(this))\n    this.parser.on('stop', this._on_stop.bind(this))\n    this.parser.on('more-bytes', this._on_more.bind(this))\n    this.parser.on('error', this._on_error.bind(this))\n    if (!no_summary) {\n      this.parser.on('data', this._on_data.bind(this))\n    }\n    this.parser.bs.on('read', this._on_read.bind(this))\n  }\n\n  /**\n   * @param {Buffer} v Descend into embedded CBOR.\n   * @private\n   */\n  _tag_24(v) {\n    const c = new Commented({depth: this.depth + 1, no_summary: true})\n\n    c.on('data', b => this.push(b))\n    c.on('error', er => this.emit('error', er))\n    c.end(v)\n  }\n\n  _transform(fresh, encoding, cb) {\n    this.parser.write(fresh, encoding, cb)\n  }\n\n  _flush(cb) {\n    // TODO: find the test that covers this, and look at the return value\n    return this.parser._flush(cb)\n  }\n\n  /**\n   * Comment on an input Buffer or string, creating a string passed to the\n   * callback.  If callback not specified, a promise is returned.\n   *\n   * @static\n   * @param {string|Buffer|ArrayBuffer|Uint8Array|Uint8ClampedArray\n   *   |DataView|stream.Readable} input Something to parse.\n   * @param {CommentOptions|commentCallback|string|number} [options={}]\n   *   Encoding, max_depth, or callback.\n   * @param {commentCallback} [cb] If specified, called on completion.\n   * @returns {Promise} If cb not specified.\n   * @throws {Error} Input required.\n   */\n  static comment(input, options = {}, cb = null) {\n    if (input == null) {\n      throw new Error('input required')\n    }\n    ({options, cb} = normalizeOptions(options, cb))\n    const bs = new NoFilter()\n    const {encoding = 'hex', ...opts} = options\n    const d = new Commented(opts)\n    let p = null\n\n    if (typeof cb === 'function') {\n      d.on('end', () => {\n        cb(null, bs.toString('utf8'))\n      })\n      d.on('error', cb)\n    } else {\n      p = new Promise((resolve, reject) => {\n        d.on('end', () => {\n          resolve(bs.toString('utf8'))\n        })\n        d.on('error', reject)\n      })\n    }\n    d.pipe(bs)\n    utils.guessEncoding(input, encoding).pipe(d)\n    return p\n  }\n\n  /**\n   * @ignore\n   */\n  _on_error(er) {\n    this.push('ERROR: ')\n    this.push(er.toString())\n    this.push('\\n')\n  }\n\n  /**\n   * @ignore\n   */\n  _on_read(buf) {\n    this.all.write(buf)\n    const hex = buf.toString('hex')\n\n    this.push(new Array(this.depth + 1).join('  '))\n    this.push(hex)\n\n    let ind = ((this.max_depth - this.depth) * 2) - hex.length\n    if (ind < 1) {\n      ind = 1\n    }\n    this.push(new Array(ind + 1).join(' '))\n    this.push('-- ')\n  }\n\n  /**\n   * @ignore\n   */\n  _on_more(mt, len, parent_mt, pos) {\n    let desc = ''\n\n    this.depth++\n    switch (mt) {\n      case MT.POS_INT:\n        desc = 'Positive number,'\n        break\n      case MT.NEG_INT:\n        desc = 'Negative number,'\n        break\n      case MT.ARRAY:\n        desc = 'Array, length'\n        break\n      case MT.MAP:\n        desc = 'Map, count'\n        break\n      case MT.BYTE_STRING:\n        desc = 'Bytes, length'\n        break\n      case MT.UTF8_STRING:\n        desc = 'String, length'\n        break\n      case MT.SIMPLE_FLOAT:\n        if (len === 1) {\n          desc = 'Simple value,'\n        } else {\n          desc = 'Float,'\n        }\n        break\n    }\n    this.push(`${desc} next ${len} byte${plural(len)}\\n`)\n  }\n\n  /**\n   * @ignore\n   */\n  _on_start_string(mt, len, parent_mt, pos) {\n    let desc = ''\n\n    this.depth++\n    switch (mt) {\n      case MT.BYTE_STRING:\n        desc = `Bytes, length: ${len}`\n        break\n      case MT.UTF8_STRING:\n        desc = `String, length: ${len.toString()}`\n        break\n    }\n    this.push(`${desc}\\n`)\n  }\n\n  /**\n   * @ignore\n   */\n  _on_start(mt, tag, parent_mt, pos) {\n    this.depth++\n    switch (parent_mt) {\n      case MT.ARRAY:\n        this.push(`[${pos}], `)\n        break\n      case MT.MAP:\n        if (pos % 2) {\n          this.push(`{Val:${Math.floor(pos / 2)}}, `)\n        } else {\n          this.push(`{Key:${Math.floor(pos / 2)}}, `)\n        }\n        break\n    }\n    switch (mt) {\n      case MT.TAG:\n        this.push(`Tag #${tag}`)\n        if (tag === 24) {\n          this.push(' Encoded CBOR data item')\n        }\n        break\n      case MT.ARRAY:\n        if (tag === SYMS.STREAM) {\n          this.push('Array (streaming)')\n        } else {\n          this.push(`Array, ${tag} item${plural(tag)}`)\n        }\n        break\n      case MT.MAP:\n        if (tag === SYMS.STREAM) {\n          this.push('Map (streaming)')\n        } else {\n          this.push(`Map, ${tag} pair${plural(tag)}`)\n        }\n        break\n      case MT.BYTE_STRING:\n        this.push('Bytes (streaming)')\n        break\n      case MT.UTF8_STRING:\n        this.push('String (streaming)')\n        break\n    }\n    this.push('\\n')\n  }\n\n  /**\n   * @ignore\n   */\n  _on_stop(mt) {\n    this.depth--\n  }\n\n  /**\n   * @private\n   */\n  _on_value(val, parent_mt, pos, ai) {\n    if (val !== SYMS.BREAK) {\n      switch (parent_mt) {\n        case MT.ARRAY:\n          this.push(`[${pos}], `)\n          break\n        case MT.MAP:\n          if (pos % 2) {\n            this.push(`{Val:${Math.floor(pos / 2)}}, `)\n          } else {\n            this.push(`{Key:${Math.floor(pos / 2)}}, `)\n          }\n          break\n      }\n    }\n    const str = utils.cborValueToString(val, -Infinity)\n\n    if ((typeof val === 'string') ||\n        (Buffer.isBuffer(val))) {\n      if (val.length > 0) {\n        this.push(str)\n        this.push('\\n')\n      }\n      this.depth--\n    } else {\n      this.push(str)\n      this.push('\\n')\n    }\n\n    switch (ai) {\n      case NUMBYTES.ONE:\n      case NUMBYTES.TWO:\n      case NUMBYTES.FOUR:\n      case NUMBYTES.EIGHT:\n        this.depth--\n    }\n  }\n\n  /**\n   * @ignore\n   */\n  _on_data() {\n    this.push('0x')\n    this.push(this.all.read().toString('hex'))\n    this.push('\\n')\n  }\n}\n\nmodule.exports = Commented\n\n\n//# sourceURL=webpack://dapp/./node_modules/cbor/lib/commented.js?");

/***/ }),

/***/ "./node_modules/cbor/lib/constants.js":
/*!********************************************!*\
  !*** ./node_modules/cbor/lib/constants.js ***!
  \********************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\n/**\n * @enum {number}\n */\nexports.MT = {\n  POS_INT: 0,\n  NEG_INT: 1,\n  BYTE_STRING: 2,\n  UTF8_STRING: 3,\n  ARRAY: 4,\n  MAP: 5,\n  TAG: 6,\n  SIMPLE_FLOAT: 7,\n}\n\n/**\n * @enum {number}\n */\nexports.TAG = {\n  DATE_STRING: 0,\n  DATE_EPOCH: 1,\n  POS_BIGINT: 2,\n  NEG_BIGINT: 3,\n  DECIMAL_FRAC: 4,\n  BIGFLOAT: 5,\n  BASE64URL_EXPECTED: 21,\n  BASE64_EXPECTED: 22,\n  BASE16_EXPECTED: 23,\n  CBOR: 24,\n  URI: 32,\n  BASE64URL: 33,\n  BASE64: 34,\n  REGEXP: 35,\n  MIME: 36,\n  // https://github.com/input-output-hk/cbor-sets-spec/blob/master/CBOR_SETS.md\n  SET: 258,\n}\n\n/**\n * @enum {number}\n */\nexports.NUMBYTES = {\n  ZERO: 0,\n  ONE: 24,\n  TWO: 25,\n  FOUR: 26,\n  EIGHT: 27,\n  INDEFINITE: 31,\n}\n\n/**\n * @enum {number}\n */\nexports.SIMPLE = {\n  FALSE: 20,\n  TRUE: 21,\n  NULL: 22,\n  UNDEFINED: 23,\n}\n\nexports.SYMS = {\n  NULL: Symbol.for('github.com/hildjj/node-cbor/null'),\n  UNDEFINED: Symbol.for('github.com/hildjj/node-cbor/undef'),\n  PARENT: Symbol.for('github.com/hildjj/node-cbor/parent'),\n  BREAK: Symbol.for('github.com/hildjj/node-cbor/break'),\n  STREAM: Symbol.for('github.com/hildjj/node-cbor/stream'),\n}\n\nexports.SHIFT32 = 0x100000000\n\nexports.BI = {\n  MINUS_ONE: BigInt(-1),\n  NEG_MAX: BigInt(-1) - BigInt(Number.MAX_SAFE_INTEGER),\n  MAXINT32: BigInt('0xffffffff'),\n  MAXINT64: BigInt('0xffffffffffffffff'),\n  SHIFT32: BigInt(exports.SHIFT32),\n}\n\n\n\n//# sourceURL=webpack://dapp/./node_modules/cbor/lib/constants.js?");

/***/ }),

/***/ "./node_modules/cbor/lib/decoder.js":
/*!******************************************!*\
  !*** ./node_modules/cbor/lib/decoder.js ***!
  \******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst BinaryParseStream = __webpack_require__(/*! ../vendor/binary-parse-stream */ \"./node_modules/cbor/vendor/binary-parse-stream/index.js\")\nconst Tagged = __webpack_require__(/*! ./tagged */ \"./node_modules/cbor/lib/tagged.js\")\nconst Simple = __webpack_require__(/*! ./simple */ \"./node_modules/cbor/lib/simple.js\")\nconst utils = __webpack_require__(/*! ./utils */ \"./node_modules/cbor/lib/utils.js\")\nconst NoFilter = __webpack_require__(/*! nofilter */ \"./node_modules/nofilter/lib/index.js\")\nconst stream = __webpack_require__(/*! stream */ \"./node_modules/stream-browserify/index.js\")\nconst constants = __webpack_require__(/*! ./constants */ \"./node_modules/cbor/lib/constants.js\")\nconst {MT, NUMBYTES, SYMS, BI} = constants\nconst {Buffer} = __webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\")\n\nconst COUNT = Symbol('count')\nconst MAJOR = Symbol('major type')\nconst ERROR = Symbol('error')\nconst NOT_FOUND = Symbol('not found')\n\nfunction parentArray(parent, typ, count) {\n  const a = []\n\n  a[COUNT] = count\n  a[SYMS.PARENT] = parent\n  a[MAJOR] = typ\n  return a\n}\n\nfunction parentBufferStream(parent, typ) {\n  const b = new NoFilter()\n\n  b[COUNT] = -1\n  b[SYMS.PARENT] = parent\n  b[MAJOR] = typ\n  return b\n}\n\nclass UnexpectedDataError extends Error {\n  constructor(byte, value) {\n    super(`Unexpected data: 0x${byte.toString(16)}`)\n    this.name = 'UnexpectedDataError'\n    this.byte = byte\n    this.value = value\n  }\n}\n\n/**\n * Things that can act as inputs, from which a NoFilter can be created.\n *\n * @typedef {string|Buffer|ArrayBuffer|Uint8Array|Uint8ClampedArray\n *   |DataView|stream.Readable} BufferLike\n */\n/**\n * @typedef ExtendedResults\n * @property {any} value The value that was found.\n * @property {number} length The number of bytes of the original input that\n *   were read.\n * @property {Buffer} bytes The bytes of the original input that were used\n *   to produce the value.\n * @property {Buffer} [unused] The bytes that were left over from the original\n *   input.  This property only exists if {@linkcode Decoder.decodeFirst} or\n *   {@linkcode Decoder.decodeFirstSync} was called.\n */\n/**\n * @typedef DecoderOptions\n * @property {number} [max_depth=-1] The maximum depth to parse.\n *   Use -1 for \"until you run out of memory\".  Set this to a finite\n *   positive number for un-trusted inputs.  Most standard inputs won't nest\n *   more than 100 or so levels; I've tested into the millions before\n *   running out of memory.\n * @property {Tagged.TagMap} [tags] Mapping from tag number to function(v),\n *   where v is the decoded value that comes after the tag, and where the\n *   function returns the correctly-created value for that tag.\n * @property {boolean} [preferWeb=false] If true, prefer Uint8Arrays to\n *   be generated instead of node Buffers.  This might turn on some more\n *   changes in the future, so forward-compatibility is not guaranteed yet.\n * @property {BufferEncoding} [encoding='hex'] The encoding of the input.\n *   Ignored if input is a Buffer.\n * @property {boolean} [required=false] Should an error be thrown when no\n *   data is in the input?\n * @property {boolean} [extendedResults=false] If true, emit extended\n *   results, which will be an object with shape {@link ExtendedResults}.\n *   The value will already have been null-checked.\n * @property {boolean} [preventDuplicateKeys=false] If true, error is\n *   thrown if a map has duplicate keys.\n */\n/**\n * @callback decodeCallback\n * @param {Error} [error] If one was generated.\n * @param {any} [value] The decoded value.\n * @returns {void}\n */\n/**\n * @param {DecoderOptions|decodeCallback|string} opts Options,\n *   the callback, or input incoding.\n * @param {decodeCallback} [cb] Called on completion.\n * @returns {{options: DecoderOptions, cb: decodeCallback}} Normalized.\n * @throws {TypeError} On unknown option type.\n * @private\n */\nfunction normalizeOptions(opts, cb) {\n  switch (typeof opts) {\n    case 'function':\n      return {options: {}, cb: /** @type {decodeCallback} */ (opts)}\n    case 'string':\n      return {options: {encoding: /** @type {BufferEncoding} */ (opts)}, cb}\n    case 'object':\n      return {options: opts || {}, cb}\n    default:\n      throw new TypeError('Unknown option type')\n  }\n}\n\n/**\n * Decode a stream of CBOR bytes by transforming them into equivalent\n * JavaScript data.  Because of the limitations of Node object streams,\n * special symbols are emitted instead of NULL or UNDEFINED.  Fix those\n * up by calling {@link Decoder.nullcheck}.\n *\n * @extends BinaryParseStream\n */\nclass Decoder extends BinaryParseStream {\n  /**\n   * Create a parsing stream.\n   *\n   * @param {DecoderOptions} [options={}] Options.\n   */\n  constructor(options = {}) {\n    const {\n      tags = {},\n      max_depth = -1,\n      preferWeb = false,\n      required = false,\n      encoding = 'hex',\n      extendedResults = false,\n      preventDuplicateKeys = false,\n      ...superOpts\n    } = options\n\n    super({defaultEncoding: encoding, ...superOpts})\n\n    this.running = true\n    this.max_depth = max_depth\n    this.tags = tags\n    this.preferWeb = preferWeb\n    this.extendedResults = extendedResults\n    this.required = required\n    this.preventDuplicateKeys = preventDuplicateKeys\n\n    if (extendedResults) {\n      this.bs.on('read', this._onRead.bind(this))\n      this.valueBytes = /** @type {NoFilter} */ (new NoFilter())\n    }\n  }\n\n  /**\n   * Check the given value for a symbol encoding a NULL or UNDEFINED value in\n   * the CBOR stream.\n   *\n   * @static\n   * @param {any} val The value to check.\n   * @returns {any} The corrected value.\n   * @throws {Error} Nothing was found.\n   * @example\n   * myDecoder.on('data', val => {\n   *   val = Decoder.nullcheck(val)\n   *   // ...\n   * })\n   */\n  static nullcheck(val) {\n    switch (val) {\n      case SYMS.NULL:\n        return null\n      case SYMS.UNDEFINED:\n        return undefined\n      // Leaving this in for now as belt-and-suspenders, but I'm pretty sure\n      // it can't happen.\n      /* istanbul ignore next */\n      case NOT_FOUND:\n        /* istanbul ignore next */\n        throw new Error('Value not found')\n      default:\n        return val\n    }\n  }\n\n  /**\n   * Decode the first CBOR item in the input, synchronously.  This will throw\n   * an exception if the input is not valid CBOR, or if there are more bytes\n   * left over at the end (if options.extendedResults is not true).\n   *\n   * @static\n   * @param {BufferLike} input If a Readable stream, must have\n   *   received the `readable` event already, or you will get an error\n   *   claiming \"Insufficient data\".\n   * @param {DecoderOptions|string} [options={}] Options or encoding for input.\n   * @returns {ExtendedResults|any} The decoded value.\n   * @throws {UnexpectedDataError} Data is left over after decoding.\n   * @throws {Error} Insufficient data.\n   */\n  static decodeFirstSync(input, options = {}) {\n    if (input == null) {\n      throw new TypeError('input required')\n    }\n    ({options} = normalizeOptions(options))\n    const {encoding = 'hex', ...opts} = options\n    const c = new Decoder(opts)\n    const s = utils.guessEncoding(input, encoding)\n\n    // For/of doesn't work when you need to call next() with a value\n    // generator created by parser will be \"done\" after each CBOR entity\n    // parser will yield numbers of bytes that it wants\n    const parser = c._parse()\n    let state = parser.next()\n\n    while (!state.done) {\n      const b = s.read(state.value)\n\n      if ((b == null) || (b.length !== state.value)) {\n        throw new Error('Insufficient data')\n      }\n      if (c.extendedResults) {\n        c.valueBytes.write(b)\n      }\n      state = parser.next(b)\n    }\n\n    let val = null\n    if (c.extendedResults) {\n      val = state.value\n      val.unused = s.read()\n    } else {\n      val = Decoder.nullcheck(state.value)\n      if (s.length > 0) {\n        const nextByte = s.read(1)\n\n        s.unshift(nextByte)\n        throw new UnexpectedDataError(nextByte[0], val)\n      }\n    }\n    return val\n  }\n\n  /**\n   * Decode all of the CBOR items in the input into an array.  This will throw\n   * an exception if the input is not valid CBOR; a zero-length input will\n   * return an empty array.\n   *\n   * @static\n   * @param {BufferLike} input What to parse?\n   * @param {DecoderOptions|string} [options={}] Options or encoding\n   *   for input.\n   * @returns {Array<ExtendedResults>|Array<any>} Array of all found items.\n   * @throws {TypeError} No input provided.\n   * @throws {Error} Insufficient data provided.\n   */\n  static decodeAllSync(input, options = {}) {\n    if (input == null) {\n      throw new TypeError('input required')\n    }\n    ({options} = normalizeOptions(options))\n    const {encoding = 'hex', ...opts} = options\n    const c = new Decoder(opts)\n    const s = utils.guessEncoding(input, encoding)\n    const res = []\n\n    while (s.length > 0) {\n      const parser = c._parse()\n      let state = parser.next()\n\n      while (!state.done) {\n        const b = s.read(state.value)\n\n        if ((b == null) || (b.length !== state.value)) {\n          throw new Error('Insufficient data')\n        }\n        if (c.extendedResults) {\n          c.valueBytes.write(b)\n        }\n        state = parser.next(b)\n      }\n      res.push(Decoder.nullcheck(state.value))\n    }\n    return res\n  }\n\n  /**\n   * Decode the first CBOR item in the input.  This will error if there are\n   * more bytes left over at the end (if options.extendedResults is not true),\n   * and optionally if there were no valid CBOR bytes in the input.  Emits the\n   * {Decoder.NOT_FOUND} Symbol in the callback if no data was found and the\n   * `required` option is false.\n   *\n   * @static\n   * @param {BufferLike} input What to parse?\n   * @param {DecoderOptions|decodeCallback|string} [options={}] Options, the\n   *   callback, or input encoding.\n   * @param {decodeCallback} [cb] Callback.\n   * @returns {Promise<ExtendedResults|any>} Returned even if callback is\n   *   specified.\n   * @throws {TypeError} No input provided.\n   */\n  static decodeFirst(input, options = {}, cb = null) {\n    if (input == null) {\n      throw new TypeError('input required')\n    }\n    ({options, cb} = normalizeOptions(options, cb))\n    const {encoding = 'hex', required = false, ...opts} = options\n\n    const c = new Decoder(opts)\n    let v = /** @type {any} */ (NOT_FOUND)\n    const s = utils.guessEncoding(input, encoding)\n    const p = new Promise((resolve, reject) => {\n      c.on('data', val => {\n        v = Decoder.nullcheck(val)\n        c.close()\n      })\n      c.once('error', er => {\n        if (c.extendedResults && (er instanceof UnexpectedDataError)) {\n          v.unused = c.bs.slice()\n          return resolve(v)\n        }\n        if (v !== NOT_FOUND) {\n          // Typescript work-around\n          // eslint-disable-next-line dot-notation\n          er['value'] = v\n        }\n        v = ERROR\n        c.close()\n        return reject(er)\n      })\n      c.once('end', () => {\n        switch (v) {\n          case NOT_FOUND:\n            if (required) {\n              return reject(new Error('No CBOR found'))\n            }\n            return resolve(v)\n          // Pretty sure this can't happen, but not *certain*.\n          /* istanbul ignore next */\n          case ERROR:\n            /* istanbul ignore next */\n            return undefined\n          default:\n            return resolve(v)\n        }\n      })\n    })\n\n    if (typeof cb === 'function') {\n      p.then(val => cb(null, val), cb)\n    }\n    s.pipe(c)\n    return p\n  }\n\n  /**\n   * @callback decodeAllCallback\n   * @param {Error} error If one was generated.\n   * @param {Array<ExtendedResults>|Array<any>} value All of the decoded\n   *   values, wrapped in an Array.\n   */\n\n  /**\n   * Decode all of the CBOR items in the input.  This will error if there are\n   * more bytes left over at the end.\n   *\n   * @static\n   * @param {BufferLike} input What to parse?\n   * @param {DecoderOptions|decodeAllCallback|string} [options={}]\n   *   Decoding options, the callback, or the input encoding.\n   * @param {decodeAllCallback} [cb] Callback.\n   * @returns {Promise<Array<ExtendedResults>|Array<any>>} Even if callback\n   *   is specified.\n   * @throws {TypeError} No input specified.\n   */\n  static decodeAll(input, options = {}, cb = null) {\n    if (input == null) {\n      throw new TypeError('input required')\n    }\n    ({options, cb} = normalizeOptions(options, cb))\n    const {encoding = 'hex', ...opts} = options\n\n    const c = new Decoder(opts)\n    const vals = []\n\n    c.on('data', val => vals.push(Decoder.nullcheck(val)))\n\n    const p = new Promise((resolve, reject) => {\n      c.on('error', reject)\n      c.on('end', () => resolve(vals))\n    })\n\n    if (typeof cb === 'function') {\n      p.then(v => cb(undefined, v), er => cb(er, undefined))\n    }\n    utils.guessEncoding(input, encoding).pipe(c)\n    return p\n  }\n\n  /**\n   * Stop processing.\n   */\n  close() {\n    this.running = false\n    this.__fresh = true\n  }\n\n  /**\n   * Only called if extendedResults is true.\n   *\n   * @ignore\n   */\n  _onRead(data) {\n    this.valueBytes.write(data)\n  }\n\n  /**\n   * @yields {number} Number of bytes to read.\n   * @returns {Generator<number, any, Buffer>} Yields a number of bytes,\n   *   returns anything, next returns a Buffer.\n   * @throws {Error} Maximum depth exceeded.\n   * @ignore\n   */\n  *_parse() {\n    let parent = null\n    let depth = 0\n    let val = null\n\n    while (true) {\n      if ((this.max_depth >= 0) && (depth > this.max_depth)) {\n        throw new Error(`Maximum depth ${this.max_depth} exceeded`)\n      }\n\n      const [octet] = yield 1\n      if (!this.running) {\n        this.bs.unshift(Buffer.from([octet]))\n        throw new UnexpectedDataError(octet)\n      }\n      const mt = octet >> 5\n      const ai = octet & 0x1f\n      const parent_major = (parent == null) ? undefined : parent[MAJOR]\n      const parent_length = (parent == null) ? undefined : parent.length\n\n      switch (ai) {\n        case NUMBYTES.ONE:\n          this.emit('more-bytes', mt, 1, parent_major, parent_length)\n          ;[val] = yield 1\n          break\n        case NUMBYTES.TWO:\n        case NUMBYTES.FOUR:\n        case NUMBYTES.EIGHT: {\n          const numbytes = 1 << (ai - 24)\n\n          this.emit('more-bytes', mt, numbytes, parent_major, parent_length)\n          const buf = yield numbytes\n          val = (mt === MT.SIMPLE_FLOAT) ?\n            buf :\n            utils.parseCBORint(ai, buf)\n          break\n        }\n        case 28:\n        case 29:\n        case 30:\n          this.running = false\n          throw new Error(`Additional info not implemented: ${ai}`)\n        case NUMBYTES.INDEFINITE:\n          switch (mt) {\n            case MT.POS_INT:\n            case MT.NEG_INT:\n            case MT.TAG:\n              throw new Error(`Invalid indefinite encoding for MT ${mt}`)\n          }\n          val = -1\n          break\n        default:\n          val = ai\n      }\n      switch (mt) {\n        case MT.POS_INT:\n          // Val already decoded\n          break\n        case MT.NEG_INT:\n          if (val === Number.MAX_SAFE_INTEGER) {\n            val = BI.NEG_MAX\n          } else {\n            val = (typeof val === 'bigint') ? BI.MINUS_ONE - val : -1 - val\n          }\n          break\n        case MT.BYTE_STRING:\n        case MT.UTF8_STRING:\n          switch (val) {\n            case 0:\n              this.emit('start-string', mt, val, parent_major, parent_length)\n              if (mt === MT.UTF8_STRING) {\n                val = ''\n              } else {\n                val = this.preferWeb ? new Uint8Array(0) : Buffer.allocUnsafe(0)\n              }\n              break\n            case -1:\n              this.emit('start', mt, SYMS.STREAM, parent_major, parent_length)\n              parent = parentBufferStream(parent, mt)\n              depth++\n              continue\n            default:\n              this.emit('start-string', mt, val, parent_major, parent_length)\n              val = yield val\n              if (mt === MT.UTF8_STRING) {\n                val = utils.utf8(val)\n              } else if (this.preferWeb) {\n                val = new Uint8Array(val.buffer, val.byteOffset, val.length)\n              }\n          }\n          break\n        case MT.ARRAY:\n        case MT.MAP:\n          switch (val) {\n            case 0:\n              val = (mt === MT.MAP) ? {} : []\n              break\n            case -1:\n              this.emit('start', mt, SYMS.STREAM, parent_major, parent_length)\n              parent = parentArray(parent, mt, -1)\n              depth++\n              continue\n            default:\n              this.emit('start', mt, val, parent_major, parent_length)\n              parent = parentArray(parent, mt, val * (mt - 3))\n              depth++\n              continue\n          }\n          break\n        case MT.TAG:\n          this.emit('start', mt, val, parent_major, parent_length)\n          parent = parentArray(parent, mt, 1)\n          parent.push(val)\n          depth++\n          continue\n        case MT.SIMPLE_FLOAT:\n          if (typeof val === 'number') {\n            if ((ai === NUMBYTES.ONE) && (val < 32)) {\n              throw new Error(\n                `Invalid two-byte encoding of simple value ${val}`\n              )\n            }\n            const hasParent = (parent != null)\n            val = Simple.decode(\n              val,\n              hasParent,\n              hasParent && (parent[COUNT] < 0)\n            )\n          } else {\n            val = utils.parseCBORfloat(val)\n          }\n      }\n      this.emit('value', val, parent_major, parent_length, ai)\n      let again = false\n      while (parent != null) {\n        if (val === SYMS.BREAK) {\n          parent[COUNT] = 1\n        } else if (Array.isArray(parent)) {\n          parent.push(val)\n        } else {\n          // Assert: parent instanceof NoFilter\n          const pm = parent[MAJOR]\n\n          if ((pm != null) && (pm !== mt)) {\n            this.running = false\n            throw new Error('Invalid major type in indefinite encoding')\n          }\n          parent.write(val)\n        }\n\n        if ((--parent[COUNT]) !== 0) {\n          again = true\n          break\n        }\n        --depth\n        delete parent[COUNT]\n\n        if (Array.isArray(parent)) {\n          switch (parent[MAJOR]) {\n            case MT.ARRAY:\n              val = parent\n              break\n            case MT.MAP: {\n              let allstrings = true\n\n              if ((parent.length % 2) !== 0) {\n                throw new Error(`Invalid map length: ${parent.length}`)\n              }\n              for (let i = 0, len = parent.length; i < len; i += 2) {\n                if ((typeof parent[i] !== 'string') ||\n                    (parent[i] === '__proto__')) {\n                  allstrings = false\n                  break\n                }\n              }\n              if (allstrings) {\n                val = {}\n                for (let i = 0, len = parent.length; i < len; i += 2) {\n                  if (this.preventDuplicateKeys &&\n                    Object.prototype.hasOwnProperty.call(val, parent[i])) {\n                    throw new Error('Duplicate keys in a map')\n                  }\n                  val[parent[i]] = parent[i + 1]\n                }\n              } else {\n                val = new Map()\n                for (let i = 0, len = parent.length; i < len; i += 2) {\n                  if (this.preventDuplicateKeys && val.has(parent[i])) {\n                    throw new Error('Duplicate keys in a map')\n                  }\n                  val.set(parent[i], parent[i + 1])\n                }\n              }\n              break\n            }\n            case MT.TAG: {\n              const t = new Tagged(parent[0], parent[1])\n\n              val = t.convert(this.tags)\n              break\n            }\n          }\n        } else /* istanbul ignore else */ if (parent instanceof NoFilter) {\n          // Only parent types are Array and NoFilter for (Array/Map) and\n          // (bytes/string) respectively.\n          switch (parent[MAJOR]) {\n            case MT.BYTE_STRING:\n              val = parent.slice()\n              if (this.preferWeb) {\n                val = new Uint8Array(\n                  /** @type {Buffer} */ (val).buffer,\n                  /** @type {Buffer} */ (val).byteOffset,\n                  /** @type {Buffer} */ (val).length\n                )\n              }\n              break\n            case MT.UTF8_STRING:\n              val = parent.toString('utf-8')\n              break\n          }\n        }\n        this.emit('stop', parent[MAJOR])\n\n        const old = parent\n        parent = parent[SYMS.PARENT]\n        delete old[SYMS.PARENT]\n        delete old[MAJOR]\n      }\n      if (!again) {\n        if (this.extendedResults) {\n          const bytes = this.valueBytes.slice()\n          const ret = {\n            value: Decoder.nullcheck(val),\n            bytes,\n            length: bytes.length,\n          }\n\n          this.valueBytes = new NoFilter()\n          return ret\n        }\n        return val\n      }\n    }\n  }\n}\n\nDecoder.NOT_FOUND = NOT_FOUND\nmodule.exports = Decoder\n\n\n//# sourceURL=webpack://dapp/./node_modules/cbor/lib/decoder.js?");

/***/ }),

/***/ "./node_modules/cbor/lib/diagnose.js":
/*!*******************************************!*\
  !*** ./node_modules/cbor/lib/diagnose.js ***!
  \*******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst stream = __webpack_require__(/*! stream */ \"./node_modules/stream-browserify/index.js\")\nconst Decoder = __webpack_require__(/*! ./decoder */ \"./node_modules/cbor/lib/decoder.js\")\nconst utils = __webpack_require__(/*! ./utils */ \"./node_modules/cbor/lib/utils.js\")\nconst NoFilter = __webpack_require__(/*! nofilter */ \"./node_modules/nofilter/lib/index.js\")\nconst {MT, SYMS} = __webpack_require__(/*! ./constants */ \"./node_modules/cbor/lib/constants.js\")\n\n/**\n * Things that can act as inputs, from which a NoFilter can be created.\n *\n * @typedef {string|Buffer|ArrayBuffer|Uint8Array|Uint8ClampedArray\n *   |DataView|stream.Readable} BufferLike\n */\n\n/**\n * @typedef DiagnoseOptions\n * @property {string} [separator='\\n'] Output between detected objects.\n * @property {boolean} [stream_errors=false] Put error info into the\n *   output stream.\n * @property {number} [max_depth=-1] The maximum depth to parse.\n *   Use -1 for \"until you run out of memory\".  Set this to a finite\n *   positive number for un-trusted inputs.  Most standard inputs won't nest\n *   more than 100 or so levels; I've tested into the millions before\n *   running out of memory.\n * @property {object} [tags] Mapping from tag number to function(v),\n *   where v is the decoded value that comes after the tag, and where the\n *   function returns the correctly-created value for that tag.\n * @property {boolean} [preferWeb=false] If true, prefer Uint8Arrays to\n *   be generated instead of node Buffers.  This might turn on some more\n *   changes in the future, so forward-compatibility is not guaranteed yet.\n * @property {BufferEncoding} [encoding='hex'] The encoding of input, ignored if\n *   input is not string.\n */\n/**\n * @callback diagnoseCallback\n * @param {Error} [error] If one was generated.\n * @param {string} [value] The diagnostic value.\n * @returns {void}\n */\n/**\n * @param {DiagnoseOptions|diagnoseCallback|string} opts Options,\n *   the callback, or input incoding.\n * @param {diagnoseCallback} [cb] Called on completion.\n * @returns {{options: DiagnoseOptions, cb: diagnoseCallback}} Normalized.\n * @throws {TypeError} Unknown option type.\n * @private\n */\nfunction normalizeOptions(opts, cb) {\n  switch (typeof opts) {\n    case 'function':\n      return {options: {}, cb: /** @type {diagnoseCallback} */ (opts)}\n    case 'string':\n      return {options: {encoding: /** @type {BufferEncoding} */ (opts)}, cb}\n    case 'object':\n      return {options: opts || {}, cb}\n    default:\n      throw new TypeError('Unknown option type')\n  }\n}\n\n/**\n * Output the diagnostic format from a stream of CBOR bytes.\n *\n * @extends stream.Transform\n */\nclass Diagnose extends stream.Transform {\n  /**\n   * Creates an instance of Diagnose.\n   *\n   * @param {DiagnoseOptions} [options={}] Options for creation.\n   */\n  constructor(options = {}) {\n    const {\n      separator = '\\n',\n      stream_errors = false,\n      // Decoder options\n      tags,\n      max_depth,\n      preferWeb,\n      encoding,\n      // Stream.Transform options\n      ...superOpts\n    } = options\n    super({\n      ...superOpts,\n      readableObjectMode: false,\n      writableObjectMode: false,\n    })\n\n    this.float_bytes = -1\n    this.separator = separator\n    this.stream_errors = stream_errors\n    this.parser = new Decoder({\n      tags,\n      max_depth,\n      preferWeb,\n      encoding,\n    })\n    this.parser.on('more-bytes', this._on_more.bind(this))\n    this.parser.on('value', this._on_value.bind(this))\n    this.parser.on('start', this._on_start.bind(this))\n    this.parser.on('stop', this._on_stop.bind(this))\n    this.parser.on('data', this._on_data.bind(this))\n    this.parser.on('error', this._on_error.bind(this))\n  }\n\n  _transform(fresh, encoding, cb) {\n    return this.parser.write(fresh, encoding, cb)\n  }\n\n  _flush(cb) {\n    return this.parser._flush(er => {\n      if (this.stream_errors) {\n        if (er) {\n          this._on_error(er)\n        }\n        return cb()\n      }\n      return cb(er)\n    })\n  }\n\n  /**\n   * Convenience function to return a string in diagnostic format.\n   *\n   * @param {BufferLike} input The CBOR bytes to format.\n   * @param {DiagnoseOptions |diagnoseCallback|string} [options={}]\n   *   Options, the callback, or the input encoding.\n   * @param {diagnoseCallback} [cb] Callback.\n   * @throws {TypeError} Input not provided.\n   * @returns {Promise} If callback not specified.\n   */\n  static diagnose(input, options = {}, cb = null) {\n    if (input == null) {\n      throw new TypeError('input required')\n    }\n    ({options, cb} = normalizeOptions(options, cb))\n    const {encoding = 'hex', ...opts} = options\n\n    const bs = new NoFilter()\n    const d = new Diagnose(opts)\n    let p = null\n    if (typeof cb === 'function') {\n      d.on('end', () => cb(null, bs.toString('utf8')))\n      d.on('error', cb)\n    } else {\n      p = new Promise((resolve, reject) => {\n        d.on('end', () => resolve(bs.toString('utf8')))\n        d.on('error', reject)\n      })\n    }\n    d.pipe(bs)\n    utils.guessEncoding(input, encoding).pipe(d)\n    return p\n  }\n\n  /**\n   * @ignore\n   */\n  _on_error(er) {\n    if (this.stream_errors) {\n      this.push(er.toString())\n    } else {\n      this.emit('error', er)\n    }\n  }\n\n  /** @private */\n  _on_more(mt, len, parent_mt, pos) {\n    if (mt === MT.SIMPLE_FLOAT) {\n      this.float_bytes = {\n        2: 1,\n        4: 2,\n        8: 3,\n      }[len]\n    }\n  }\n\n  /** @private */\n  _fore(parent_mt, pos) {\n    switch (parent_mt) {\n      case MT.BYTE_STRING:\n      case MT.UTF8_STRING:\n      case MT.ARRAY:\n        if (pos > 0) {\n          this.push(', ')\n        }\n        break\n      case MT.MAP:\n        if (pos > 0) {\n          if (pos % 2) {\n            this.push(': ')\n          } else {\n            this.push(', ')\n          }\n        }\n    }\n  }\n\n  /** @private */\n  _on_value(val, parent_mt, pos) {\n    if (val === SYMS.BREAK) {\n      return\n    }\n    this._fore(parent_mt, pos)\n    const fb = this.float_bytes\n    this.float_bytes = -1\n    this.push(utils.cborValueToString(val, fb))\n  }\n\n  /** @private */\n  _on_start(mt, tag, parent_mt, pos) {\n    this._fore(parent_mt, pos)\n    switch (mt) {\n      case MT.TAG:\n        this.push(`${tag}(`)\n        break\n      case MT.ARRAY:\n        this.push('[')\n        break\n      case MT.MAP:\n        this.push('{')\n        break\n      case MT.BYTE_STRING:\n      case MT.UTF8_STRING:\n        this.push('(')\n        break\n    }\n    if (tag === SYMS.STREAM) {\n      this.push('_ ')\n    }\n  }\n\n  /** @private */\n  _on_stop(mt) {\n    switch (mt) {\n      case MT.TAG:\n        this.push(')')\n        break\n      case MT.ARRAY:\n        this.push(']')\n        break\n      case MT.MAP:\n        this.push('}')\n        break\n      case MT.BYTE_STRING:\n      case MT.UTF8_STRING:\n        this.push(')')\n        break\n    }\n  }\n\n  /** @private */\n  _on_data() {\n    this.push(this.separator)\n  }\n}\n\nmodule.exports = Diagnose\n\n\n//# sourceURL=webpack://dapp/./node_modules/cbor/lib/diagnose.js?");

/***/ }),

/***/ "./node_modules/cbor/lib/encoder.js":
/*!******************************************!*\
  !*** ./node_modules/cbor/lib/encoder.js ***!
  \******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst stream = __webpack_require__(/*! stream */ \"./node_modules/stream-browserify/index.js\")\nconst NoFilter = __webpack_require__(/*! nofilter */ \"./node_modules/nofilter/lib/index.js\")\nconst utils = __webpack_require__(/*! ./utils */ \"./node_modules/cbor/lib/utils.js\")\nconst constants = __webpack_require__(/*! ./constants */ \"./node_modules/cbor/lib/constants.js\")\nconst {\n  MT, NUMBYTES, SHIFT32, SIMPLE, SYMS, TAG, BI,\n} = constants\nconst {Buffer} = __webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\")\n\nconst HALF = (MT.SIMPLE_FLOAT << 5) | NUMBYTES.TWO\nconst FLOAT = (MT.SIMPLE_FLOAT << 5) | NUMBYTES.FOUR\nconst DOUBLE = (MT.SIMPLE_FLOAT << 5) | NUMBYTES.EIGHT\nconst TRUE = (MT.SIMPLE_FLOAT << 5) | SIMPLE.TRUE\nconst FALSE = (MT.SIMPLE_FLOAT << 5) | SIMPLE.FALSE\nconst UNDEFINED = (MT.SIMPLE_FLOAT << 5) | SIMPLE.UNDEFINED\nconst NULL = (MT.SIMPLE_FLOAT << 5) | SIMPLE.NULL\n\nconst BREAK = Buffer.from([0xff])\nconst BUF_NAN = Buffer.from('f97e00', 'hex')\nconst BUF_INF_NEG = Buffer.from('f9fc00', 'hex')\nconst BUF_INF_POS = Buffer.from('f97c00', 'hex')\nconst BUF_NEG_ZERO = Buffer.from('f98000', 'hex')\n\n/**\n * Generate the CBOR for a value.  If you are using this, you'll either need\n * to call {@link Encoder.write} with a Buffer, or look into the internals of\n * Encoder to reuse existing non-documented behavior.\n *\n * @callback EncodeFunction\n * @param {Encoder} enc The encoder to use.\n * @param {any} val The value to encode.\n * @returns {boolean} True on success.\n */\n\n/* eslint-disable jsdoc/check-types */\n/**\n * A mapping from tag number to a tag decoding function.\n *\n * @typedef {Object.<string, EncodeFunction>} SemanticMap\n */\n/* eslint-enable jsdoc/check-types */\n\n/**\n * @type {SemanticMap}\n * @private\n */\nconst SEMANTIC_TYPES = {}\n\n/**\n * @type {SemanticMap}\n * @private\n */\nlet current_SEMANTIC_TYPES = {}\n\n/**\n * @param {string} str String to normalize.\n * @returns {\"number\"|\"float\"|\"int\"|\"string\"} Normalized.\n * @throws {TypeError} Invalid input.\n * @private\n */\nfunction parseDateType(str) {\n  if (!str) {\n    return 'number'\n  }\n  switch (str.toLowerCase()) {\n    case 'number':\n      return 'number'\n    case 'float':\n      return 'float'\n    case 'int':\n    case 'integer':\n      return 'int'\n    case 'string':\n      return 'string'\n  }\n  throw new TypeError(`dateType invalid, got \"${str}\"`)\n}\n\n/**\n * @typedef EncodingOptions\n * @property {any[]|object} [genTypes=[]] Array of pairs of\n *   `type`, `function(Encoder)` for semantic types to be encoded.  Not\n *   needed for Array, Date, Buffer, Map, RegExp, Set, or URL.\n *   If an object, the keys are the constructor names for the types.\n * @property {boolean} [canonical=false] Should the output be\n *   canonicalized.\n * @property {boolean|WeakSet} [detectLoops=false] Should object loops\n *   be detected?  This will currently add memory to track every part of the\n *   object being encoded in a WeakSet.  Do not encode\n *   the same object twice on the same encoder, without calling\n *   `removeLoopDetectors` in between, which will clear the WeakSet.\n *   You may pass in your own WeakSet to be used; this is useful in some\n *   recursive scenarios.\n * @property {(\"number\"|\"float\"|\"int\"|\"string\")} [dateType=\"number\"] -\n *   how should dates be encoded?  \"number\" means float or int, if no\n *   fractional seconds.\n * @property {any} [encodeUndefined=undefined] How should an\n *   \"undefined\" in the input be encoded.  By default, just encode a CBOR\n *   undefined.  If this is a buffer, use those bytes without re-encoding\n *   them.  If this is a function, the function will be called (which is a\n *   good time to throw an exception, if that's what you want), and the\n *   return value will be used according to these rules.  Anything else will\n *   be encoded as CBOR.\n * @property {boolean} [disallowUndefinedKeys=false] Should\n *   \"undefined\" be disallowed as a key in a Map that is serialized?  If\n *   this is true, encode(new Map([[undefined, 1]])) will throw an\n *   exception.  Note that it is impossible to get a key of undefined in a\n *   normal JS object.\n * @property {boolean} [collapseBigIntegers=false] Should integers\n *   that come in as ECMAscript bigint's be encoded\n *   as normal CBOR integers if they fit, discarding type information?\n * @property {number} [chunkSize=4096] Number of characters or bytes\n *   for each chunk, if obj is a string or Buffer, when indefinite encoding.\n * @property {boolean} [omitUndefinedProperties=false] When encoding\n *   objects or Maps, do not include a key if its corresponding value is\n *   `undefined`.\n */\n\n/**\n * Transform JavaScript values into CBOR bytes.  The `Writable` side of\n * the stream is in object mode.\n *\n * @extends stream.Transform\n */\nclass Encoder extends stream.Transform {\n  /**\n   * Creates an instance of Encoder.\n   *\n   * @param {EncodingOptions} [options={}] Options for the encoder.\n   */\n  constructor(options = {}) {\n    const {\n      canonical = false,\n      encodeUndefined,\n      disallowUndefinedKeys = false,\n      dateType = 'number',\n      collapseBigIntegers = false,\n      detectLoops = false,\n      omitUndefinedProperties = false,\n      genTypes = [],\n      ...superOpts\n    } = options\n\n    super({\n      ...superOpts,\n      readableObjectMode: false,\n      writableObjectMode: true,\n    })\n\n    this.canonical = canonical\n    this.encodeUndefined = encodeUndefined\n    this.disallowUndefinedKeys = disallowUndefinedKeys\n    this.dateType = parseDateType(dateType)\n    this.collapseBigIntegers = this.canonical ? true : collapseBigIntegers\n\n    /** @type {WeakSet?} */\n    this.detectLoops = undefined\n    if (typeof detectLoops === 'boolean') {\n      if (detectLoops) {\n        this.detectLoops = new WeakSet()\n      }\n    } else if (detectLoops instanceof WeakSet) {\n      this.detectLoops = detectLoops\n    } else {\n      throw new TypeError('detectLoops must be boolean or WeakSet')\n    }\n    this.omitUndefinedProperties = omitUndefinedProperties\n\n    this.semanticTypes = {...Encoder.SEMANTIC_TYPES}\n\n    if (Array.isArray(genTypes)) {\n      for (let i = 0, len = genTypes.length; i < len; i += 2) {\n        this.addSemanticType(genTypes[i], genTypes[i + 1])\n      }\n    } else {\n      for (const [k, v] of Object.entries(genTypes)) {\n        this.addSemanticType(k, v)\n      }\n    }\n  }\n\n  _transform(fresh, encoding, cb) {\n    const ret = this.pushAny(fresh)\n    // Old transformers might not return bool.  undefined !== false\n    return cb((ret === false) ? new Error('Push Error') : undefined)\n  }\n\n  // eslint-disable-next-line class-methods-use-this\n  _flush(cb) {\n    return cb()\n  }\n\n  /**\n   * @param {number} val Number(0-255) to encode.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  _pushUInt8(val) {\n    const b = Buffer.allocUnsafe(1)\n    b.writeUInt8(val, 0)\n    return this.push(b)\n  }\n\n  /**\n   * @param {number} val Number(0-65535) to encode.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  _pushUInt16BE(val) {\n    const b = Buffer.allocUnsafe(2)\n    b.writeUInt16BE(val, 0)\n    return this.push(b)\n  }\n\n  /**\n   * @param {number} val Number(0..2**32-1) to encode.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  _pushUInt32BE(val) {\n    const b = Buffer.allocUnsafe(4)\n    b.writeUInt32BE(val, 0)\n    return this.push(b)\n  }\n\n  /**\n   * @param {number} val Number to encode as 4-byte float.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  _pushFloatBE(val) {\n    const b = Buffer.allocUnsafe(4)\n    b.writeFloatBE(val, 0)\n    return this.push(b)\n  }\n\n  /**\n   * @param {number} val Number to encode as 8-byte double.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  _pushDoubleBE(val) {\n    const b = Buffer.allocUnsafe(8)\n    b.writeDoubleBE(val, 0)\n    return this.push(b)\n  }\n\n  /**\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  _pushNaN() {\n    return this.push(BUF_NAN)\n  }\n\n  /**\n   * @param {number} obj Positive or negative infinity.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  _pushInfinity(obj) {\n    const half = (obj < 0) ? BUF_INF_NEG : BUF_INF_POS\n    return this.push(half)\n  }\n\n  /**\n   * Choose the best float representation for a number and encode it.\n   *\n   * @param {number} obj A number that is known to be not-integer, but not\n   *    how many bytes of precision it needs.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  _pushFloat(obj) {\n    if (this.canonical) {\n      // TODO: is this enough slower to hide behind canonical?\n      // It's certainly enough of a hack (see utils.parseHalf)\n\n      // From section 3.9:\n      // If a protocol allows for IEEE floats, then additional canonicalization\n      // rules might need to be added.  One example rule might be to have all\n      // floats start as a 64-bit float, then do a test conversion to a 32-bit\n      // float; if the result is the same numeric value, use the shorter value\n      // and repeat the process with a test conversion to a 16-bit float.  (This\n      // rule selects 16-bit float for positive and negative Infinity as well.)\n\n      // which seems pretty much backwards to me.\n      const b2 = Buffer.allocUnsafe(2)\n      if (utils.writeHalf(b2, obj)) {\n        // I have convinced myself that there are no cases where writeHalf\n        // will return true but `utils.parseHalf(b2) !== obj)`\n        return this._pushUInt8(HALF) && this.push(b2)\n      }\n    }\n    if (Math.fround(obj) === obj) {\n      return this._pushUInt8(FLOAT) && this._pushFloatBE(obj)\n    }\n\n    return this._pushUInt8(DOUBLE) && this._pushDoubleBE(obj)\n  }\n\n  /**\n   * Choose the best integer representation for a postive number and encode\n   * it.  If the number is over MAX_SAFE_INTEGER, fall back on float (but I\n   * don't remember why).\n   *\n   * @param {number} obj A positive number that is known to be an integer,\n   *    but not how many bytes of precision it needs.\n   * @param {number} mt The Major Type number to combine with the integer.\n   *    Not yet shifted.\n   * @param {number} [orig] The number before it was transformed to positive.\n   *    If the mt is NEG_INT, and the positive number is over MAX_SAFE_INT,\n   *    then we'll encode this as a float rather than making the number\n   *    negative again and losing precision.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  _pushInt(obj, mt, orig) {\n    const m = mt << 5\n\n    if (obj < 24) {\n      return this._pushUInt8(m | obj)\n    }\n    if (obj <= 0xff) {\n      return this._pushUInt8(m | NUMBYTES.ONE) && this._pushUInt8(obj)\n    }\n    if (obj <= 0xffff) {\n      return this._pushUInt8(m | NUMBYTES.TWO) && this._pushUInt16BE(obj)\n    }\n    if (obj <= 0xffffffff) {\n      return this._pushUInt8(m | NUMBYTES.FOUR) && this._pushUInt32BE(obj)\n    }\n    let max = Number.MAX_SAFE_INTEGER\n    if (mt === MT.NEG_INT) {\n      // Special case for Number.MIN_SAFE_INTEGER - 1\n      max--\n    }\n    if (obj <= max) {\n      return this._pushUInt8(m | NUMBYTES.EIGHT) &&\n        this._pushUInt32BE(Math.floor(obj / SHIFT32)) &&\n        this._pushUInt32BE(obj % SHIFT32)\n    }\n    if (mt === MT.NEG_INT) {\n      return this._pushFloat(orig)\n    }\n    return this._pushFloat(obj)\n  }\n\n  /**\n   * Choose the best integer representation for a number and encode it.\n   *\n   * @param {number} obj A number that is known to be an integer,\n   *    but not how many bytes of precision it needs.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  _pushIntNum(obj) {\n    if (Object.is(obj, -0)) {\n      return this.push(BUF_NEG_ZERO)\n    }\n\n    if (obj < 0) {\n      return this._pushInt(-obj - 1, MT.NEG_INT, obj)\n    }\n    return this._pushInt(obj, MT.POS_INT)\n  }\n\n  /**\n   * @param {number} obj Plain JS number to encode.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  _pushNumber(obj) {\n    if (isNaN(obj)) {\n      return this._pushNaN()\n    }\n    if (!isFinite(obj)) {\n      return this._pushInfinity(obj)\n    }\n    if (Math.round(obj) === obj) {\n      return this._pushIntNum(obj)\n    }\n    return this._pushFloat(obj)\n  }\n\n  /**\n   * @param {string} obj String to encode.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  _pushString(obj) {\n    const len = Buffer.byteLength(obj, 'utf8')\n    return this._pushInt(len, MT.UTF8_STRING) && this.push(obj, 'utf8')\n  }\n\n  /**\n   * @param {boolean} obj Bool to encode.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  _pushBoolean(obj) {\n    return this._pushUInt8(obj ? TRUE : FALSE)\n  }\n\n  /**\n   * @param {undefined} obj Ignored.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  _pushUndefined(obj) {\n    switch (typeof this.encodeUndefined) {\n      case 'undefined':\n        return this._pushUInt8(UNDEFINED)\n      case 'function':\n        return this.pushAny(this.encodeUndefined(obj))\n      case 'object': {\n        const buf = utils.bufferishToBuffer(this.encodeUndefined)\n        if (buf) {\n          return this.push(buf)\n        }\n      }\n    }\n    return this.pushAny(this.encodeUndefined)\n  }\n\n  /**\n   * @param {null} obj Ignored.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  _pushNull(obj) {\n    return this._pushUInt8(NULL)\n  }\n\n  /**\n   * @param {number} tag Tag number to encode.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  _pushTag(tag) {\n    return this._pushInt(tag, MT.TAG)\n  }\n\n  /**\n   * @param {bigint} obj BigInt to encode.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  _pushJSBigint(obj) {\n    let m = MT.POS_INT\n    let tag = TAG.POS_BIGINT\n    // BigInt doesn't have -0\n    if (obj < 0) {\n      obj = -obj + BI.MINUS_ONE\n      m = MT.NEG_INT\n      tag = TAG.NEG_BIGINT\n    }\n\n    if (this.collapseBigIntegers &&\n        (obj <= BI.MAXINT64)) {\n      // Special handiling for 64bits\n      if (obj <= 0xffffffff) {\n        return this._pushInt(Number(obj), m)\n      }\n      return this._pushUInt8((m << 5) | NUMBYTES.EIGHT) &&\n        this._pushUInt32BE(Number(obj / BI.SHIFT32)) &&\n        this._pushUInt32BE(Number(obj % BI.SHIFT32))\n    }\n\n    let str = obj.toString(16)\n    if (str.length % 2) {\n      str = `0${str}`\n    }\n    const buf = Buffer.from(str, 'hex')\n    return this._pushTag(tag) && Encoder._pushBuffer(this, buf)\n  }\n\n  /**\n   * @param {object} obj Object to encode.\n   * @returns {boolean} True on success.\n   * @throws {Error} Loop detected.\n   * @ignore\n   */\n  _pushObject(obj, opts) {\n    if (!obj) {\n      return this._pushNull(obj)\n    }\n    opts = {\n      indefinite: false,\n      skipTypes: false,\n      ...opts,\n    }\n    if (!opts.indefinite) {\n      // This will only happen the first time through for indefinite encoding\n      if (this.detectLoops) {\n        if (this.detectLoops.has(obj)) {\n          throw new Error(`\\\nLoop detected while CBOR encoding.\nCall removeLoopDetectors before resuming.`)\n        } else {\n          this.detectLoops.add(obj)\n        }\n      }\n    }\n    if (!opts.skipTypes) {\n      const f = obj.encodeCBOR\n      if (typeof f === 'function') {\n        return f.call(obj, this)\n      }\n      const converter = this.semanticTypes[obj.constructor.name]\n      if (converter) {\n        return converter.call(obj, this, obj)\n      }\n    }\n    const keys = Object.keys(obj).filter(k => {\n      const tv = typeof obj[k]\n      return (tv !== 'function') &&\n        (!this.omitUndefinedProperties || (tv !== 'undefined'))\n    })\n    const cbor_keys = {}\n    if (this.canonical) {\n      // Note: this can't be a normal sort, because 'b' needs to sort before\n      // 'aa'\n      keys.sort((a, b) => {\n        // Always strings, so don't bother to pass options.\n        // hold on to the cbor versions, since there's no need\n        // to encode more than once\n        const a_cbor = cbor_keys[a] || (cbor_keys[a] = Encoder.encode(a))\n        const b_cbor = cbor_keys[b] || (cbor_keys[b] = Encoder.encode(b))\n\n        return a_cbor.compare(b_cbor)\n      })\n    }\n    if (opts.indefinite) {\n      if (!this._pushUInt8((MT.MAP << 5) | NUMBYTES.INDEFINITE)) {\n        return false\n      }\n    } else if (!this._pushInt(keys.length, MT.MAP)) {\n      return false\n    }\n    let ck = null\n    for (let j = 0, len2 = keys.length; j < len2; j++) {\n      const k = keys[j]\n      if (this.canonical && ((ck = cbor_keys[k]))) {\n        if (!this.push(ck)) { // Already a Buffer\n          return false\n        }\n      } else if (!this._pushString(k)) {\n        return false\n      }\n      if (!this.pushAny(obj[k])) {\n        return false\n      }\n    }\n    if (opts.indefinite) {\n      if (!this.push(BREAK)) {\n        return false\n      }\n    } else if (this.detectLoops) {\n      this.detectLoops.delete(obj)\n    }\n    return true\n  }\n\n  /**\n   * @param {any[]} objs Array of supported things.\n   * @returns {Buffer} Concatenation of encodings for the supported things.\n   * @ignore\n   */\n  _encodeAll(objs) {\n    const bs = new NoFilter({highWaterMark: this.readableHighWaterMark})\n    this.pipe(bs)\n    for (const o of objs) {\n      this.pushAny(o)\n    }\n    this.end()\n    return bs.read()\n  }\n\n  /**\n   * Add an encoding function to the list of supported semantic types.  This\n   * is useful for objects for which you can't add an encodeCBOR method.\n   *\n   * @param {string|Function} type The type to encode.\n   * @param {EncodeFunction} fun The encoder to use.\n   * @returns {EncodeFunction?} The previous encoder or undefined if there\n   *   wasn't one.\n   * @throws {TypeError} Invalid function.\n   */\n  addSemanticType(type, fun) {\n    const typeName = (typeof type === 'string') ? type : type.name\n    const old = this.semanticTypes[typeName]\n\n    if (fun) {\n      if (typeof fun !== 'function') {\n        throw new TypeError('fun must be of type function')\n      }\n      this.semanticTypes[typeName] = fun\n    } else if (old) {\n      delete this.semanticTypes[typeName]\n    }\n    return old\n  }\n\n  /**\n   * Push any supported type onto the encoded stream.\n   *\n   * @param {any} obj The thing to encode.\n   * @returns {boolean} True on success.\n   * @throws {TypeError} Unknown type for obj.\n   */\n  pushAny(obj) {\n    switch (typeof obj) {\n      case 'number':\n        return this._pushNumber(obj)\n      case 'bigint':\n        return this._pushJSBigint(obj)\n      case 'string':\n        return this._pushString(obj)\n      case 'boolean':\n        return this._pushBoolean(obj)\n      case 'undefined':\n        return this._pushUndefined(obj)\n      case 'object':\n        return this._pushObject(obj)\n      case 'symbol':\n        switch (obj) {\n          case SYMS.NULL:\n            return this._pushNull(null)\n          case SYMS.UNDEFINED:\n            return this._pushUndefined(undefined)\n          // TODO: Add pluggable support for other symbols\n          default:\n            throw new TypeError(`Unknown symbol: ${obj.toString()}`)\n        }\n      default:\n        throw new TypeError(\n          `Unknown type: ${typeof obj}, ${(typeof obj.toString === 'function') ? obj.toString() : ''}`\n        )\n    }\n  }\n\n  /**\n   * Encode an array and all of its elements.\n   *\n   * @param {Encoder} gen Encoder to use.\n   * @param {any[]} obj Array to encode.\n   * @param {object} [opts] Options.\n   * @param {boolean} [opts.indefinite=false] Use indefinite encoding?\n   * @returns {boolean} True on success.\n   */\n  static pushArray(gen, obj, opts) {\n    opts = {\n      indefinite: false,\n      ...opts,\n    }\n    const len = obj.length\n    if (opts.indefinite) {\n      if (!gen._pushUInt8((MT.ARRAY << 5) | NUMBYTES.INDEFINITE)) {\n        return false\n      }\n    } else if (!gen._pushInt(len, MT.ARRAY)) {\n      return false\n    }\n    for (let j = 0; j < len; j++) {\n      if (!gen.pushAny(obj[j])) {\n        return false\n      }\n    }\n    if (opts.indefinite) {\n      if (!gen.push(BREAK)) {\n        return false\n      }\n    }\n    return true\n  }\n\n  /**\n   * Remove the loop detector WeakSet for this Encoder.\n   *\n   * @returns {boolean} True when the Encoder was reset, else false.\n   */\n  removeLoopDetectors() {\n    if (!this.detectLoops) {\n      return false\n    }\n    this.detectLoops = new WeakSet()\n    return true\n  }\n\n  /**\n   * @param {Encoder} gen Encoder.\n   * @param {Date} obj Date to encode.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  static _pushDate(gen, obj) {\n    switch (gen.dateType) {\n      case 'string':\n        return gen._pushTag(TAG.DATE_STRING) &&\n          gen._pushString(obj.toISOString())\n      case 'int':\n        return gen._pushTag(TAG.DATE_EPOCH) &&\n          gen._pushIntNum(Math.round(obj.getTime() / 1000))\n      case 'float':\n        // Force float\n        return gen._pushTag(TAG.DATE_EPOCH) &&\n          gen._pushFloat(obj.getTime() / 1000)\n      case 'number':\n      default:\n        // If we happen to have an integral number of seconds,\n        // use integer.  Otherwise, use float.\n        return gen._pushTag(TAG.DATE_EPOCH) &&\n          gen.pushAny(obj.getTime() / 1000)\n    }\n  }\n\n  /**\n   * @param {Encoder} gen Encoder.\n   * @param {Buffer} obj Buffer to encode.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  static _pushBuffer(gen, obj) {\n    return gen._pushInt(obj.length, MT.BYTE_STRING) && gen.push(obj)\n  }\n\n  /**\n   * @param {Encoder} gen Encoder.\n   * @param {NoFilter} obj Buffer to encode.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  static _pushNoFilter(gen, obj) {\n    return Encoder._pushBuffer(gen, /** @type {Buffer} */ (obj.slice()))\n  }\n\n  /**\n   * @param {Encoder} gen Encoder.\n   * @param {RegExp} obj RegExp to encode.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  static _pushRegexp(gen, obj) {\n    return gen._pushTag(TAG.REGEXP) && gen.pushAny(obj.source)\n  }\n\n  /**\n   * @param {Encoder} gen Encoder.\n   * @param {Set} obj Set to encode.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  static _pushSet(gen, obj) {\n    if (!gen._pushTag(TAG.SET)) {\n      return false\n    }\n    if (!gen._pushInt(obj.size, MT.ARRAY)) {\n      return false\n    }\n    for (const x of obj) {\n      if (!gen.pushAny(x)) {\n        return false\n      }\n    }\n    return true\n  }\n\n  /**\n   * @param {Encoder} gen Encoder.\n   * @param {URL} obj URL to encode.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  static _pushURL(gen, obj) {\n    return gen._pushTag(TAG.URI) && gen.pushAny(obj.toString())\n  }\n\n  /**\n   * @param {Encoder} gen Encoder.\n   * @param {object} obj Boxed String, Number, or Boolean object to encode.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  static _pushBoxed(gen, obj) {\n    return gen.pushAny(obj.valueOf())\n  }\n\n  /**\n   * @param {Encoder} gen Encoder.\n   * @param {Map} obj Map to encode.\n   * @returns {boolean} True on success.\n   * @throws {Error} Map key that is undefined.\n   * @ignore\n   */\n  static _pushMap(gen, obj, opts) {\n    opts = {\n      indefinite: false,\n      ...opts,\n    }\n    let entries = [...obj.entries()]\n    if (gen.omitUndefinedProperties) {\n      entries = entries.filter(([k, v]) => v !== undefined)\n    }\n    if (opts.indefinite) {\n      if (!gen._pushUInt8((MT.MAP << 5) | NUMBYTES.INDEFINITE)) {\n        return false\n      }\n    } else if (!gen._pushInt(entries.length, MT.MAP)) {\n      return false\n    }\n    // Memoizing the cbor only helps in certain cases, and hurts in most\n    // others.  Just avoid it.\n    if (gen.canonical) {\n      // Keep the key/value pairs together, so we don't have to do odd\n      // gets with object keys later\n      const enc = new Encoder({\n        genTypes: gen.semanticTypes,\n        canonical: gen.canonical,\n        detectLoops: Boolean(gen.detectLoops), // Give enc its own loop detector\n        dateType: gen.dateType,\n        disallowUndefinedKeys: gen.disallowUndefinedKeys,\n        collapseBigIntegers: gen.collapseBigIntegers,\n      })\n      const bs = new NoFilter({highWaterMark: gen.readableHighWaterMark})\n      enc.pipe(bs)\n      entries.sort(([a], [b]) => {\n        // Both a and b are the keys\n        enc.pushAny(a)\n        const a_cbor = bs.read()\n        enc.pushAny(b)\n        const b_cbor = bs.read()\n        return a_cbor.compare(b_cbor)\n      })\n      for (const [k, v] of entries) {\n        if (gen.disallowUndefinedKeys && (typeof k === 'undefined')) {\n          throw new Error('Invalid Map key: undefined')\n        }\n        if (!(gen.pushAny(k) && gen.pushAny(v))) {\n          return false\n        }\n      }\n    } else {\n      for (const [k, v] of entries) {\n        if (gen.disallowUndefinedKeys && (typeof k === 'undefined')) {\n          throw new Error('Invalid Map key: undefined')\n        }\n        if (!(gen.pushAny(k) && gen.pushAny(v))) {\n          return false\n        }\n      }\n    }\n    if (opts.indefinite) {\n      if (!gen.push(BREAK)) {\n        return false\n      }\n    }\n    return true\n  }\n\n  /**\n   * @param {Encoder} gen Encoder.\n   * @param {NodeJS.TypedArray} obj Array to encode.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  static _pushTypedArray(gen, obj) {\n    // See https://tools.ietf.org/html/rfc8746\n\n    let typ = 0b01000000\n    let sz = obj.BYTES_PER_ELEMENT\n    const {name} = obj.constructor\n\n    if (name.startsWith('Float')) {\n      typ |= 0b00010000\n      sz /= 2\n    } else if (!name.includes('U')) {\n      typ |= 0b00001000\n    }\n    if (name.includes('Clamped') || ((sz !== 1) && !utils.isBigEndian())) {\n      typ |= 0b00000100\n    }\n    typ |= {\n      1: 0b00,\n      2: 0b01,\n      4: 0b10,\n      8: 0b11,\n    }[sz]\n    if (!gen._pushTag(typ)) {\n      return false\n    }\n    return Encoder._pushBuffer(\n      gen,\n      Buffer.from(obj.buffer, obj.byteOffset, obj.byteLength)\n    )\n  }\n\n  /**\n   * @param {Encoder} gen Encoder.\n   * @param { ArrayBuffer } obj Array to encode.\n   * @returns {boolean} True on success.\n   * @ignore\n   */\n  static _pushArrayBuffer(gen, obj) {\n    return Encoder._pushBuffer(gen, Buffer.from(obj))\n  }\n\n  /**\n   * Encode the given object with indefinite length.  There are apparently\n   * some (IMO) broken implementations of poorly-specified protocols that\n   * REQUIRE indefinite-encoding.  See the example for how to add this as an\n   * `encodeCBOR` function to an object or class to get indefinite encoding.\n   *\n   * @param {Encoder} gen The encoder to use.\n   * @param {string|Buffer|Array|Map|object} [obj] The object to encode.  If\n   *   null, use \"this\" instead.\n   * @param {EncodingOptions} [options={}] Options for encoding.\n   * @returns {boolean} True on success.\n   * @throws {Error} No object to encode or invalid indefinite encoding.\n   * @example <caption>Force indefinite encoding:</caption>\n   * const o = {\n   *   a: true,\n   *   encodeCBOR: cbor.Encoder.encodeIndefinite,\n   * }\n   * const m = []\n   * m.encodeCBOR = cbor.Encoder.encodeIndefinite\n   * cbor.encodeOne([o, m])\n   */\n  static encodeIndefinite(gen, obj, options = {}) {\n    if (obj == null) {\n      if (this == null) {\n        throw new Error('No object to encode')\n      }\n      obj = this\n    }\n\n    // TODO: consider other options\n    const {chunkSize = 4096} = options\n\n    let ret = true\n    const objType = typeof obj\n    let buf = null\n    if (objType === 'string') {\n      // TODO: make sure not to split surrogate pairs at the edges of chunks,\n      // since such half-surrogates cannot be legally encoded as UTF-8.\n      ret = ret && gen._pushUInt8((MT.UTF8_STRING << 5) | NUMBYTES.INDEFINITE)\n      let offset = 0\n      while (offset < obj.length) {\n        const endIndex = offset + chunkSize\n        ret = ret && gen._pushString(obj.slice(offset, endIndex))\n        offset = endIndex\n      }\n      ret = ret && gen.push(BREAK)\n    } else if ((buf = utils.bufferishToBuffer(obj))) {\n      ret = ret && gen._pushUInt8((MT.BYTE_STRING << 5) | NUMBYTES.INDEFINITE)\n      let offset = 0\n      while (offset < buf.length) {\n        const endIndex = offset + chunkSize\n        ret = ret && Encoder._pushBuffer(gen, buf.slice(offset, endIndex))\n        offset = endIndex\n      }\n      ret = ret && gen.push(BREAK)\n    } else if (Array.isArray(obj)) {\n      ret = ret && Encoder.pushArray(gen, obj, {\n        indefinite: true,\n      })\n    } else if (obj instanceof Map) {\n      ret = ret && Encoder._pushMap(gen, obj, {\n        indefinite: true,\n      })\n    } else {\n      if (objType !== 'object') {\n        throw new Error('Invalid indefinite encoding')\n      }\n      ret = ret && gen._pushObject(obj, {\n        indefinite: true,\n        skipTypes: true,\n      })\n    }\n    return ret\n  }\n\n  /**\n   * Encode one or more JavaScript objects, and return a Buffer containing the\n   * CBOR bytes.\n   *\n   * @param {...any} objs The objects to encode.\n   * @returns {Buffer} The encoded objects.\n   */\n  static encode(...objs) {\n    return new Encoder()._encodeAll(objs)\n  }\n\n  /**\n   * Encode one or more JavaScript objects canonically (slower!), and return\n   * a Buffer containing the CBOR bytes.\n   *\n   * @param {...any} objs The objects to encode.\n   * @returns {Buffer} The encoded objects.\n   */\n  static encodeCanonical(...objs) {\n    return new Encoder({\n      canonical: true,\n    })._encodeAll(objs)\n  }\n\n  /**\n   * Encode one JavaScript object using the given options.\n   *\n   * @static\n   * @param {any} obj The object to encode.\n   * @param {EncodingOptions} [options={}] Passed to the Encoder constructor.\n   * @returns {Buffer} The encoded objects.\n   */\n  static encodeOne(obj, options) {\n    return new Encoder(options)._encodeAll([obj])\n  }\n\n  /**\n   * Encode one JavaScript object using the given options in a way that\n   * is more resilient to objects being larger than the highWaterMark\n   * number of bytes.  As with the other static encode functions, this\n   * will still use a large amount of memory.  Use a stream-based approach\n   * directly if you need to process large and complicated inputs.\n   *\n   * @param {any} obj The object to encode.\n   * @param {EncodingOptions} [options={}] Passed to the Encoder constructor.\n   * @returns {Promise<Buffer>} A promise for the encoded buffer.\n   */\n  static encodeAsync(obj, options) {\n    return new Promise((resolve, reject) => {\n      const bufs = []\n      const enc = new Encoder(options)\n      enc.on('data', buf => bufs.push(buf))\n      enc.on('error', reject)\n      enc.on('finish', () => resolve(Buffer.concat(bufs)))\n      enc.pushAny(obj)\n      enc.end()\n    })\n  }\n\n  /**\n   * The currently supported set of semantic types.  May be modified by plugins.\n   *\n   * @type {SemanticMap}\n   */\n  static get SEMANTIC_TYPES() {\n    return current_SEMANTIC_TYPES\n  }\n\n  static set SEMANTIC_TYPES(val) {\n    current_SEMANTIC_TYPES = val\n  }\n\n  /**\n   * Reset the supported semantic types to the original set, before any\n   * plugins modified the list.\n   */\n  static reset() {\n    Encoder.SEMANTIC_TYPES = {...SEMANTIC_TYPES}\n  }\n}\n\nObject.assign(SEMANTIC_TYPES, {\n  Array: Encoder.pushArray,\n  Date: Encoder._pushDate,\n  Buffer: Encoder._pushBuffer,\n  [Buffer.name]: Encoder._pushBuffer, // Might be mangled\n  Map: Encoder._pushMap,\n  NoFilter: Encoder._pushNoFilter,\n  [NoFilter.name]: Encoder._pushNoFilter, // Mßight be mangled\n  RegExp: Encoder._pushRegexp,\n  Set: Encoder._pushSet,\n  ArrayBuffer: Encoder._pushArrayBuffer,\n  Uint8ClampedArray: Encoder._pushTypedArray,\n  Uint8Array: Encoder._pushTypedArray,\n  Uint16Array: Encoder._pushTypedArray,\n  Uint32Array: Encoder._pushTypedArray,\n  Int8Array: Encoder._pushTypedArray,\n  Int16Array: Encoder._pushTypedArray,\n  Int32Array: Encoder._pushTypedArray,\n  Float32Array: Encoder._pushTypedArray,\n  Float64Array: Encoder._pushTypedArray,\n  URL: Encoder._pushURL,\n  Boolean: Encoder._pushBoxed,\n  Number: Encoder._pushBoxed,\n  String: Encoder._pushBoxed,\n})\n\n// Safari needs to get better.\nif (typeof BigUint64Array !== 'undefined') {\n  SEMANTIC_TYPES[BigUint64Array.name] = Encoder._pushTypedArray\n}\nif (typeof BigInt64Array !== 'undefined') {\n  SEMANTIC_TYPES[BigInt64Array.name] = Encoder._pushTypedArray\n}\n\nEncoder.reset()\nmodule.exports = Encoder\n\n\n//# sourceURL=webpack://dapp/./node_modules/cbor/lib/encoder.js?");

/***/ }),

/***/ "./node_modules/cbor/lib/map.js":
/*!**************************************!*\
  !*** ./node_modules/cbor/lib/map.js ***!
  \**************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst {Buffer} = __webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\")\nconst encoder = __webpack_require__(/*! ./encoder */ \"./node_modules/cbor/lib/encoder.js\")\nconst decoder = __webpack_require__(/*! ./decoder */ \"./node_modules/cbor/lib/decoder.js\")\nconst {MT} = __webpack_require__(/*! ./constants */ \"./node_modules/cbor/lib/constants.js\")\n\n/**\n * Wrapper around a JavaScript Map object that allows the keys to be\n * any complex type.  The base Map object allows this, but will only\n * compare the keys by identity, not by value.  CborMap translates keys\n * to CBOR first (and base64's them to ensure by-value comparison).\n *\n * This is not a subclass of Object, because it would be tough to get\n * the semantics to be an exact match.\n *\n * @extends Map\n */\nclass CborMap extends Map {\n  /**\n   * Creates an instance of CborMap.\n   *\n   * @param {Iterable<any>} [iterable] An Array or other iterable\n   *   object whose elements are key-value pairs (arrays with two elements, e.g.\n   *   <code>[[ 1, 'one' ],[ 2, 'two' ]]</code>). Each key-value pair is added\n   *   to the new CborMap; null values are treated as undefined.\n   */\n  constructor(iterable) {\n    super(iterable)\n  }\n\n  /**\n   * @ignore\n   */\n  static _encode(key) {\n    return encoder.encodeCanonical(key).toString('base64')\n  }\n\n  /**\n   * @ignore\n   */\n  static _decode(key) {\n    return decoder.decodeFirstSync(key, 'base64')\n  }\n\n  /**\n   * Retrieve a specified element.\n   *\n   * @param {any} key The key identifying the element to retrieve.\n   *   Can be any type, which will be serialized into CBOR and compared by\n   *   value.\n   * @returns {any} The element if it exists, or <code>undefined</code>.\n   */\n  get(key) {\n    return super.get(CborMap._encode(key))\n  }\n\n  /**\n   * Adds or updates an element with a specified key and value.\n   *\n   * @param {any} key The key identifying the element to store.\n   *   Can be any type, which will be serialized into CBOR and compared by\n   *   value.\n   * @param {any} val The element to store.\n   * @returns {this} This object.\n   */\n  set(key, val) {\n    return super.set(CborMap._encode(key), val)\n  }\n\n  /**\n   * Removes the specified element.\n   *\n   * @param {any} key The key identifying the element to delete. Can be any\n   *   type, which will be serialized into CBOR and compared by value.\n   * @returns {boolean} True if an element in the Map object existed and has\n   *   been removed, or false if the element does not exist.\n   */\n  delete(key) {\n    return super.delete(CborMap._encode(key))\n  }\n\n  /**\n   * Does an element with the specified key exist?\n   *\n   * @param {any} key The key identifying the element to check.\n   *   Can be any type, which will be serialized into CBOR and compared by\n   *   value.\n   * @returns {boolean} True if an element with the specified key exists in\n   *   the Map object; otherwise false.\n   */\n  has(key) {\n    return super.has(CborMap._encode(key))\n  }\n\n  /**\n   * Returns a new Iterator object that contains the keys for each element\n   * in the Map object in insertion order.  The keys are decoded into their\n   * original format.\n   *\n   * @yields {any} The keys of the map.\n   */\n  *keys() {\n    for (const k of super.keys()) {\n      yield CborMap._decode(k)\n    }\n  }\n\n  /* eslint-disable jsdoc/require-returns-check */\n  /**\n   * Returns a new Iterator object that contains the [key, value] pairs for\n   * each element in the Map object in insertion order.\n   *\n   * @yields {any[]} Key value pairs.\n   * @returns {IterableIterator<any, any>} Key value pairs.\n   */\n  *entries() {\n    for (const kv of super.entries()) {\n      yield [CborMap._decode(kv[0]), kv[1]]\n    }\n  }\n  /* eslint-enable jsdoc/require-returns-check */\n\n  /**\n   * Returns a new Iterator object that contains the [key, value] pairs for\n   * each element in the Map object in insertion order.\n   *\n   * @returns {IterableIterator} Key value pairs.\n   */\n  [Symbol.iterator]() {\n    return this.entries()\n  }\n\n  /**\n   * Executes a provided function once per each key/value pair in the Map\n   * object, in insertion order.\n   *\n   * @param {function(any, any, Map): undefined} fun Function to execute for\n   *  each element, which takes a value, a key, and the Map being traversed.\n   * @param {any} thisArg Value to use as this when executing callback.\n   * @throws {TypeError} Invalid function.\n   */\n  forEach(fun, thisArg) {\n    if (typeof fun !== 'function') {\n      throw new TypeError('Must be function')\n    }\n    for (const kv of super.entries()) {\n      fun.call(this, kv[1], CborMap._decode(kv[0]), this)\n    }\n  }\n\n  /**\n   * Push the simple value onto the CBOR stream.\n   *\n   * @param {object} gen The generator to push onto.\n   * @returns {boolean} True on success.\n   */\n  encodeCBOR(gen) {\n    if (!gen._pushInt(this.size, MT.MAP)) {\n      return false\n    }\n    if (gen.canonical) {\n      const entries = Array.from(super.entries())\n        .map(kv => [Buffer.from(kv[0], 'base64'), kv[1]])\n      entries.sort((a, b) => a[0].compare(b[0]))\n      for (const kv of entries) {\n        if (!(gen.push(kv[0]) && gen.pushAny(kv[1]))) {\n          return false\n        }\n      }\n    } else {\n      for (const kv of super.entries()) {\n        if (!(gen.push(Buffer.from(kv[0], 'base64')) && gen.pushAny(kv[1]))) {\n          return false\n        }\n      }\n    }\n    return true\n  }\n}\n\nmodule.exports = CborMap\n\n\n//# sourceURL=webpack://dapp/./node_modules/cbor/lib/map.js?");

/***/ }),

/***/ "./node_modules/cbor/lib/simple.js":
/*!*****************************************!*\
  !*** ./node_modules/cbor/lib/simple.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst {MT, SIMPLE, SYMS} = __webpack_require__(/*! ./constants */ \"./node_modules/cbor/lib/constants.js\")\n\n/**\n * A CBOR Simple Value that does not map onto a known constant.\n */\nclass Simple {\n  /**\n   * Creates an instance of Simple.\n   *\n   * @param {number} value The simple value's integer value.\n   */\n  constructor(value) {\n    if (typeof value !== 'number') {\n      throw new Error(`Invalid Simple type: ${typeof value}`)\n    }\n    if ((value < 0) || (value > 255) || ((value | 0) !== value)) {\n      throw new Error(`value must be a small positive integer: ${value}`)\n    }\n    this.value = value\n  }\n\n  /**\n   * Debug string for simple value.\n   *\n   * @returns {string} Formated string of `simple(value)`.\n   */\n  toString() {\n    return `simple(${this.value})`\n  }\n\n  /**\n   * Debug string for simple value.\n   *\n   * @param {number} depth How deep are we?\n   * @param {object} opts Options.\n   * @returns {string} Formatted string of `simple(value)`.\n   */\n  [Symbol.for('nodejs.util.inspect.custom')](depth, opts) {\n    return `simple(${this.value})`\n  }\n\n  /**\n   * Push the simple value onto the CBOR stream.\n   *\n   * @param {object} gen The generator to push onto.\n   * @returns {boolean} True on success.\n   */\n  encodeCBOR(gen) {\n    return gen._pushInt(this.value, MT.SIMPLE_FLOAT)\n  }\n\n  /**\n   * Is the given object a Simple?\n   *\n   * @param {any} obj Object to test.\n   * @returns {boolean} Is it Simple?\n   */\n  static isSimple(obj) {\n    return obj instanceof Simple\n  }\n\n  /**\n   * Decode from the CBOR additional information into a JavaScript value.\n   * If the CBOR item has no parent, return a \"safe\" symbol instead of\n   * `null` or `undefined`, so that the value can be passed through a\n   * stream in object mode.\n   *\n   * @param {number} val The CBOR additional info to convert.\n   * @param {boolean} [has_parent=true] Does the CBOR item have a parent?\n   * @param {boolean} [parent_indefinite=false] Is the parent element\n   *   indefinitely encoded?\n   * @returns {(null|undefined|boolean|symbol|Simple)} The decoded value.\n   * @throws {Error} Invalid BREAK.\n   */\n  static decode(val, has_parent = true, parent_indefinite = false) {\n    switch (val) {\n      case SIMPLE.FALSE:\n        return false\n      case SIMPLE.TRUE:\n        return true\n      case SIMPLE.NULL:\n        if (has_parent) {\n          return null\n        }\n        return SYMS.NULL\n      case SIMPLE.UNDEFINED:\n        if (has_parent) {\n          return undefined\n        }\n        return SYMS.UNDEFINED\n      case -1:\n        if (!has_parent || !parent_indefinite) {\n          throw new Error('Invalid BREAK')\n        }\n        return SYMS.BREAK\n      default:\n        return new Simple(val)\n    }\n  }\n}\n\nmodule.exports = Simple\n\n\n//# sourceURL=webpack://dapp/./node_modules/cbor/lib/simple.js?");

/***/ }),

/***/ "./node_modules/cbor/lib/tagged.js":
/*!*****************************************!*\
  !*** ./node_modules/cbor/lib/tagged.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst constants = __webpack_require__(/*! ./constants */ \"./node_modules/cbor/lib/constants.js\")\nconst utils = __webpack_require__(/*! ./utils */ \"./node_modules/cbor/lib/utils.js\")\nconst INTERNAL_JSON = Symbol('INTERNAL_JSON')\n\nfunction setBuffersToJSON(obj, fn) {\n  // The data item tagged can be a byte string or any other data item.  In the\n  // latter case, the tag applies to all of the byte string data items\n  // contained in the data item, except for those contained in a nested data\n  // item tagged with an expected conversion.\n  if (utils.isBufferish(obj)) {\n    obj.toJSON = fn\n  } else if (Array.isArray(obj)) {\n    for (const v of obj) {\n      setBuffersToJSON(v, fn)\n    }\n  } else if (obj && (typeof obj === 'object')) {\n    // FFS, complexity in the protocol.\n\n    // There's some circular dependency in here.\n    // eslint-disable-next-line no-use-before-define\n    if (!(obj instanceof Tagged) || (obj.tag < 21) || (obj.tag > 23)) {\n      for (const v of Object.values(obj)) {\n        setBuffersToJSON(v, fn)\n      }\n    }\n  }\n}\n\nfunction b64this() {\n  // eslint-disable-next-line no-invalid-this\n  return utils.base64(this)\n}\n\nfunction b64urlThis() {\n  // eslint-disable-next-line no-invalid-this\n  return utils.base64url(this)\n}\n\nfunction hexThis() {\n  // eslint-disable-next-line no-invalid-this\n  return this.toString('hex')\n}\n\nfunction swapEndian(ab, size, byteOffset, byteLength) {\n  const dv = new DataView(ab)\n  const [getter, setter] = {\n    2: [dv.getUint16, dv.setUint16],\n    4: [dv.getUint32, dv.setUint32],\n    8: [dv.getBigUint64, dv.setBigUint64],\n  }[size]\n\n  const end = byteOffset + byteLength\n  for (let offset = byteOffset; offset < end; offset += size) {\n    setter.call(dv, offset, getter.call(dv, offset, true))\n  }\n}\n\n/**\n * Convert a tagged value to a more interesting JavaScript type.  Errors\n * thrown in this function will be captured into the \"err\" property of the\n * original Tagged instance.\n *\n * @callback TagFunction\n * @param {any} value The value inside the tag.\n * @param {Tagged} tag The enclosing Tagged instance; useful if you want to\n *   modify it and return it.  Also available as \"this\".\n * @returns {any} The transformed value.\n */\n\n/* eslint-disable jsdoc/check-types */\n/**\n * A mapping from tag number to a tag decoding function.\n *\n * @typedef {Object.<string, TagFunction>} TagMap\n */\n/* eslint-enable jsdoc/check-types */\n\n/**\n * @type {TagMap}\n * @private\n */\nconst TAGS = {\n  // Standard date/time string; see Section 3.4.1\n  0: v => new Date(v),\n  // Epoch-based date/time; see Section 3.4.2\n  1: v => new Date(v * 1000),\n  // Positive bignum; see Section 3.4.3\n  2: v => utils.bufferToBigInt(v),\n  // Negative bignum; see Section 3.4.3\n  3: v => constants.BI.MINUS_ONE - utils.bufferToBigInt(v),\n  // Expected conversion to base64url encoding; see Section 3.4.5.2\n  21: (v, tag) => {\n    if (utils.isBufferish(v)) {\n      tag[INTERNAL_JSON] = b64urlThis\n    } else {\n      setBuffersToJSON(v, b64urlThis)\n    }\n    return tag\n  },\n  // Expected conversion to base64 encoding; see Section 3.4.5.2\n  22: (v, tag) => {\n    if (utils.isBufferish(v)) {\n      tag[INTERNAL_JSON] = b64this\n    } else {\n      setBuffersToJSON(v, b64this)\n    }\n    return tag\n  },\n  // Expected conversion to base16 encoding; see Section Section 3.4.5.2\n  23: (v, tag) => {\n    if (utils.isBufferish(v)) {\n      tag[INTERNAL_JSON] = hexThis\n    } else {\n      setBuffersToJSON(v, hexThis)\n    }\n    return tag\n  },\n  // URI; see Section 3.4.5.3\n  32: v => new URL(v),\n  // Base64url; see Section 3.4.5.3\n  33: (v, tag) => {\n    // If any of the following apply:\n    // -  the encoded text string contains non-alphabet characters or\n    //    only 1 alphabet character in the last block of 4 (where\n    //    alphabet is defined by Section 5 of [RFC4648] for tag number 33\n    //    and Section 4 of [RFC4648] for tag number 34), or\n    if (!v.match(/^[a-zA-Z0-9_-]+$/)) {\n      throw new Error('Invalid base64url characters')\n    }\n    const last = v.length % 4\n    if (last === 1) {\n      throw new Error('Invalid base64url length')\n    }\n    // -  the padding bits in a 2- or 3-character block are not 0, or\n    if (last === 2) {\n      // The last 4 bits of the last character need to be zero.\n      if ('AQgw'.indexOf(v[v.length - 1]) === -1) {\n        throw new Error('Invalid base64 padding')\n      }\n    } else if (last === 3) {\n      // The last 2 bits of the last character need to be zero.\n      if ('AEIMQUYcgkosw048'.indexOf(v[v.length - 1]) === -1) {\n        throw new Error('Invalid base64 padding')\n      }\n    }\n\n    //    Or\n    // -  the base64url encoding has padding characters,\n    // (caught above)\n\n    // the string is invalid.\n    return tag\n  },\n  // Base64; see Section 3.4.5.3\n  34: (v, tag) => {\n    // If any of the following apply:\n    // -  the encoded text string contains non-alphabet characters or\n    //    only 1 alphabet character in the last block of 4 (where\n    //    alphabet is defined by Section 5 of [RFC4648] for tag number 33\n    //    and Section 4 of [RFC4648] for tag number 34), or\n    const m = v.match(/^[a-zA-Z0-9+/]+(?<padding>={0,2})$/)\n    if (!m) {\n      throw new Error('Invalid base64 characters')\n    }\n    if ((v.length % 4) !== 0) {\n      throw new Error('Invalid base64 length')\n    }\n    // -  the padding bits in a 2- or 3-character block are not 0, or\n    if (m.groups.padding === '=') {\n      // The last 4 bits of the last character need to be zero.\n      if ('AQgw'.indexOf(v[v.length - 2]) === -1) {\n        throw new Error('Invalid base64 padding')\n      }\n    } else if (m.groups.padding === '==') {\n      // The last 2 bits of the last character need to be zero.\n      if ('AEIMQUYcgkosw048'.indexOf(v[v.length - 3]) === -1) {\n        throw new Error('Invalid base64 padding')\n      }\n    }\n\n    // -  the base64 encoding has the wrong number of padding characters,\n    // (caught above)\n    // the string is invalid.\n    return tag\n  },\n  // Regular expression; see Section 2.4.4.3\n  35: v => new RegExp(v),\n  // https://github.com/input-output-hk/cbor-sets-spec/blob/master/CBOR_SETS.md\n  258: v => new Set(v),\n}\n\nconst TYPED_ARRAY_TAGS = {\n  64: Uint8Array,\n  65: Uint16Array,\n  66: Uint32Array,\n  // 67: BigUint64Array,  Safari doesn't implement\n  68: Uint8ClampedArray,\n  69: Uint16Array,\n  70: Uint32Array,\n  // 71: BigUint64Array,  Safari doesn't implement\n  72: Int8Array,\n  73: Int16Array,\n  74: Int32Array,\n  // 75: BigInt64Array,  Safari doesn't implement\n  // 76: reserved\n  77: Int16Array,\n  78: Int32Array,\n  // 79: BigInt64Array,  Safari doesn't implement\n  // 80: not implemented, float16 array\n  81: Float32Array,\n  82: Float64Array,\n  // 83: not implemented, float128 array\n  // 84: not implemented, float16 array\n  85: Float32Array,\n  86: Float64Array,\n  // 87: not implemented, float128 array\n}\n\n// Safari\nif (typeof BigUint64Array !== 'undefined') {\n  TYPED_ARRAY_TAGS[67] = BigUint64Array\n  TYPED_ARRAY_TAGS[71] = BigUint64Array\n}\nif (typeof BigInt64Array !== 'undefined') {\n  TYPED_ARRAY_TAGS[75] = BigInt64Array\n  TYPED_ARRAY_TAGS[79] = BigInt64Array\n}\n\nfunction _toTypedArray(val, tagged) {\n  if (!utils.isBufferish(val)) {\n    throw new TypeError('val not a buffer')\n  }\n  const {tag} = tagged\n  // See https://tools.ietf.org/html/rfc8746\n  const TypedClass = TYPED_ARRAY_TAGS[tag]\n  if (!TypedClass) {\n    throw new Error(`Invalid typed array tag: ${tag}`)\n  }\n  const little = tag & 0b00000100\n  const float = (tag & 0b00010000) >> 4\n  const sz = 2 ** (float + (tag & 0b00000011))\n\n  if ((!little !== utils.isBigEndian()) && (sz > 1)) {\n    swapEndian(val.buffer, sz, val.byteOffset, val.byteLength)\n  }\n\n  const ab = val.buffer.slice(val.byteOffset, val.byteOffset + val.byteLength)\n  return new TypedClass(ab)\n}\n\nfor (const n of Object.keys(TYPED_ARRAY_TAGS)) {\n  TAGS[n] = _toTypedArray\n}\n\n/**\n * @type {TagMap}\n * @private\n */\nlet current_TAGS = {}\n\n/**\n * A CBOR tagged item, where the tag does not have semantics specified at the\n * moment, or those semantics threw an error during parsing. Typically this will\n * be an extension point you're not yet expecting.\n */\nclass Tagged {\n  /**\n   * Creates an instance of Tagged.\n   *\n   * @param {number} tag The number of the tag.\n   * @param {any} value The value inside the tag.\n   * @param {Error} [err] The error that was thrown parsing the tag, or null.\n   */\n  constructor(tag, value, err) {\n    this.tag = tag\n    this.value = value\n    this.err = err\n    if (typeof this.tag !== 'number') {\n      throw new Error(`Invalid tag type (${typeof this.tag})`)\n    }\n    if ((this.tag < 0) || ((this.tag | 0) !== this.tag)) {\n      throw new Error(`Tag must be a positive integer: ${this.tag}`)\n    }\n  }\n\n  toJSON() {\n    if (this[INTERNAL_JSON]) {\n      return this[INTERNAL_JSON].call(this.value)\n    }\n    const ret = {\n      tag: this.tag,\n      value: this.value,\n    }\n    if (this.err) {\n      ret.err = this.err\n    }\n    return ret\n  }\n\n  /**\n   * Convert to a String.\n   *\n   * @returns {string} String of the form '1(2)'.\n   */\n  toString() {\n    return `${this.tag}(${JSON.stringify(this.value)})`\n  }\n\n  /**\n   * Push the simple value onto the CBOR stream.\n   *\n   * @param {object} gen The generator to push onto.\n   * @returns {boolean} True on success.\n   */\n  encodeCBOR(gen) {\n    gen._pushTag(this.tag)\n    return gen.pushAny(this.value)\n  }\n\n  /**\n   * If we have a converter for this type, do the conversion.  Some converters\n   * are built-in.  Additional ones can be passed in.  If you want to remove\n   * a built-in converter, pass a converter in whose value is 'null' instead\n   * of a function.\n   *\n   * @param {object} converters Keys in the object are a tag number, the value\n   *   is a function that takes the decoded CBOR and returns a JavaScript value\n   *   of the appropriate type.  Throw an exception in the function on errors.\n   * @returns {any} The converted item.\n   */\n  convert(converters) {\n    let f = (converters == null) ? undefined : converters[this.tag]\n    if (typeof f !== 'function') {\n      f = Tagged.TAGS[this.tag]\n      if (typeof f !== 'function') {\n        return this\n      }\n    }\n    try {\n      return f.call(this, this.value, this)\n    } catch (error) {\n      if (error && error.message && (error.message.length > 0)) {\n        this.err = error.message\n      } else {\n        this.err = error\n      }\n      return this\n    }\n  }\n\n  /**\n   * The current set of supported tags.  May be modified by plugins.\n   *\n   * @type {TagMap}\n   * @static\n   */\n  static get TAGS() {\n    return current_TAGS\n  }\n\n  static set TAGS(val) {\n    current_TAGS = val\n  }\n\n  /**\n   * Reset the supported tags to the original set, before any plugins modified\n   * the list.\n   */\n  static reset() {\n    Tagged.TAGS = {...TAGS}\n  }\n}\nTagged.INTERNAL_JSON = INTERNAL_JSON\nTagged.reset()\nmodule.exports = Tagged\n\n\n//# sourceURL=webpack://dapp/./node_modules/cbor/lib/tagged.js?");

/***/ }),

/***/ "./node_modules/cbor/lib/utils.js":
/*!****************************************!*\
  !*** ./node_modules/cbor/lib/utils.js ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nconst {Buffer} = __webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\")\nconst NoFilter = __webpack_require__(/*! nofilter */ \"./node_modules/nofilter/lib/index.js\")\nconst stream = __webpack_require__(/*! stream */ \"./node_modules/stream-browserify/index.js\")\nconst constants = __webpack_require__(/*! ./constants */ \"./node_modules/cbor/lib/constants.js\")\nconst {NUMBYTES, SHIFT32, BI, SYMS} = constants\nconst MAX_SAFE_HIGH = 0x1fffff\n\n/**\n * Convert a UTF8-encoded Buffer to a JS string.  If possible, throw an error\n * on invalid UTF8.  Byte Order Marks are not looked at or stripped.\n *\n * @private\n */\nconst td = new TextDecoder('utf8', {fatal: true, ignoreBOM: true})\nexports.utf8 = buf => td.decode(buf)\nexports.utf8.checksUTF8 = true\n\nfunction isReadable(s) {\n  // Is this a readable stream?  In the webpack version, instanceof isn't\n  // working correctly.\n  if (s instanceof stream.Readable) {\n    return true\n  }\n  return ['read', 'on', 'pipe'].every(f => typeof s[f] === 'function')\n}\n\nexports.isBufferish = function isBufferish(b) {\n  return b &&\n    (typeof b === 'object') &&\n    ((Buffer.isBuffer(b)) ||\n      (b instanceof Uint8Array) ||\n      (b instanceof Uint8ClampedArray) ||\n      (b instanceof ArrayBuffer) ||\n      (b instanceof DataView))\n}\n\nexports.bufferishToBuffer = function bufferishToBuffer(b) {\n  if (Buffer.isBuffer(b)) {\n    return b\n  } else if (ArrayBuffer.isView(b)) {\n    return Buffer.from(b.buffer, b.byteOffset, b.byteLength)\n  } else if (b instanceof ArrayBuffer) {\n    return Buffer.from(b)\n  }\n  return null\n}\n\nexports.parseCBORint = function parseCBORint(ai, buf) {\n  switch (ai) {\n    case NUMBYTES.ONE:\n      return buf.readUInt8(0)\n    case NUMBYTES.TWO:\n      return buf.readUInt16BE(0)\n    case NUMBYTES.FOUR:\n      return buf.readUInt32BE(0)\n    case NUMBYTES.EIGHT: {\n      const f = buf.readUInt32BE(0)\n      const g = buf.readUInt32BE(4)\n      if (f > MAX_SAFE_HIGH) {\n        return (BigInt(f) * BI.SHIFT32) + BigInt(g)\n      }\n      return (f * SHIFT32) + g\n    }\n    default:\n      throw new Error(`Invalid additional info for int: ${ai}`)\n  }\n}\n\nexports.writeHalf = function writeHalf(buf, half) {\n  // Assume 0, -0, NaN, Infinity, and -Infinity have already been caught\n\n  // HACK: everyone settle in.  This isn't going to be pretty.\n  // Translate cn-cbor's C code (from Carsten Borman):\n\n  // uint32_t be32;\n  // uint16_t be16, u16;\n  // union {\n  //   float f;\n  //   uint32_t u;\n  // } u32;\n  // u32.f = float_val;\n\n  const u32 = Buffer.allocUnsafe(4)\n  u32.writeFloatBE(half, 0)\n  const u = u32.readUInt32BE(0)\n\n  // If ((u32.u & 0x1FFF) == 0) { /* worth trying half */\n\n  // hildjj: If the lower 13 bits aren't 0,\n  // we will lose precision in the conversion.\n  // mant32 = 24bits, mant16 = 11bits, 24-11 = 13\n  if ((u & 0x1FFF) !== 0) {\n    return false\n  }\n\n  // Sign, exponent, mantissa\n  //   int s16 = (u32.u >> 16) & 0x8000;\n  //   int exp = (u32.u >> 23) & 0xff;\n  //   int mant = u32.u & 0x7fffff;\n\n  let s16 = (u >> 16) & 0x8000 // Top bit is sign\n  const exp = (u >> 23) & 0xff // Then 5 bits of exponent\n  const mant = u & 0x7fffff\n\n  // Hildjj: zeros already handled.  Assert if you don't believe me.\n  //   if (exp == 0 && mant == 0)\n  //     ;              /* 0.0, -0.0 */\n\n  //   else if (exp >= 113 && exp <= 142) /* normalized */\n  //     s16 += ((exp - 112) << 10) + (mant >> 13);\n\n  if ((exp >= 113) && (exp <= 142)) {\n    s16 += ((exp - 112) << 10) + (mant >> 13)\n  } else if ((exp >= 103) && (exp < 113)) {\n    // Denormalized numbers\n    //   else if (exp >= 103 && exp < 113) { /* denorm, exp16 = 0 */\n    //     if (mant & ((1 << (126 - exp)) - 1))\n    //       goto float32;         /* loss of precision */\n    //     s16 += ((mant + 0x800000) >> (126 - exp));\n\n    if (mant & ((1 << (126 - exp)) - 1)) {\n      return false\n    }\n    s16 += ((mant + 0x800000) >> (126 - exp))\n  } else {\n  //   } else if (exp == 255 && mant == 0) { /* Inf */\n  //     s16 += 0x7c00;\n\n    // hildjj: Infinity already handled\n\n    //   } else\n    //     goto float32;           /* loss of range */\n\n    return false\n  }\n\n  // Done\n  //   ensure_writable(3);\n  //   u16 = s16;\n  //   be16 = hton16p((const uint8_t*)&u16);\n  buf.writeUInt16BE(s16)\n  return true\n}\n\nexports.parseHalf = function parseHalf(buf) {\n  const sign = buf[0] & 0x80 ? -1 : 1\n  const exp = (buf[0] & 0x7C) >> 2\n  const mant = ((buf[0] & 0x03) << 8) | buf[1]\n  if (!exp) {\n    return sign * 5.9604644775390625e-8 * mant\n  } else if (exp === 0x1f) {\n    return sign * (mant ? NaN : Infinity)\n  }\n  return sign * (2 ** (exp - 25)) * (1024 + mant)\n}\n\nexports.parseCBORfloat = function parseCBORfloat(buf) {\n  switch (buf.length) {\n    case 2:\n      return exports.parseHalf(buf)\n    case 4:\n      return buf.readFloatBE(0)\n    case 8:\n      return buf.readDoubleBE(0)\n    default:\n      throw new Error(`Invalid float size: ${buf.length}`)\n  }\n}\n\nexports.hex = function hex(s) {\n  return Buffer.from(s.replace(/^0x/, ''), 'hex')\n}\n\nexports.bin = function bin(s) {\n  s = s.replace(/\\s/g, '')\n  let start = 0\n  let end = (s.length % 8) || 8\n  const chunks = []\n  while (end <= s.length) {\n    chunks.push(parseInt(s.slice(start, end), 2))\n    start = end\n    end += 8\n  }\n  return Buffer.from(chunks)\n}\n\nexports.arrayEqual = function arrayEqual(a, b) {\n  if ((a == null) && (b == null)) {\n    return true\n  }\n  if ((a == null) || (b == null)) {\n    return false\n  }\n  return (a.length === b.length) && a.every((elem, i) => elem === b[i])\n}\n\nexports.bufferToBigInt = function bufferToBigInt(buf) {\n  return BigInt(`0x${buf.toString('hex')}`)\n}\n\nexports.cborValueToString = function cborValueToString(val, float_bytes = -1) {\n  switch (typeof val) {\n    case 'symbol': {\n      switch (val) {\n        case SYMS.NULL:\n          return 'null'\n        case SYMS.UNDEFINED:\n          return 'undefined'\n        case SYMS.BREAK:\n          return 'BREAK'\n      }\n      // Impossible in node 10\n      /* istanbul ignore if */\n      if (val.description) {\n        return val.description\n      }\n      // On node10, Symbol doesn't have description.  Parse it out of the\n      // toString value, which looks like `Symbol(foo)`.\n      const s = val.toString()\n      const m = s.match(/^Symbol\\((?<name>.*)\\)/)\n      /* istanbul ignore if */\n      if (m && m.groups.name) {\n        // Impossible in node 12+\n        /* istanbul ignore next */\n        return m.groups.name\n      }\n      return 'Symbol'\n    }\n    case 'string':\n      return JSON.stringify(val)\n    case 'bigint':\n      return val.toString()\n    case 'number': {\n      const s = Object.is(val, -0) ? '-0' : String(val)\n      return (float_bytes > 0) ? `${s}_${float_bytes}` : s\n    }\n    case 'object': {\n      // A null should be caught above\n      const buf = exports.bufferishToBuffer(val)\n      if (buf) {\n        const hex = buf.toString('hex')\n        return (float_bytes === -Infinity) ? hex : `h'${hex}'`\n      }\n      if (typeof val[Symbol.for('nodejs.util.inspect.custom')] === 'function') {\n        return val[Symbol.for('nodejs.util.inspect.custom')]()\n      }\n      // Shouldn't get non-empty arrays here\n      if (Array.isArray(val)) {\n        return '[]'\n      }\n      // This should be all that is left\n      return '{}'\n    }\n  }\n  return String(val)\n}\n\nexports.guessEncoding = function guessEncoding(input, encoding) {\n  if (typeof input === 'string') {\n    return new NoFilter(input, (encoding == null) ? 'hex' : encoding)\n  }\n  const buf = exports.bufferishToBuffer(input)\n  if (buf) {\n    return new NoFilter(buf)\n  }\n  if (isReadable(input)) {\n    return input\n  }\n  throw new Error('Unknown input type')\n}\n\nconst B64URL_SWAPS = {\n  '=': '',\n  '+': '-',\n  '/': '_',\n}\n\n/**\n * @param {Buffer|Uint8Array|Uint8ClampedArray|ArrayBuffer|DataView} buf\n *   Buffer to convert.\n * @returns {string} Base64url string.\n * @private\n */\nexports.base64url = function base64url(buf) {\n  return exports.bufferishToBuffer(buf)\n    .toString('base64')\n    .replace(/[=+/]/g, c => B64URL_SWAPS[c])\n}\n\n/**\n * @param {Buffer|Uint8Array|Uint8ClampedArray|ArrayBuffer|DataView} buf\n *   Buffer to convert.\n * @returns {string} Base64 string.\n * @private\n */\nexports.base64 = function base64(buf) {\n  return exports.bufferishToBuffer(buf).toString('base64')\n}\n\nexports.isBigEndian = function isBigEndian() {\n  const array = new Uint8Array(4)\n  const view = new Uint32Array(array.buffer)\n  return !((view[0] = 1) & array[0])\n}\n\n\n//# sourceURL=webpack://dapp/./node_modules/cbor/lib/utils.js?");

/***/ }),

/***/ "./node_modules/cbor/vendor/binary-parse-stream/index.js":
/*!***************************************************************!*\
  !*** ./node_modules/cbor/vendor/binary-parse-stream/index.js ***!
  \***************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Tweaked version of nathan7's binary-parse-stream\n// (see https://github.com/nathan7/binary-parse-stream)\n// Uses NoFilter instead of the readable in the original.  Removes\n// the ability to read -1, which was odd and un-needed.\n// License for binary-parse-stream: MIT\n\n// binary-parse-stream is now unmaintained, so I have rewritten it as\n// more modern JS so I can get tsc to help check types.\n\n\nconst stream = __webpack_require__(/*! stream */ \"./node_modules/stream-browserify/index.js\")\nconst NoFilter = __webpack_require__(/*! nofilter */ \"./node_modules/nofilter/lib/index.js\")\n\n/**\n * BinaryParseStream is a TransformStream that consumes buffers and outputs\n * objects on the other end.  It expects your subclass to implement a `_parse`\n * method that is a generator.  When your generator yields a number, it'll be\n * fed a buffer of that length from the input.  When your generator returns,\n * the return value will be pushed to the output side.\n *\n * @extends stream.Transform\n */\nclass BinaryParseStream extends stream.Transform {\n  /**\n   * Creates an instance of BinaryParseStream.\n   *\n   * @param {stream.TransformOptions} options Stream options.\n   * @memberof BinaryParseStream\n   */\n  constructor(options) {\n    super(options)\n    // Doesn't work to pass these in as opts, for some reason\n    // also, work around typescript not knowing TransformStream internals\n    // eslint-disable-next-line dot-notation\n    this['_writableState'].objectMode = false\n    // eslint-disable-next-line dot-notation\n    this['_readableState'].objectMode = true\n\n    this.bs = new NoFilter()\n    this.__restart()\n  }\n\n  _transform(fresh, encoding, cb) {\n    this.bs.write(fresh)\n\n    while (this.bs.length >= this.__needed) {\n      let ret = null\n      const chunk = (this.__needed === null) ?\n        undefined :\n        this.bs.read(this.__needed)\n\n      try {\n        ret = this.__parser.next(chunk)\n      } catch (e) {\n        return cb(e)\n      }\n\n      if (this.__needed) {\n        this.__fresh = false\n      }\n\n      if (ret.done) {\n        this.push(ret.value)\n        this.__restart()\n      } else {\n        this.__needed = ret.value || Infinity\n      }\n    }\n\n    return cb()\n  }\n\n  /**\n   * Subclasses must override this to set their parsing behavior.  Yield a\n   * number to receive a Buffer of that many bytes.\n   *\n   * @abstract\n   * @returns {Generator<number, undefined, Buffer>}\n   */\n  /* istanbul ignore next */\n  *_parse() { // eslint-disable-line class-methods-use-this, require-yield\n    throw new Error('Must be implemented in subclass')\n  }\n\n  __restart() {\n    this.__needed = null\n    this.__parser = this._parse()\n    this.__fresh = true\n  }\n\n  _flush(cb) {\n    cb(this.__fresh ? null : new Error('unexpected end of input'))\n  }\n}\n\nmodule.exports = BinaryParseStream\n\n\n//# sourceURL=webpack://dapp/./node_modules/cbor/vendor/binary-parse-stream/index.js?");

/***/ }),

/***/ "./node_modules/events/events.js":
/*!***************************************!*\
  !*** ./node_modules/events/events.js ***!
  \***************************************/
/***/ ((module) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\nvar R = typeof Reflect === 'object' ? Reflect : null\nvar ReflectApply = R && typeof R.apply === 'function'\n  ? R.apply\n  : function ReflectApply(target, receiver, args) {\n    return Function.prototype.apply.call(target, receiver, args);\n  }\n\nvar ReflectOwnKeys\nif (R && typeof R.ownKeys === 'function') {\n  ReflectOwnKeys = R.ownKeys\n} else if (Object.getOwnPropertySymbols) {\n  ReflectOwnKeys = function ReflectOwnKeys(target) {\n    return Object.getOwnPropertyNames(target)\n      .concat(Object.getOwnPropertySymbols(target));\n  };\n} else {\n  ReflectOwnKeys = function ReflectOwnKeys(target) {\n    return Object.getOwnPropertyNames(target);\n  };\n}\n\nfunction ProcessEmitWarning(warning) {\n  if (console && console.warn) console.warn(warning);\n}\n\nvar NumberIsNaN = Number.isNaN || function NumberIsNaN(value) {\n  return value !== value;\n}\n\nfunction EventEmitter() {\n  EventEmitter.init.call(this);\n}\nmodule.exports = EventEmitter;\nmodule.exports.once = once;\n\n// Backwards-compat with node 0.10.x\nEventEmitter.EventEmitter = EventEmitter;\n\nEventEmitter.prototype._events = undefined;\nEventEmitter.prototype._eventsCount = 0;\nEventEmitter.prototype._maxListeners = undefined;\n\n// By default EventEmitters will print a warning if more than 10 listeners are\n// added to it. This is a useful default which helps finding memory leaks.\nvar defaultMaxListeners = 10;\n\nfunction checkListener(listener) {\n  if (typeof listener !== 'function') {\n    throw new TypeError('The \"listener\" argument must be of type Function. Received type ' + typeof listener);\n  }\n}\n\nObject.defineProperty(EventEmitter, 'defaultMaxListeners', {\n  enumerable: true,\n  get: function() {\n    return defaultMaxListeners;\n  },\n  set: function(arg) {\n    if (typeof arg !== 'number' || arg < 0 || NumberIsNaN(arg)) {\n      throw new RangeError('The value of \"defaultMaxListeners\" is out of range. It must be a non-negative number. Received ' + arg + '.');\n    }\n    defaultMaxListeners = arg;\n  }\n});\n\nEventEmitter.init = function() {\n\n  if (this._events === undefined ||\n      this._events === Object.getPrototypeOf(this)._events) {\n    this._events = Object.create(null);\n    this._eventsCount = 0;\n  }\n\n  this._maxListeners = this._maxListeners || undefined;\n};\n\n// Obviously not all Emitters should be limited to 10. This function allows\n// that to be increased. Set to zero for unlimited.\nEventEmitter.prototype.setMaxListeners = function setMaxListeners(n) {\n  if (typeof n !== 'number' || n < 0 || NumberIsNaN(n)) {\n    throw new RangeError('The value of \"n\" is out of range. It must be a non-negative number. Received ' + n + '.');\n  }\n  this._maxListeners = n;\n  return this;\n};\n\nfunction _getMaxListeners(that) {\n  if (that._maxListeners === undefined)\n    return EventEmitter.defaultMaxListeners;\n  return that._maxListeners;\n}\n\nEventEmitter.prototype.getMaxListeners = function getMaxListeners() {\n  return _getMaxListeners(this);\n};\n\nEventEmitter.prototype.emit = function emit(type) {\n  var args = [];\n  for (var i = 1; i < arguments.length; i++) args.push(arguments[i]);\n  var doError = (type === 'error');\n\n  var events = this._events;\n  if (events !== undefined)\n    doError = (doError && events.error === undefined);\n  else if (!doError)\n    return false;\n\n  // If there is no 'error' event listener then throw.\n  if (doError) {\n    var er;\n    if (args.length > 0)\n      er = args[0];\n    if (er instanceof Error) {\n      // Note: The comments on the `throw` lines are intentional, they show\n      // up in Node's output if this results in an unhandled exception.\n      throw er; // Unhandled 'error' event\n    }\n    // At least give some kind of context to the user\n    var err = new Error('Unhandled error.' + (er ? ' (' + er.message + ')' : ''));\n    err.context = er;\n    throw err; // Unhandled 'error' event\n  }\n\n  var handler = events[type];\n\n  if (handler === undefined)\n    return false;\n\n  if (typeof handler === 'function') {\n    ReflectApply(handler, this, args);\n  } else {\n    var len = handler.length;\n    var listeners = arrayClone(handler, len);\n    for (var i = 0; i < len; ++i)\n      ReflectApply(listeners[i], this, args);\n  }\n\n  return true;\n};\n\nfunction _addListener(target, type, listener, prepend) {\n  var m;\n  var events;\n  var existing;\n\n  checkListener(listener);\n\n  events = target._events;\n  if (events === undefined) {\n    events = target._events = Object.create(null);\n    target._eventsCount = 0;\n  } else {\n    // To avoid recursion in the case that type === \"newListener\"! Before\n    // adding it to the listeners, first emit \"newListener\".\n    if (events.newListener !== undefined) {\n      target.emit('newListener', type,\n                  listener.listener ? listener.listener : listener);\n\n      // Re-assign `events` because a newListener handler could have caused the\n      // this._events to be assigned to a new object\n      events = target._events;\n    }\n    existing = events[type];\n  }\n\n  if (existing === undefined) {\n    // Optimize the case of one listener. Don't need the extra array object.\n    existing = events[type] = listener;\n    ++target._eventsCount;\n  } else {\n    if (typeof existing === 'function') {\n      // Adding the second element, need to change to array.\n      existing = events[type] =\n        prepend ? [listener, existing] : [existing, listener];\n      // If we've already got an array, just append.\n    } else if (prepend) {\n      existing.unshift(listener);\n    } else {\n      existing.push(listener);\n    }\n\n    // Check for listener leak\n    m = _getMaxListeners(target);\n    if (m > 0 && existing.length > m && !existing.warned) {\n      existing.warned = true;\n      // No error code for this since it is a Warning\n      // eslint-disable-next-line no-restricted-syntax\n      var w = new Error('Possible EventEmitter memory leak detected. ' +\n                          existing.length + ' ' + String(type) + ' listeners ' +\n                          'added. Use emitter.setMaxListeners() to ' +\n                          'increase limit');\n      w.name = 'MaxListenersExceededWarning';\n      w.emitter = target;\n      w.type = type;\n      w.count = existing.length;\n      ProcessEmitWarning(w);\n    }\n  }\n\n  return target;\n}\n\nEventEmitter.prototype.addListener = function addListener(type, listener) {\n  return _addListener(this, type, listener, false);\n};\n\nEventEmitter.prototype.on = EventEmitter.prototype.addListener;\n\nEventEmitter.prototype.prependListener =\n    function prependListener(type, listener) {\n      return _addListener(this, type, listener, true);\n    };\n\nfunction onceWrapper() {\n  if (!this.fired) {\n    this.target.removeListener(this.type, this.wrapFn);\n    this.fired = true;\n    if (arguments.length === 0)\n      return this.listener.call(this.target);\n    return this.listener.apply(this.target, arguments);\n  }\n}\n\nfunction _onceWrap(target, type, listener) {\n  var state = { fired: false, wrapFn: undefined, target: target, type: type, listener: listener };\n  var wrapped = onceWrapper.bind(state);\n  wrapped.listener = listener;\n  state.wrapFn = wrapped;\n  return wrapped;\n}\n\nEventEmitter.prototype.once = function once(type, listener) {\n  checkListener(listener);\n  this.on(type, _onceWrap(this, type, listener));\n  return this;\n};\n\nEventEmitter.prototype.prependOnceListener =\n    function prependOnceListener(type, listener) {\n      checkListener(listener);\n      this.prependListener(type, _onceWrap(this, type, listener));\n      return this;\n    };\n\n// Emits a 'removeListener' event if and only if the listener was removed.\nEventEmitter.prototype.removeListener =\n    function removeListener(type, listener) {\n      var list, events, position, i, originalListener;\n\n      checkListener(listener);\n\n      events = this._events;\n      if (events === undefined)\n        return this;\n\n      list = events[type];\n      if (list === undefined)\n        return this;\n\n      if (list === listener || list.listener === listener) {\n        if (--this._eventsCount === 0)\n          this._events = Object.create(null);\n        else {\n          delete events[type];\n          if (events.removeListener)\n            this.emit('removeListener', type, list.listener || listener);\n        }\n      } else if (typeof list !== 'function') {\n        position = -1;\n\n        for (i = list.length - 1; i >= 0; i--) {\n          if (list[i] === listener || list[i].listener === listener) {\n            originalListener = list[i].listener;\n            position = i;\n            break;\n          }\n        }\n\n        if (position < 0)\n          return this;\n\n        if (position === 0)\n          list.shift();\n        else {\n          spliceOne(list, position);\n        }\n\n        if (list.length === 1)\n          events[type] = list[0];\n\n        if (events.removeListener !== undefined)\n          this.emit('removeListener', type, originalListener || listener);\n      }\n\n      return this;\n    };\n\nEventEmitter.prototype.off = EventEmitter.prototype.removeListener;\n\nEventEmitter.prototype.removeAllListeners =\n    function removeAllListeners(type) {\n      var listeners, events, i;\n\n      events = this._events;\n      if (events === undefined)\n        return this;\n\n      // not listening for removeListener, no need to emit\n      if (events.removeListener === undefined) {\n        if (arguments.length === 0) {\n          this._events = Object.create(null);\n          this._eventsCount = 0;\n        } else if (events[type] !== undefined) {\n          if (--this._eventsCount === 0)\n            this._events = Object.create(null);\n          else\n            delete events[type];\n        }\n        return this;\n      }\n\n      // emit removeListener for all listeners on all events\n      if (arguments.length === 0) {\n        var keys = Object.keys(events);\n        var key;\n        for (i = 0; i < keys.length; ++i) {\n          key = keys[i];\n          if (key === 'removeListener') continue;\n          this.removeAllListeners(key);\n        }\n        this.removeAllListeners('removeListener');\n        this._events = Object.create(null);\n        this._eventsCount = 0;\n        return this;\n      }\n\n      listeners = events[type];\n\n      if (typeof listeners === 'function') {\n        this.removeListener(type, listeners);\n      } else if (listeners !== undefined) {\n        // LIFO order\n        for (i = listeners.length - 1; i >= 0; i--) {\n          this.removeListener(type, listeners[i]);\n        }\n      }\n\n      return this;\n    };\n\nfunction _listeners(target, type, unwrap) {\n  var events = target._events;\n\n  if (events === undefined)\n    return [];\n\n  var evlistener = events[type];\n  if (evlistener === undefined)\n    return [];\n\n  if (typeof evlistener === 'function')\n    return unwrap ? [evlistener.listener || evlistener] : [evlistener];\n\n  return unwrap ?\n    unwrapListeners(evlistener) : arrayClone(evlistener, evlistener.length);\n}\n\nEventEmitter.prototype.listeners = function listeners(type) {\n  return _listeners(this, type, true);\n};\n\nEventEmitter.prototype.rawListeners = function rawListeners(type) {\n  return _listeners(this, type, false);\n};\n\nEventEmitter.listenerCount = function(emitter, type) {\n  if (typeof emitter.listenerCount === 'function') {\n    return emitter.listenerCount(type);\n  } else {\n    return listenerCount.call(emitter, type);\n  }\n};\n\nEventEmitter.prototype.listenerCount = listenerCount;\nfunction listenerCount(type) {\n  var events = this._events;\n\n  if (events !== undefined) {\n    var evlistener = events[type];\n\n    if (typeof evlistener === 'function') {\n      return 1;\n    } else if (evlistener !== undefined) {\n      return evlistener.length;\n    }\n  }\n\n  return 0;\n}\n\nEventEmitter.prototype.eventNames = function eventNames() {\n  return this._eventsCount > 0 ? ReflectOwnKeys(this._events) : [];\n};\n\nfunction arrayClone(arr, n) {\n  var copy = new Array(n);\n  for (var i = 0; i < n; ++i)\n    copy[i] = arr[i];\n  return copy;\n}\n\nfunction spliceOne(list, index) {\n  for (; index + 1 < list.length; index++)\n    list[index] = list[index + 1];\n  list.pop();\n}\n\nfunction unwrapListeners(arr) {\n  var ret = new Array(arr.length);\n  for (var i = 0; i < ret.length; ++i) {\n    ret[i] = arr[i].listener || arr[i];\n  }\n  return ret;\n}\n\nfunction once(emitter, name) {\n  return new Promise(function (resolve, reject) {\n    function errorListener(err) {\n      emitter.removeListener(name, resolver);\n      reject(err);\n    }\n\n    function resolver() {\n      if (typeof emitter.removeListener === 'function') {\n        emitter.removeListener('error', errorListener);\n      }\n      resolve([].slice.call(arguments));\n    };\n\n    eventTargetAgnosticAddListener(emitter, name, resolver, { once: true });\n    if (name !== 'error') {\n      addErrorHandlerIfEventEmitter(emitter, errorListener, { once: true });\n    }\n  });\n}\n\nfunction addErrorHandlerIfEventEmitter(emitter, handler, flags) {\n  if (typeof emitter.on === 'function') {\n    eventTargetAgnosticAddListener(emitter, 'error', handler, flags);\n  }\n}\n\nfunction eventTargetAgnosticAddListener(emitter, name, listener, flags) {\n  if (typeof emitter.on === 'function') {\n    if (flags.once) {\n      emitter.once(name, listener);\n    } else {\n      emitter.on(name, listener);\n    }\n  } else if (typeof emitter.addEventListener === 'function') {\n    // EventTarget does not have `error` event semantics like Node\n    // EventEmitters, we do not listen for `error` events here.\n    emitter.addEventListener(name, function wrapListener(arg) {\n      // IE does not have builtin `{ once: true }` support so we\n      // have to do it manually.\n      if (flags.once) {\n        emitter.removeEventListener(name, wrapListener);\n      }\n      listener(arg);\n    });\n  } else {\n    throw new TypeError('The \"emitter\" argument must be of type EventEmitter. Received type ' + typeof emitter);\n  }\n}\n\n\n//# sourceURL=webpack://dapp/./node_modules/events/events.js?");

/***/ }),

/***/ "./node_modules/nofilter/lib/index.js":
/*!********************************************!*\
  !*** ./node_modules/nofilter/lib/index.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst stream = __webpack_require__(/*! stream */ \"./node_modules/stream-browserify/index.js\")\nconst {Buffer} = __webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\")\nconst td = new TextDecoder('utf8', {fatal: true, ignoreBOM: true})\n\n/**\n * @typedef {object} NoFilterOptions\n * @property {string|Buffer} [input=null] Input source data.\n * @property {BufferEncoding} [inputEncoding=null] Encoding name for input,\n *   ignored if input is not a String.\n * @property {number} [highWaterMark=16384] The maximum number of bytes to\n *   store in the internal buffer before ceasing to read from the underlying\n *   resource. Default=16kb, or 16 for objectMode streams.\n * @property {BufferEncoding} [encoding=null] If specified, then buffers\n *   will be decoded to strings using the specified encoding.\n * @property {boolean} [objectMode=false] Whether this stream should behave\n *   as a stream of objects. Meaning that stream.read(n) returns a single\n *   value instead of a Buffer of size n.\n * @property {boolean} [decodeStrings=true] Whether or not to decode\n *   strings into Buffers before passing them to _write().\n * @property {boolean} [watchPipe=true] Whether to watch for 'pipe' events,\n *   setting this stream's objectMode based on the objectMode of the input\n *   stream.\n * @property {boolean} [readError=false] If true, when a read() underflows,\n *   throw an error.\n * @property {boolean} [allowHalfOpen=true] If set to false, then the\n *   stream will automatically end the writable side when the readable side\n *   ends.\n * @property {boolean} [autoDestroy=true] Whether this stream should\n *   automatically call .destroy() on itself after ending.\n * @property {BufferEncoding} [defaultEncoding='utf8'] The default encoding\n *   that is used when no encoding is specified as an argument to\n *   stream.write().\n * @property {boolean} [emitClose=true] Whether or not the stream should\n *   emit 'close' after it has been destroyed.\n * @property {number} [readableHighWaterMark] Sets highWaterMark for the\n *   readable side of the stream. Has no effect if highWaterMark is provided.\n * @property {boolean} [readableObjectMode=false] Sets objectMode for\n *   readable side of the stream. Has no effect if objectMode is true.\n * @property {number} [writableHighWaterMark] Sets highWaterMark for the\n *   writable side of the stream. Has no effect if highWaterMark is provided.\n * @property {boolean} [writableObjectMode=false] Sets objectMode for\n *   writable side of the stream. Has no effect if objectMode is true.\n */\n\n/**\n * NoFilter stream.  Can be used to sink or source data to and from\n * other node streams.  Implemented as the \"identity\" Transform stream\n * (hence the name), but allows for inspecting data that is in-flight.\n *\n * Allows passing in source data (input, inputEncoding) at creation\n * time.  Source data can also be passed in the options object.\n *\n * @example <caption>source and sink</caption>\n * const source = new NoFilter('Zm9v', 'base64')\n * source.pipe(process.stdout)\n * const sink = new Nofilter()\n * // NOTE: 'finish' fires when the input is done writing\n * sink.on('finish', () => console.log(n.toString('base64')))\n * process.stdin.pipe(sink)\n */\nclass NoFilter extends stream.Transform {\n  /**\n   * Create an instance of NoFilter.\n   *\n   * @param {string|Buffer|BufferEncoding|NoFilterOptions} [input] Source data.\n   * @param {BufferEncoding|NoFilterOptions} [inputEncoding] Encoding\n   *   name for input, ignored if input is not a String.\n   * @param {NoFilterOptions} [options] Other options.\n   */\n  constructor(input, inputEncoding, options = {}) {\n    let inp = null\n    let inpE = /** @type {BufferEncoding?} */ (null)\n    switch (typeof input) {\n      case 'object':\n        if (Buffer.isBuffer(input)) {\n          inp = input\n        } else if (input) {\n          options = input\n        }\n        break\n      case 'string':\n        inp = input\n        break\n      case 'undefined':\n        break\n      default:\n        throw new TypeError('Invalid input')\n    }\n    switch (typeof inputEncoding) {\n      case 'object':\n        if (inputEncoding) {\n          options = inputEncoding\n        }\n        break\n      case 'string':\n        inpE = /** @type {BufferEncoding} */ (inputEncoding)\n        break\n      case 'undefined':\n        break\n      default:\n        throw new TypeError('Invalid inputEncoding')\n    }\n    if (!options || typeof options !== 'object') {\n      throw new TypeError('Invalid options')\n    }\n    if (inp == null) {\n      inp = options.input\n    }\n    if (inpE == null) {\n      inpE = options.inputEncoding\n    }\n    delete options.input\n    delete options.inputEncoding\n    const watchPipe = options.watchPipe == null ? true : options.watchPipe\n    delete options.watchPipe\n    const readError = Boolean(options.readError)\n    delete options.readError\n    super(options)\n\n    this.readError = readError\n\n    if (watchPipe) {\n      this.on('pipe', readable => {\n        // @ts-ignore: TS2339 (using internal interface)\n        const om = readable._readableState.objectMode\n        // @ts-ignore: TS2339 (using internal interface)\n        if ((this.length > 0) && (om !== this._readableState.objectMode)) {\n          throw new Error(\n            'Do not switch objectMode in the middle of the stream'\n          )\n        }\n\n        // @ts-ignore: TS2339 (using internal interface)\n        this._readableState.objectMode = om\n        // @ts-ignore: TS2339 (using internal interface)\n        this._writableState.objectMode = om\n      })\n    }\n\n    if (inp != null) {\n      this.end(inp, inpE)\n    }\n  }\n\n  /**\n   * Is the given object a {NoFilter}?\n   *\n   * @param {object} obj The object to test.\n   * @returns {boolean} True if obj is a NoFilter.\n   */\n  static isNoFilter(obj) {\n    return obj instanceof this\n  }\n\n  /**\n   * The same as nf1.compare(nf2). Useful for sorting an Array of NoFilters.\n   *\n   * @param {NoFilter} nf1 The first object to compare.\n   * @param {NoFilter} nf2 The second object to compare.\n   * @returns {number} -1, 0, 1 for less, equal, greater.\n   * @throws {TypeError} Arguments not NoFilter instances.\n   * @example\n   * const arr = [new NoFilter('1234'), new NoFilter('0123')]\n   * arr.sort(NoFilter.compare)\n   */\n  static compare(nf1, nf2) {\n    if (!(nf1 instanceof this)) {\n      throw new TypeError('Arguments must be NoFilters')\n    }\n    if (nf1 === nf2) {\n      return 0\n    }\n    return nf1.compare(nf2)\n  }\n\n  /**\n   * Returns a buffer which is the result of concatenating all the\n   * NoFilters in the list together. If the list has no items, or if\n   * the totalLength is 0, then it returns a zero-length buffer.\n   *\n   * If length is not provided, it is read from the buffers in the\n   * list. However, this adds an additional loop to the function, so\n   * it is faster to provide the length explicitly if you already know it.\n   *\n   * @param {Array<NoFilter>} list Inputs.  Must not be all either in object\n   *   mode, or all not in object mode.\n   * @param {number} [length=null] Number of bytes or objects to read.\n   * @returns {Buffer|Array} The concatenated values as an array if in object\n   *   mode, otherwise a Buffer.\n   * @throws {TypeError} List not array of NoFilters.\n   */\n  static concat(list, length) {\n    if (!Array.isArray(list)) {\n      throw new TypeError('list argument must be an Array of NoFilters')\n    }\n    if ((list.length === 0) || (length === 0)) {\n      return Buffer.alloc(0)\n    }\n    if ((length == null)) {\n      length = list.reduce((tot, nf) => {\n        if (!(nf instanceof NoFilter)) {\n          throw new TypeError('list argument must be an Array of NoFilters')\n        }\n        return tot + nf.length\n      }, 0)\n    }\n    let allBufs = true\n    let allObjs = true\n    const bufs = list.map(nf => {\n      if (!(nf instanceof NoFilter)) {\n        throw new TypeError('list argument must be an Array of NoFilters')\n      }\n      const buf = nf.slice()\n      if (Buffer.isBuffer(buf)) {\n        allObjs = false\n      } else {\n        allBufs = false\n      }\n      return buf\n    })\n    if (allBufs) {\n      // @ts-ignore: TS2322, tsc can't see the type checking above\n      return Buffer.concat(bufs, length)\n    }\n    if (allObjs) {\n      return [].concat(...bufs).slice(0, length)\n    }\n    // TODO: maybe coalesce buffers, counting bytes, and flatten in arrays\n    // counting objects?  I can't imagine why that would be useful.\n    throw new Error('Concatenating mixed object and byte streams not supported')\n  }\n\n  /**\n   * @ignore\n   */\n  _transform(chunk, encoding, callback) {\n    // @ts-ignore: TS2339 (using internal interface)\n    if (!this._readableState.objectMode && !Buffer.isBuffer(chunk)) {\n      chunk = Buffer.from(chunk, encoding)\n    }\n    this.push(chunk)\n    callback()\n  }\n\n  /**\n   * @returns {Buffer[]} The current internal buffers.  They are layed out\n   *   end to end.\n   * @ignore\n   */\n  _bufArray() {\n    // @ts-ignore: TS2339 (using internal interface)\n    let bufs = this._readableState.buffer\n    // HACK: replace with something else one day.  This is what I get for\n    // relying on internals.\n    if (!Array.isArray(bufs)) {\n      let b = bufs.head\n      bufs = []\n      while (b != null) {\n        bufs.push(b.data)\n        b = b.next\n      }\n    }\n    return bufs\n  }\n\n  /**\n   * Pulls some data out of the internal buffer and returns it.\n   * If there is no data available, then it will return null.\n   *\n   * If you pass in a size argument, then it will return that many bytes. If\n   * size bytes are not available, then it will return null, unless we've\n   * ended, in which case it will return the data remaining in the buffer.\n   *\n   * If you do not specify a size argument, then it will return all the data in\n   * the internal buffer.\n   *\n   * @param {number} [size=null] Number of bytes to read.\n   * @returns {string|Buffer|null} If no data or not enough data, null.  If\n   *   decoding output a string, otherwise a Buffer.\n   * @throws Error If readError is true and there was underflow.\n   * @fires NoFilter#read When read from.\n   */\n  read(size) {\n    const buf = super.read(size)\n    if (buf != null) {\n      /**\n       * Read event. Fired whenever anything is read from the stream.\n       *\n       * @event NoFilter#read\n       * @param {Buffer|string|object} buf What was read.\n       */\n      this.emit('read', buf)\n      if (this.readError && (buf.length < size)) {\n        throw new Error(`Read ${buf.length}, wanted ${size}`)\n      }\n    } else if (this.readError) {\n      throw new Error(`No data available, wanted ${size}`)\n    }\n    return buf\n  }\n\n  /**\n   * Read the full number of bytes asked for, no matter how long it takes.\n   * Fail if an error occurs in the meantime, or if the stream finishes before\n   * enough data is available.\n   *\n   * Note: This function won't work fully correctly if you are using\n   * stream-browserify (for example, on the Web).\n   *\n   * @param {number} size The number of bytes to read.\n   * @returns {Promise<string|Buffer>} A promise for the data read.\n   */\n  readFull(size) {\n    let onReadable = null\n    let onFinish = null\n    let onError = null\n    return new Promise((resolve, reject) => {\n      if (this.length >= size) {\n        resolve(this.read(size))\n        return\n      }\n\n      // Added in Node 12.19.  This won't work with stream-browserify yet.\n      // If it's needed, file a bug, and I'll do a work-around.\n      if (this.writableFinished) {\n        // Already finished writing, so no more coming.\n        reject(new Error(`Stream finished before ${size} bytes were available`))\n        return\n      }\n\n      onReadable = chunk => {\n        if (this.length >= size) {\n          resolve(this.read(size))\n        }\n      }\n      onFinish = () => {\n        reject(new Error(`Stream finished before ${size} bytes were available`))\n      }\n      onError = reject\n      this.on('readable', onReadable)\n      this.on('error', onError)\n      this.on('finish', onFinish)\n    }).finally(() => {\n      if (onReadable) {\n        this.removeListener('readable', onReadable)\n        this.removeListener('error', onError)\n        this.removeListener('finish', onFinish)\n      }\n    })\n  }\n\n  /**\n   * Return a promise fulfilled with the full contents, after the 'finish'\n   * event fires.  Errors on the stream cause the promise to be rejected.\n   *\n   * @param {Function} [cb=null] Finished/error callback used in *addition*\n   *   to the promise.\n   * @returns {Promise<Buffer|string>} Fulfilled when complete.\n   */\n  promise(cb) {\n    let done = false\n    return new Promise((resolve, reject) => {\n      this.on('finish', () => {\n        const data = this.read()\n        if ((cb != null) && !done) {\n          done = true\n          cb(null, data)\n        }\n        resolve(data)\n      })\n      this.on('error', er => {\n        if ((cb != null) && !done) {\n          done = true\n          cb(er)\n        }\n        reject(er)\n      })\n    })\n  }\n\n  /**\n   * Returns a number indicating whether this comes before or after or is the\n   * same as the other NoFilter in sort order.\n   *\n   * @param {NoFilter} other The other object to compare.\n   * @returns {number} -1, 0, 1 for less, equal, greater.\n   * @throws {TypeError} Arguments must be NoFilters.\n   */\n  compare(other) {\n    if (!(other instanceof NoFilter)) {\n      throw new TypeError('Arguments must be NoFilters')\n    }\n    if (this === other) {\n      return 0\n    }\n\n    const buf1 = this.slice()\n    const buf2 = other.slice()\n    // These will both be buffers because of the check above.\n    if (Buffer.isBuffer(buf1) && Buffer.isBuffer(buf2)) {\n      return buf1.compare(buf2)\n    }\n    throw new Error('Cannot compare streams in object mode')\n  }\n\n  /**\n   * Do these NoFilter's contain the same bytes?  Doesn't work if either is\n   * in object mode.\n   *\n   * @param {NoFilter} other Other NoFilter to compare against.\n   * @returns {boolean} Equal?\n   */\n  equals(other) {\n    return this.compare(other) === 0\n  }\n\n  /**\n   * Read bytes or objects without consuming them.  Useful for diagnostics.\n   * Note: as a side-effect, concatenates multiple writes together into what\n   * looks like a single write, so that this concat doesn't have to happen\n   * multiple times when you're futzing with the same NoFilter.\n   *\n   * @param {number} [start=0] Beginning offset.\n   * @param {number} [end=length] Ending offset.\n   * @returns {Buffer|Array} If in object mode, an array of objects.  Otherwise,\n   *   concatenated array of contents.\n   */\n  slice(start, end) {\n    // @ts-ignore: TS2339 (using internal interface)\n    if (this._readableState.objectMode) {\n      return this._bufArray().slice(start, end)\n    }\n    const bufs = this._bufArray()\n    switch (bufs.length) {\n      case 0: return Buffer.alloc(0)\n      case 1: return bufs[0].slice(start, end)\n      default: {\n        const b = Buffer.concat(bufs)\n        // TODO: store the concatented bufs back\n        // @_readableState.buffer = [b]\n        return b.slice(start, end)\n      }\n    }\n  }\n\n  /**\n   * Get a byte by offset.  I didn't want to get into metaprogramming\n   * to give you the `NoFilter[0]` syntax.\n   *\n   * @param {number} index The byte to retrieve.\n   * @returns {number} 0-255.\n   */\n  get(index) {\n    return this.slice()[index]\n  }\n\n  /**\n   * Return an object compatible with Buffer's toJSON implementation, so that\n   * round-tripping will produce a Buffer.\n   *\n   * @returns {string|Array|{type: 'Buffer',data: number[]}} If in object mode,\n   *   the objects.  Otherwise, JSON text.\n   * @example <caption>output for 'foo', not in object mode</caption>\n   * ({\n   *   type: 'Buffer',\n   *   data: [102, 111, 111],\n   * })\n   */\n  toJSON() {\n    const b = this.slice()\n    if (Buffer.isBuffer(b)) {\n      return b.toJSON()\n    }\n    return b\n  }\n\n  /**\n   * Decodes and returns a string from buffer data encoded using the specified\n   * character set encoding. If encoding is undefined or null, then encoding\n   * defaults to 'utf8'. The start and end parameters default to 0 and\n   * NoFilter.length when undefined.\n   *\n   * @param {BufferEncoding} [encoding='utf8'] Which to use for decoding?\n   * @param {number} [start=0] Start offset.\n   * @param {number} [end=length] End offset.\n   * @returns {string} String version of the contents.\n   */\n  toString(encoding, start, end) {\n    const buf = this.slice(start, end)\n    if (!Buffer.isBuffer(buf)) {\n      return JSON.stringify(buf)\n    }\n    if (!encoding || (encoding === 'utf8')) {\n      return td.decode(buf)\n    }\n    return buf.toString(encoding)\n  }\n\n  /**\n   * @ignore\n   */\n  [Symbol.for('nodejs.util.inspect.custom')](depth, options) {\n    const bufs = this._bufArray()\n    const hex = bufs.map(b => {\n      if (Buffer.isBuffer(b)) {\n        return options.stylize(b.toString('hex'), 'string')\n      }\n      return JSON.stringify(b)\n    }).join(', ')\n    return `${this.constructor.name} [${hex}]`\n  }\n\n  /**\n   * Current readable length, in bytes.\n   *\n   * @returns {number} Length of the contents.\n   */\n  get length() {\n    // @ts-ignore: TS2339 (using internal interface)\n    return this._readableState.length\n  }\n\n  /**\n   * Write a JavaScript BigInt to the stream.  Negative numbers will be\n   * written as their 2's complement version.\n   *\n   * @param {bigint} val The value to write.\n   * @returns {boolean} True on success.\n   */\n  writeBigInt(val) {\n    let str = val.toString(16)\n    if (val < 0) {\n      // Two's complement\n      // Note: str always starts with '-' here.\n      const sz = BigInt(Math.floor(str.length / 2))\n      const mask = BigInt(1) << (sz * BigInt(8))\n      val = mask + val\n      str = val.toString(16)\n    }\n    if (str.length % 2) {\n      str = `0${str}`\n    }\n    return this.push(Buffer.from(str, 'hex'))\n  }\n\n  /**\n   * Read a variable-sized JavaScript unsigned BigInt from the stream.\n   *\n   * @param {number} [len=null] Number of bytes to read or all remaining\n   *   if null.\n   * @returns {bigint} A BigInt.\n   */\n  readUBigInt(len) {\n    const b = this.read(len)\n    if (!Buffer.isBuffer(b)) {\n      return null\n    }\n    return BigInt(`0x${b.toString('hex')}`)\n  }\n\n  /**\n   * Read a variable-sized JavaScript signed BigInt from the stream in 2's\n   * complement format.\n   *\n   * @param {number} [len=null] Number of bytes to read or all remaining\n   *   if null.\n   * @returns {bigint} A BigInt.\n   */\n  readBigInt(len) {\n    const b = this.read(len)\n    if (!Buffer.isBuffer(b)) {\n      return null\n    }\n    let ret = BigInt(`0x${b.toString('hex')}`)\n    // Negative?\n    if (b[0] & 0x80) {\n      // Two's complement\n      const mask = BigInt(1) << (BigInt(b.length) * BigInt(8))\n      ret -= mask\n    }\n    return ret\n  }\n\n  /**\n   * Write an 8-bit unsigned integer to the stream.  Adds 1 byte.\n   *\n   * @param {number} value 0..255.\n   * @returns {boolean} True on success.\n   */\n  writeUInt8(value) {\n    const b = Buffer.from([value])\n    return this.push(b)\n  }\n\n  /**\n   * Write a little-endian 16-bit unsigned integer to the stream.  Adds\n   * 2 bytes.\n   *\n   * @param {number} value 0..65535.\n   * @returns {boolean} True on success.\n   */\n  writeUInt16LE(value) {\n    const b = Buffer.alloc(2)\n    b.writeUInt16LE(value)\n    return this.push(b)\n  }\n\n  /**\n   * Write a big-endian 16-bit unsigned integer to the stream.  Adds\n   * 2 bytes.\n   *\n   * @param {number} value 0..65535.\n   * @returns {boolean} True on success.\n   */\n  writeUInt16BE(value) {\n    const b = Buffer.alloc(2)\n    b.writeUInt16BE(value)\n    return this.push(b)\n  }\n\n  /**\n   * Write a little-endian 32-bit unsigned integer to the stream.  Adds\n   * 4 bytes.\n   *\n   * @param {number} value 0..2**32-1.\n   * @returns {boolean} True on success.\n   */\n  writeUInt32LE(value) {\n    const b = Buffer.alloc(4)\n    b.writeUInt32LE(value)\n    return this.push(b)\n  }\n\n  /**\n   * Write a big-endian 32-bit unsigned integer to the stream.  Adds\n   * 4 bytes.\n   *\n   * @param {number} value 0..2**32-1.\n   * @returns {boolean} True on success.\n   */\n  writeUInt32BE(value) {\n    const b = Buffer.alloc(4)\n    b.writeUInt32BE(value)\n    return this.push(b)\n  }\n\n  /**\n   * Write a signed 8-bit integer to the stream.  Adds 1 byte.\n   *\n   * @param {number} value (-128)..127.\n   * @returns {boolean} True on success.\n   */\n  writeInt8(value) {\n    const b = Buffer.from([value])\n    return this.push(b)\n  }\n\n  /**\n   * Write a signed little-endian 16-bit integer to the stream.  Adds 2 bytes.\n   *\n   * @param {number} value (-32768)..32767.\n   * @returns {boolean} True on success.\n   */\n  writeInt16LE(value) {\n    const b = Buffer.alloc(2)\n    b.writeUInt16LE(value)\n    return this.push(b)\n  }\n\n  /**\n   * Write a signed big-endian 16-bit integer to the stream.  Adds 2 bytes.\n   *\n   * @param {number} value (-32768)..32767.\n   * @returns {boolean} True on success.\n   */\n  writeInt16BE(value) {\n    const b = Buffer.alloc(2)\n    b.writeUInt16BE(value)\n    return this.push(b)\n  }\n\n  /**\n   * Write a signed little-endian 32-bit integer to the stream.  Adds 4 bytes.\n   *\n   * @param {number} value (-2**31)..(2**31-1).\n   * @returns {boolean} True on success.\n   */\n  writeInt32LE(value) {\n    const b = Buffer.alloc(4)\n    b.writeUInt32LE(value)\n    return this.push(b)\n  }\n\n  /**\n   * Write a signed big-endian 32-bit integer to the stream.  Adds 4 bytes.\n   *\n   * @param {number} value (-2**31)..(2**31-1).\n   * @returns {boolean} True on success.\n   */\n  writeInt32BE(value) {\n    const b = Buffer.alloc(4)\n    b.writeUInt32BE(value)\n    return this.push(b)\n  }\n\n  /**\n   * Write a little-endian 32-bit float to the stream.  Adds 4 bytes.\n   *\n   * @param {number} value 32-bit float.\n   * @returns {boolean} True on success.\n   */\n  writeFloatLE(value) {\n    const b = Buffer.alloc(4)\n    b.writeFloatLE(value)\n    return this.push(b)\n  }\n\n  /**\n   * Write a big-endian 32-bit float to the stream.  Adds 4 bytes.\n   *\n   * @param {number} value 32-bit float.\n   * @returns {boolean} True on success.\n   */\n  writeFloatBE(value) {\n    const b = Buffer.alloc(4)\n    b.writeFloatBE(value)\n    return this.push(b)\n  }\n\n  /**\n   * Write a little-endian 64-bit double to the stream.  Adds 8 bytes.\n   *\n   * @param {number} value 64-bit float.\n   * @returns {boolean} True on success.\n   */\n  writeDoubleLE(value) {\n    const b = Buffer.alloc(8)\n    b.writeDoubleLE(value)\n    return this.push(b)\n  }\n\n  /**\n   * Write a big-endian 64-bit float to the stream.  Adds 8 bytes.\n   *\n   * @param {number} value 64-bit float.\n   * @returns {boolean} True on success.\n   */\n  writeDoubleBE(value) {\n    const b = Buffer.alloc(8)\n    b.writeDoubleBE(value)\n    return this.push(b)\n  }\n\n  /**\n   * Write a signed little-endian 64-bit BigInt to the stream.  Adds 8 bytes.\n   *\n   * @param {bigint} value BigInt.\n   * @returns {boolean} True on success.\n   */\n  writeBigInt64LE(value) {\n    const b = Buffer.alloc(8)\n    b.writeBigInt64LE(value)\n    return this.push(b)\n  }\n\n  /**\n   * Write a signed big-endian 64-bit BigInt to the stream.  Adds 8 bytes.\n   *\n   * @param {bigint} value BigInt.\n   * @returns {boolean} True on success.\n   */\n  writeBigInt64BE(value) {\n    const b = Buffer.alloc(8)\n    b.writeBigInt64BE(value)\n    return this.push(b)\n  }\n\n  /**\n   * Write an unsigned little-endian 64-bit BigInt to the stream.  Adds 8 bytes.\n   *\n   * @param {bigint} value Non-negative BigInt.\n   * @returns {boolean} True on success.\n   */\n  writeBigUInt64LE(value) {\n    const b = Buffer.alloc(8)\n    b.writeBigUInt64LE(value)\n    return this.push(b)\n  }\n\n  /**\n   * Write an unsigned big-endian 64-bit BigInt to the stream.  Adds 8 bytes.\n   *\n   * @param {bigint} value Non-negative BigInt.\n   * @returns {boolean} True on success.\n   */\n  writeBigUInt64BE(value) {\n    const b = Buffer.alloc(8)\n    b.writeBigUInt64BE(value)\n    return this.push(b)\n  }\n\n  /**\n   * Read an unsigned 8-bit integer from the stream.  Consumes 1 byte.\n   *\n   * @returns {number} Value read.\n   */\n  readUInt8() {\n    const b = this.read(1)\n    if (!Buffer.isBuffer(b)) {\n      return null\n    }\n    return b.readUInt8()\n  }\n\n  /**\n   * Read a little-endian unsigned 16-bit integer from the stream.\n   * Consumes 2 bytes.\n   *\n   * @returns {number} Value read.\n   */\n  readUInt16LE() {\n    const b = this.read(2)\n    if (!Buffer.isBuffer(b)) {\n      return null\n    }\n    return b.readUInt16LE()\n  }\n\n  /**\n   * Read a little-endian unsigned 16-bit integer from the stream.\n   * Consumes 2 bytes.\n   *\n   * @returns {number} Value read.\n   */\n  readUInt16BE() {\n    const b = this.read(2)\n    if (!Buffer.isBuffer(b)) {\n      return null\n    }\n    return b.readUInt16BE()\n  }\n\n  /**\n   * Read a little-endian unsigned 32-bit integer from the stream.\n   * Consumes 4 bytes.\n   *\n   * @returns {number} Value read.\n   */\n  readUInt32LE() {\n    const b = this.read(4)\n    if (!Buffer.isBuffer(b)) {\n      return null\n    }\n    return b.readUInt32LE()\n  }\n\n  /**\n   * Read a little-endian unsigned 16-bit integer from the stream.\n   * Consumes 4 bytes.\n   *\n   * @returns {number} Value read.\n   */\n  readUInt32BE() {\n    const b = this.read(4)\n    if (!Buffer.isBuffer(b)) {\n      return null\n    }\n    return b.readUInt32BE()\n  }\n\n  /**\n   * Read a signed 8-bit integer from the stream.  Consumes 1 byte.\n   *\n   * @returns {number} Value read.\n   */\n  readInt8() {\n    const b = this.read(1)\n    if (!Buffer.isBuffer(b)) {\n      return null\n    }\n    return b.readInt8()\n  }\n\n  /**\n   * Read a little-endian signed 16-bit integer from the stream.\n   * Consumes 2 bytes.\n   *\n   * @returns {number} Value read.\n   */\n  readInt16LE() {\n    const b = this.read(2)\n    if (!Buffer.isBuffer(b)) {\n      return null\n    }\n    return b.readInt16LE()\n  }\n\n  /**\n   * Read a little-endian signed 16-bit integer from the stream.\n   * Consumes 2 bytes.\n   *\n   * @returns {number} Value read.\n   */\n  readInt16BE() {\n    const b = this.read(2)\n    if (!Buffer.isBuffer(b)) {\n      return null\n    }\n    return b.readInt16BE()\n  }\n\n  /**\n   * Read a little-endian signed 32-bit integer from the stream.\n   * Consumes 4 bytes.\n   *\n   * @returns {number} Value read.\n   */\n  readInt32LE() {\n    const b = this.read(4)\n    if (!Buffer.isBuffer(b)) {\n      return null\n    }\n    return b.readInt32LE()\n  }\n\n  /**\n   * Read a little-endian signed 16-bit integer from the stream.\n   * Consumes 4 bytes.\n   *\n   * @returns {number} Value read.\n   */\n  readInt32BE() {\n    const b = this.read(4)\n    if (!Buffer.isBuffer(b)) {\n      return null\n    }\n    return b.readInt32BE()\n  }\n\n  /**\n   * Read a 32-bit little-endian float from the stream.\n   * Consumes 4 bytes.\n   *\n   * @returns {number} Value read.\n   */\n  readFloatLE() {\n    const b = this.read(4)\n    if (!Buffer.isBuffer(b)) {\n      return null\n    }\n    return b.readFloatLE()\n  }\n\n  /**\n   * Read a 32-bit big-endian float from the stream.\n   * Consumes 4 bytes.\n   *\n   * @returns {number} Value read.\n   */\n  readFloatBE() {\n    const b = this.read(4)\n    if (!Buffer.isBuffer(b)) {\n      return null\n    }\n    return b.readFloatBE()\n  }\n\n  /**\n   * Read a 64-bit little-endian float from the stream.\n   * Consumes 8 bytes.\n   *\n   * @returns {number} Value read.\n   */\n  readDoubleLE() {\n    const b = this.read(8)\n    if (!Buffer.isBuffer(b)) {\n      return null\n    }\n    return b.readDoubleLE()\n  }\n\n  /**\n   * Read a 64-bit big-endian float from the stream.\n   * Consumes 8 bytes.\n   *\n   * @returns {number} Value read.\n   */\n  readDoubleBE() {\n    const b = this.read(8)\n    if (!Buffer.isBuffer(b)) {\n      return null\n    }\n    return b.readDoubleBE()\n  }\n\n  /**\n   * Read a signed 64-bit little-endian BigInt from the stream.\n   * Consumes 8 bytes.\n   *\n   * @returns {bigint} Value read.\n   */\n  readBigInt64LE() {\n    const b = this.read(8)\n    if (!Buffer.isBuffer(b)) {\n      return null\n    }\n    return b.readBigInt64LE()\n  }\n\n  /**\n   * Read a signed 64-bit big-endian BigInt from the stream.\n   * Consumes 8 bytes.\n   *\n   * @returns {bigint} Value read.\n   */\n  readBigInt64BE() {\n    const b = this.read(8)\n    if (!Buffer.isBuffer(b)) {\n      return null\n    }\n    return b.readBigInt64BE()\n  }\n\n  /**\n   * Read an unsigned 64-bit little-endian BigInt from the stream.\n   * Consumes 8 bytes.\n   *\n   * @returns {bigint} Value read.\n   */\n  readBigUInt64LE() {\n    const b = this.read(8)\n    if (!Buffer.isBuffer(b)) {\n      return null\n    }\n    return b.readBigUInt64LE()\n  }\n\n  /**\n   * Read an unsigned 64-bit big-endian BigInt from the stream.\n   * Consumes 8 bytes.\n   *\n   * @returns {bigint} Value read.\n   */\n  readBigUInt64BE() {\n    const b = this.read(8)\n    if (!Buffer.isBuffer(b)) {\n      return null\n    }\n    return b.readBigUInt64BE()\n  }\n}\n\nmodule.exports = NoFilter\n\n\n//# sourceURL=webpack://dapp/./node_modules/nofilter/lib/index.js?");

/***/ }),

/***/ "./node_modules/readable-stream/errors-browser.js":
/*!********************************************************!*\
  !*** ./node_modules/readable-stream/errors-browser.js ***!
  \********************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nfunction _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\n\nvar codes = {};\n\nfunction createErrorType(code, message, Base) {\n  if (!Base) {\n    Base = Error;\n  }\n\n  function getMessage(arg1, arg2, arg3) {\n    if (typeof message === 'string') {\n      return message;\n    } else {\n      return message(arg1, arg2, arg3);\n    }\n  }\n\n  var NodeError =\n  /*#__PURE__*/\n  function (_Base) {\n    _inheritsLoose(NodeError, _Base);\n\n    function NodeError(arg1, arg2, arg3) {\n      return _Base.call(this, getMessage(arg1, arg2, arg3)) || this;\n    }\n\n    return NodeError;\n  }(Base);\n\n  NodeError.prototype.name = Base.name;\n  NodeError.prototype.code = code;\n  codes[code] = NodeError;\n} // https://github.com/nodejs/node/blob/v10.8.0/lib/internal/errors.js\n\n\nfunction oneOf(expected, thing) {\n  if (Array.isArray(expected)) {\n    var len = expected.length;\n    expected = expected.map(function (i) {\n      return String(i);\n    });\n\n    if (len > 2) {\n      return \"one of \".concat(thing, \" \").concat(expected.slice(0, len - 1).join(', '), \", or \") + expected[len - 1];\n    } else if (len === 2) {\n      return \"one of \".concat(thing, \" \").concat(expected[0], \" or \").concat(expected[1]);\n    } else {\n      return \"of \".concat(thing, \" \").concat(expected[0]);\n    }\n  } else {\n    return \"of \".concat(thing, \" \").concat(String(expected));\n  }\n} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/startsWith\n\n\nfunction startsWith(str, search, pos) {\n  return str.substr(!pos || pos < 0 ? 0 : +pos, search.length) === search;\n} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/endsWith\n\n\nfunction endsWith(str, search, this_len) {\n  if (this_len === undefined || this_len > str.length) {\n    this_len = str.length;\n  }\n\n  return str.substring(this_len - search.length, this_len) === search;\n} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/includes\n\n\nfunction includes(str, search, start) {\n  if (typeof start !== 'number') {\n    start = 0;\n  }\n\n  if (start + search.length > str.length) {\n    return false;\n  } else {\n    return str.indexOf(search, start) !== -1;\n  }\n}\n\ncreateErrorType('ERR_INVALID_OPT_VALUE', function (name, value) {\n  return 'The value \"' + value + '\" is invalid for option \"' + name + '\"';\n}, TypeError);\ncreateErrorType('ERR_INVALID_ARG_TYPE', function (name, expected, actual) {\n  // determiner: 'must be' or 'must not be'\n  var determiner;\n\n  if (typeof expected === 'string' && startsWith(expected, 'not ')) {\n    determiner = 'must not be';\n    expected = expected.replace(/^not /, '');\n  } else {\n    determiner = 'must be';\n  }\n\n  var msg;\n\n  if (endsWith(name, ' argument')) {\n    // For cases like 'first argument'\n    msg = \"The \".concat(name, \" \").concat(determiner, \" \").concat(oneOf(expected, 'type'));\n  } else {\n    var type = includes(name, '.') ? 'property' : 'argument';\n    msg = \"The \\\"\".concat(name, \"\\\" \").concat(type, \" \").concat(determiner, \" \").concat(oneOf(expected, 'type'));\n  }\n\n  msg += \". Received type \".concat(typeof actual);\n  return msg;\n}, TypeError);\ncreateErrorType('ERR_STREAM_PUSH_AFTER_EOF', 'stream.push() after EOF');\ncreateErrorType('ERR_METHOD_NOT_IMPLEMENTED', function (name) {\n  return 'The ' + name + ' method is not implemented';\n});\ncreateErrorType('ERR_STREAM_PREMATURE_CLOSE', 'Premature close');\ncreateErrorType('ERR_STREAM_DESTROYED', function (name) {\n  return 'Cannot call ' + name + ' after a stream was destroyed';\n});\ncreateErrorType('ERR_MULTIPLE_CALLBACK', 'Callback called multiple times');\ncreateErrorType('ERR_STREAM_CANNOT_PIPE', 'Cannot pipe, not readable');\ncreateErrorType('ERR_STREAM_WRITE_AFTER_END', 'write after end');\ncreateErrorType('ERR_STREAM_NULL_VALUES', 'May not write null values to stream', TypeError);\ncreateErrorType('ERR_UNKNOWN_ENCODING', function (arg) {\n  return 'Unknown encoding: ' + arg;\n}, TypeError);\ncreateErrorType('ERR_STREAM_UNSHIFT_AFTER_END_EVENT', 'stream.unshift() after end event');\nmodule.exports.codes = codes;\n\n\n//# sourceURL=webpack://dapp/./node_modules/readable-stream/errors-browser.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_duplex.js":
/*!************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_duplex.js ***!
  \************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\n\n\n/*<replacement>*/\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) keys.push(key);\n  return keys;\n};\n/*</replacement>*/\n\nmodule.exports = Duplex;\nvar Readable = __webpack_require__(/*! ./_stream_readable */ \"./node_modules/readable-stream/lib/_stream_readable.js\");\nvar Writable = __webpack_require__(/*! ./_stream_writable */ \"./node_modules/readable-stream/lib/_stream_writable.js\");\n__webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits_browser.js\")(Duplex, Readable);\n{\n  // Allow the keys array to be GC'ed.\n  var keys = objectKeys(Writable.prototype);\n  for (var v = 0; v < keys.length; v++) {\n    var method = keys[v];\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n  }\n}\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n  Readable.call(this, options);\n  Writable.call(this, options);\n  this.allowHalfOpen = true;\n  if (options) {\n    if (options.readable === false) this.readable = false;\n    if (options.writable === false) this.writable = false;\n    if (options.allowHalfOpen === false) {\n      this.allowHalfOpen = false;\n      this.once('end', onend);\n    }\n  }\n}\nObject.defineProperty(Duplex.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.highWaterMark;\n  }\n});\nObject.defineProperty(Duplex.prototype, 'writableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState && this._writableState.getBuffer();\n  }\n});\nObject.defineProperty(Duplex.prototype, 'writableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.length;\n  }\n});\n\n// the no-half-open enforcer\nfunction onend() {\n  // If the writable side ended, then we're ok.\n  if (this._writableState.ended) return;\n\n  // no more data can be written.\n  // But allow more writes to happen in this tick.\n  process.nextTick(onEndNT, this);\n}\nfunction onEndNT(self) {\n  self.end();\n}\nObject.defineProperty(Duplex.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed && this._writableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n    this._writableState.destroyed = value;\n  }\n});\n\n//# sourceURL=webpack://dapp/./node_modules/readable-stream/lib/_stream_duplex.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_passthrough.js":
/*!*****************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_passthrough.js ***!
  \*****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n\n\nmodule.exports = PassThrough;\nvar Transform = __webpack_require__(/*! ./_stream_transform */ \"./node_modules/readable-stream/lib/_stream_transform.js\");\n__webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits_browser.js\")(PassThrough, Transform);\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n  Transform.call(this, options);\n}\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};\n\n//# sourceURL=webpack://dapp/./node_modules/readable-stream/lib/_stream_passthrough.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_readable.js":
/*!**************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_readable.js ***!
  \**************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\nmodule.exports = Readable;\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n\n/*<replacement>*/\nvar EE = (__webpack_require__(/*! events */ \"./node_modules/events/events.js\").EventEmitter);\nvar EElistenerCount = function EElistenerCount(emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = __webpack_require__(/*! ./internal/streams/stream */ \"./node_modules/readable-stream/lib/internal/streams/stream-browser.js\");\n/*</replacement>*/\n\nvar Buffer = (__webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\").Buffer);\nvar OurUint8Array = (typeof __webpack_require__.g !== 'undefined' ? __webpack_require__.g : typeof window !== 'undefined' ? window : typeof self !== 'undefined' ? self : {}).Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*<replacement>*/\nvar debugUtil = __webpack_require__(/*! util */ \"?d17e\");\nvar debug;\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function debug() {};\n}\n/*</replacement>*/\n\nvar BufferList = __webpack_require__(/*! ./internal/streams/buffer_list */ \"./node_modules/readable-stream/lib/internal/streams/buffer_list.js\");\nvar destroyImpl = __webpack_require__(/*! ./internal/streams/destroy */ \"./node_modules/readable-stream/lib/internal/streams/destroy.js\");\nvar _require = __webpack_require__(/*! ./internal/streams/state */ \"./node_modules/readable-stream/lib/internal/streams/state.js\"),\n  getHighWaterMark = _require.getHighWaterMark;\nvar _require$codes = (__webpack_require__(/*! ../errors */ \"./node_modules/readable-stream/errors-browser.js\").codes),\n  ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,\n  ERR_STREAM_PUSH_AFTER_EOF = _require$codes.ERR_STREAM_PUSH_AFTER_EOF,\n  ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n  ERR_STREAM_UNSHIFT_AFTER_END_EVENT = _require$codes.ERR_STREAM_UNSHIFT_AFTER_END_EVENT;\n\n// Lazy loaded to improve the startup performance.\nvar StringDecoder;\nvar createReadableStreamAsyncIterator;\nvar from;\n__webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits_browser.js\")(Readable, Stream);\nvar errorOrDestroy = destroyImpl.errorOrDestroy;\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn);\n\n  // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (Array.isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\nfunction ReadableState(options, stream, isDuplex) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex;\n\n  // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n  this.objectMode = !!options.objectMode;\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode;\n\n  // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  this.highWaterMark = getHighWaterMark(this, options, 'readableHighWaterMark', isDuplex);\n\n  // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false;\n\n  // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n  this.sync = true;\n\n  // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n  this.paused = true;\n\n  // Should close be emitted on destroy. Defaults to true.\n  this.emitClose = options.emitClose !== false;\n\n  // Should .destroy() be called after 'end' (and potentially 'finish')\n  this.autoDestroy = !!options.autoDestroy;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // the number of writers that are awaiting a drain event in .pipe()s\n  this.awaitDrain = 0;\n\n  // if true, a maybeReadMore has been scheduled\n  this.readingMore = false;\n  this.decoder = null;\n  this.encoding = null;\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = (__webpack_require__(/*! string_decoder/ */ \"./node_modules/string_decoder/lib/string_decoder.js\").StringDecoder);\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\nfunction Readable(options) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n  if (!(this instanceof Readable)) return new Readable(options);\n\n  // Checking for a Stream.Duplex instance is faster here instead of inside\n  // the ReadableState constructor, at least with V8 6.5\n  var isDuplex = this instanceof Duplex;\n  this._readableState = new ReadableState(options, this, isDuplex);\n\n  // legacy\n  this.readable = true;\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n  Stream.call(this);\n}\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._readableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n  }\n});\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\nReadable.prototype._destroy = function (err, cb) {\n  cb(err);\n};\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n};\n\n// Unshift should *always* be something directly out of read()\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  debug('readableAddChunk', chunk);\n  var state = stream._readableState;\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n    if (er) {\n      errorOrDestroy(stream, er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n      if (addToFront) {\n        if (state.endEmitted) errorOrDestroy(stream, new ERR_STREAM_UNSHIFT_AFTER_END_EVENT());else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        errorOrDestroy(stream, new ERR_STREAM_PUSH_AFTER_EOF());\n      } else if (state.destroyed) {\n        return false;\n      } else {\n        state.reading = false;\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n      maybeReadMore(stream, state);\n    }\n  }\n\n  // We can push more data if we are below the highWaterMark.\n  // Also, if we have no data yet, we can stand some more bytes.\n  // This is to work around cases where hwm=0, such as the repl.\n  return !state.ended && (state.length < state.highWaterMark || state.length === 0);\n}\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    state.awaitDrain = 0;\n    stream.emit('data', chunk);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n    if (state.needReadable) emitReadable(stream);\n  }\n  maybeReadMore(stream, state);\n}\nfunction chunkInvalid(state, chunk) {\n  var er;\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer', 'Uint8Array'], chunk);\n  }\n  return er;\n}\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n};\n\n// backwards compatibility.\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = (__webpack_require__(/*! string_decoder/ */ \"./node_modules/string_decoder/lib/string_decoder.js\").StringDecoder);\n  var decoder = new StringDecoder(enc);\n  this._readableState.decoder = decoder;\n  // If setEncoding(null), decoder.encoding equals utf8\n  this._readableState.encoding = this._readableState.decoder.encoding;\n\n  // Iterate over current buffer to convert already stored Buffers:\n  var p = this._readableState.buffer.head;\n  var content = '';\n  while (p !== null) {\n    content += decoder.write(p.data);\n    p = p.next;\n  }\n  this._readableState.buffer.clear();\n  if (content !== '') this._readableState.buffer.push(content);\n  this._readableState.length = content.length;\n  return this;\n};\n\n// Don't raise the hwm > 1GB\nvar MAX_HWM = 0x40000000;\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    // TODO(ronag): Throw ERR_VALUE_OUT_OF_RANGE.\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n  return n;\n}\n\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  }\n  // If we're asking for more than the current hwm, then raise the hwm.\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n;\n  // Don't have enough\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n  return state.length;\n}\n\n// you can override either this method, or the async _read(n) below.\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n  if (n !== 0) state.emittedReadable = false;\n\n  // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 && state.needReadable && ((state.highWaterMark !== 0 ? state.length >= state.highWaterMark : state.length > 0) || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n  n = howMuchToRead(n, state);\n\n  // if we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  var doRead = state.needReadable;\n  debug('need readable', doRead);\n\n  // if we currently have less than the highWaterMark, then also read some\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  }\n\n  // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true;\n    // if the length is currently zero, then we *need* a readable event.\n    if (state.length === 0) state.needReadable = true;\n    // call internal read method\n    this._read(state.highWaterMark);\n    state.sync = false;\n    // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n  if (ret === null) {\n    state.needReadable = state.length <= state.highWaterMark;\n    n = 0;\n  } else {\n    state.length -= n;\n    state.awaitDrain = 0;\n  }\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true;\n\n    // If we tried to read() past the EOF, then emit end on the next tick.\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n  if (ret !== null) this.emit('data', ret);\n  return ret;\n};\nfunction onEofChunk(stream, state) {\n  debug('onEofChunk');\n  if (state.ended) return;\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n  if (state.sync) {\n    // if we are sync, wait until next tick to emit the data.\n    // Otherwise we risk emitting data in the flow()\n    // the readable code triggers during a read() call\n    emitReadable(stream);\n  } else {\n    // emit 'readable' now to make sure it gets picked up.\n    state.needReadable = false;\n    if (!state.emittedReadable) {\n      state.emittedReadable = true;\n      emitReadable_(stream);\n    }\n  }\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  debug('emitReadable', state.needReadable, state.emittedReadable);\n  state.needReadable = false;\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    process.nextTick(emitReadable_, stream);\n  }\n}\nfunction emitReadable_(stream) {\n  var state = stream._readableState;\n  debug('emitReadable_', state.destroyed, state.length, state.ended);\n  if (!state.destroyed && (state.length || state.ended)) {\n    stream.emit('readable');\n    state.emittedReadable = false;\n  }\n\n  // The stream needs another readable event if\n  // 1. It is not flowing, as the flow mechanism will take\n  //    care of it.\n  // 2. It is not ended.\n  // 3. It is below the highWaterMark, so we can schedule\n  //    another readable later.\n  state.needReadable = !state.flowing && !state.ended && state.length <= state.highWaterMark;\n  flow(stream);\n}\n\n// at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    process.nextTick(maybeReadMore_, stream, state);\n  }\n}\nfunction maybeReadMore_(stream, state) {\n  // Attempt to read more data if we should.\n  //\n  // The conditions for reading more data are (one of):\n  // - Not enough data buffered (state.length < state.highWaterMark). The loop\n  //   is responsible for filling the buffer with enough data if such data\n  //   is available. If highWaterMark is 0 and we are not in the flowing mode\n  //   we should _not_ attempt to buffer any extra data. We'll get more data\n  //   when the stream consumer calls read() instead.\n  // - No data in the buffer, and the stream is in flowing mode. In this mode\n  //   the loop below is responsible for ensuring read() is called. Failing to\n  //   call read here would abort the flow and there's no other mechanism for\n  //   continuing the flow if the stream consumer has just subscribed to the\n  //   'data' event.\n  //\n  // In addition to the above conditions to keep reading data, the following\n  // conditions prevent the data from being read:\n  // - The stream has ended (state.ended).\n  // - There is already a pending 'read' operation (state.reading). This is a\n  //   case where the the stream has called the implementation defined _read()\n  //   method, but they are processing the call asynchronously and have _not_\n  //   called push() with new data. In this case we skip performing more\n  //   read()s. The execution ends in this method again after the _read() ends\n  //   up calling push() with more data.\n  while (!state.reading && !state.ended && (state.length < state.highWaterMark || state.flowing && state.length === 0)) {\n    var len = state.length;\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length)\n      // didn't get any data, stop spinning.\n      break;\n  }\n  state.readingMore = false;\n}\n\n// abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function (n) {\n  errorOrDestroy(this, new ERR_METHOD_NOT_IMPLEMENTED('_read()'));\n};\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) process.nextTick(endFn);else src.once('end', endFn);\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n  function onend() {\n    debug('onend');\n    dest.end();\n  }\n\n  // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n  var cleanedUp = false;\n  function cleanup() {\n    debug('cleanup');\n    // cleanup event handlers once the pipe is broken\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n    cleanedUp = true;\n\n    // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n  src.on('data', ondata);\n  function ondata(chunk) {\n    debug('ondata');\n    var ret = dest.write(chunk);\n    debug('dest.write', ret);\n    if (ret === false) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', state.awaitDrain);\n        state.awaitDrain++;\n      }\n      src.pause();\n    }\n  }\n\n  // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) errorOrDestroy(dest, er);\n  }\n\n  // Make sure our error handler is attached before userland ones.\n  prependListener(dest, 'error', onerror);\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  }\n\n  // tell the dest that it's being piped to\n  dest.emit('pipe', src);\n\n  // start the flow if it hasn't been started already.\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n  return dest;\n};\nfunction pipeOnDrain(src) {\n  return function pipeOnDrainFunctionResult() {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = {\n    hasUnpiped: false\n  };\n\n  // if we're not piping anywhere, then do nothing.\n  if (state.pipesCount === 0) return this;\n\n  // just one destination.  most common case.\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n    if (!dest) dest = state.pipes;\n\n    // got a match.\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  }\n\n  // slow case. multiple pipe destinations.\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    for (var i = 0; i < len; i++) dests[i].emit('unpipe', this, {\n      hasUnpiped: false\n    });\n    return this;\n  }\n\n  // try to find the right one.\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n  dest.emit('unpipe', this, unpipeInfo);\n  return this;\n};\n\n// set up data events if they are asked for\n// Ensure readable listeners eventually get something\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n  var state = this._readableState;\n  if (ev === 'data') {\n    // update readableListening so that resume() may be a no-op\n    // a few lines down. This is needed to support once('readable').\n    state.readableListening = this.listenerCount('readable') > 0;\n\n    // Try start flowing on next tick if stream isn't explicitly paused\n    if (state.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.flowing = false;\n      state.emittedReadable = false;\n      debug('on readable', state.length, state.reading);\n      if (state.length) {\n        emitReadable(this);\n      } else if (!state.reading) {\n        process.nextTick(nReadingNextTick, this);\n      }\n    }\n  }\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\nReadable.prototype.removeListener = function (ev, fn) {\n  var res = Stream.prototype.removeListener.call(this, ev, fn);\n  if (ev === 'readable') {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this);\n  }\n  return res;\n};\nReadable.prototype.removeAllListeners = function (ev) {\n  var res = Stream.prototype.removeAllListeners.apply(this, arguments);\n  if (ev === 'readable' || ev === undefined) {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this);\n  }\n  return res;\n};\nfunction updateReadableListening(self) {\n  var state = self._readableState;\n  state.readableListening = self.listenerCount('readable') > 0;\n  if (state.resumeScheduled && !state.paused) {\n    // flowing needs to be set to true now, otherwise\n    // the upcoming resume will not flow.\n    state.flowing = true;\n\n    // crude way to check if we should resume\n  } else if (self.listenerCount('data') > 0) {\n    self.resume();\n  }\n}\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n}\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n  if (!state.flowing) {\n    debug('resume');\n    // we flow only if there is no one listening\n    // for readable, but we still have to call\n    // resume()\n    state.flowing = !state.readableListening;\n    resume(this, state);\n  }\n  state.paused = false;\n  return this;\n};\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    process.nextTick(resume_, stream, state);\n  }\n}\nfunction resume_(stream, state) {\n  debug('resume', state.reading);\n  if (!state.reading) {\n    stream.read(0);\n  }\n  state.resumeScheduled = false;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n  if (this._readableState.flowing !== false) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n  this._readableState.paused = true;\n  return this;\n};\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n  while (state.flowing && stream.read() !== null);\n}\n\n// wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n  var state = this._readableState;\n  var paused = false;\n  stream.on('end', function () {\n    debug('wrapped end');\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n    _this.push(null);\n  });\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk);\n\n    // don't skip over falsy values in objectMode\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n    var ret = _this.push(chunk);\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  });\n\n  // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function methodWrap(method) {\n        return function methodWrapReturnFunction() {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  }\n\n  // proxy certain important events.\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  }\n\n  // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n  this._read = function (n) {\n    debug('wrapped _read', n);\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n  return this;\n};\nif (typeof Symbol === 'function') {\n  Readable.prototype[Symbol.asyncIterator] = function () {\n    if (createReadableStreamAsyncIterator === undefined) {\n      createReadableStreamAsyncIterator = __webpack_require__(/*! ./internal/streams/async_iterator */ \"./node_modules/readable-stream/lib/internal/streams/async_iterator.js\");\n    }\n    return createReadableStreamAsyncIterator(this);\n  };\n}\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.highWaterMark;\n  }\n});\nObject.defineProperty(Readable.prototype, 'readableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState && this._readableState.buffer;\n  }\n});\nObject.defineProperty(Readable.prototype, 'readableFlowing', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.flowing;\n  },\n  set: function set(state) {\n    if (this._readableState) {\n      this._readableState.flowing = state;\n    }\n  }\n});\n\n// exposed for testing purposes only.\nReadable._fromList = fromList;\nObject.defineProperty(Readable.prototype, 'readableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.length;\n  }\n});\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.first();else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = state.buffer.consume(n, state.decoder);\n  }\n  return ret;\n}\nfunction endReadable(stream) {\n  var state = stream._readableState;\n  debug('endReadable', state.endEmitted);\n  if (!state.endEmitted) {\n    state.ended = true;\n    process.nextTick(endReadableNT, state, stream);\n  }\n}\nfunction endReadableNT(state, stream) {\n  debug('endReadableNT', state.endEmitted, state.length);\n\n  // Check that we didn't get one last unshift.\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n    if (state.autoDestroy) {\n      // In case of duplex streams we need a way to detect\n      // if the writable side is ready for autoDestroy as well\n      var wState = stream._writableState;\n      if (!wState || wState.autoDestroy && wState.finished) {\n        stream.destroy();\n      }\n    }\n  }\n}\nif (typeof Symbol === 'function') {\n  Readable.from = function (iterable, opts) {\n    if (from === undefined) {\n      from = __webpack_require__(/*! ./internal/streams/from */ \"./node_modules/readable-stream/lib/internal/streams/from-browser.js\");\n    }\n    return from(Readable, iterable, opts);\n  };\n}\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n  return -1;\n}\n\n//# sourceURL=webpack://dapp/./node_modules/readable-stream/lib/_stream_readable.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_transform.js":
/*!***************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_transform.js ***!
  \***************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n\n\nmodule.exports = Transform;\nvar _require$codes = (__webpack_require__(/*! ../errors */ \"./node_modules/readable-stream/errors-browser.js\").codes),\n  ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n  ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,\n  ERR_TRANSFORM_ALREADY_TRANSFORMING = _require$codes.ERR_TRANSFORM_ALREADY_TRANSFORMING,\n  ERR_TRANSFORM_WITH_LENGTH_0 = _require$codes.ERR_TRANSFORM_WITH_LENGTH_0;\nvar Duplex = __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n__webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits_browser.js\")(Transform, Duplex);\nfunction afterTransform(er, data) {\n  var ts = this._transformState;\n  ts.transforming = false;\n  var cb = ts.writecb;\n  if (cb === null) {\n    return this.emit('error', new ERR_MULTIPLE_CALLBACK());\n  }\n  ts.writechunk = null;\n  ts.writecb = null;\n  if (data != null)\n    // single equals check for both `null` and `undefined`\n    this.push(data);\n  cb(er);\n  var rs = this._readableState;\n  rs.reading = false;\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    this._read(rs.highWaterMark);\n  }\n}\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n  Duplex.call(this, options);\n  this._transformState = {\n    afterTransform: afterTransform.bind(this),\n    needTransform: false,\n    transforming: false,\n    writecb: null,\n    writechunk: null,\n    writeencoding: null\n  };\n\n  // start out asking for a readable event once data is transformed.\n  this._readableState.needReadable = true;\n\n  // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  }\n\n  // When the writable side finishes, then flush out anything remaining.\n  this.on('prefinish', prefinish);\n}\nfunction prefinish() {\n  var _this = this;\n  if (typeof this._flush === 'function' && !this._readableState.destroyed) {\n    this._flush(function (er, data) {\n      done(_this, er, data);\n    });\n  } else {\n    done(this, null, null);\n  }\n}\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n};\n\n// This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  cb(new ERR_METHOD_NOT_IMPLEMENTED('_transform()'));\n};\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n};\n\n// Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n  if (ts.writechunk !== null && !ts.transforming) {\n    ts.transforming = true;\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\nTransform.prototype._destroy = function (err, cb) {\n  Duplex.prototype._destroy.call(this, err, function (err2) {\n    cb(err2);\n  });\n};\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n  if (data != null)\n    // single equals check for both `null` and `undefined`\n    stream.push(data);\n\n  // TODO(BridgeAR): Write a test for these two error cases\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n  if (stream._writableState.length) throw new ERR_TRANSFORM_WITH_LENGTH_0();\n  if (stream._transformState.transforming) throw new ERR_TRANSFORM_ALREADY_TRANSFORMING();\n  return stream.push(null);\n}\n\n//# sourceURL=webpack://dapp/./node_modules/readable-stream/lib/_stream_transform.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_writable.js":
/*!**************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_writable.js ***!
  \**************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n\n\nmodule.exports = Writable;\n\n/* <replacement> */\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n}\n\n// It seems a linked list but it is not\n// there will be only 2 of these for each stream\nfunction CorkedRequest(state) {\n  var _this = this;\n  this.next = null;\n  this.entry = null;\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n/*<replacement>*/\nvar internalUtil = {\n  deprecate: __webpack_require__(/*! util-deprecate */ \"./node_modules/util-deprecate/browser.js\")\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = __webpack_require__(/*! ./internal/streams/stream */ \"./node_modules/readable-stream/lib/internal/streams/stream-browser.js\");\n/*</replacement>*/\n\nvar Buffer = (__webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\").Buffer);\nvar OurUint8Array = (typeof __webpack_require__.g !== 'undefined' ? __webpack_require__.g : typeof window !== 'undefined' ? window : typeof self !== 'undefined' ? self : {}).Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\nvar destroyImpl = __webpack_require__(/*! ./internal/streams/destroy */ \"./node_modules/readable-stream/lib/internal/streams/destroy.js\");\nvar _require = __webpack_require__(/*! ./internal/streams/state */ \"./node_modules/readable-stream/lib/internal/streams/state.js\"),\n  getHighWaterMark = _require.getHighWaterMark;\nvar _require$codes = (__webpack_require__(/*! ../errors */ \"./node_modules/readable-stream/errors-browser.js\").codes),\n  ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,\n  ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n  ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,\n  ERR_STREAM_CANNOT_PIPE = _require$codes.ERR_STREAM_CANNOT_PIPE,\n  ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED,\n  ERR_STREAM_NULL_VALUES = _require$codes.ERR_STREAM_NULL_VALUES,\n  ERR_STREAM_WRITE_AFTER_END = _require$codes.ERR_STREAM_WRITE_AFTER_END,\n  ERR_UNKNOWN_ENCODING = _require$codes.ERR_UNKNOWN_ENCODING;\nvar errorOrDestroy = destroyImpl.errorOrDestroy;\n__webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits_browser.js\")(Writable, Stream);\nfunction nop() {}\nfunction WritableState(options, stream, isDuplex) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream,\n  // e.g. options.readableObjectMode vs. options.writableObjectMode, etc.\n  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex;\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode;\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  this.highWaterMark = getHighWaterMark(this, options, 'writableHighWaterMark', isDuplex);\n\n  // if _final has been called\n  this.finalCalled = false;\n\n  // drain event flag.\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // when true all writes will be buffered until .uncork() call\n  this.corked = 0;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null;\n\n  // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n  this.pendingcb = 0;\n\n  // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n  this.prefinished = false;\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n\n  // Should close be emitted on destroy. Defaults to true.\n  this.emitClose = options.emitClose !== false;\n\n  // Should .destroy() be called after 'finish' (and potentially 'end')\n  this.autoDestroy = !!options.autoDestroy;\n\n  // count buffered requests\n  this.bufferedRequestCount = 0;\n\n  // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n  return out;\n};\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function writableStateBufferGetter() {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})();\n\n// Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\nvar realHasInstance;\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function value(object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function realHasInstance(object) {\n    return object instanceof this;\n  };\n}\nfunction Writable(options) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n\n  // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n\n  // Checking for a Stream.Duplex instance is faster here instead of inside\n  // the WritableState constructor, at least with V8 6.5\n  var isDuplex = this instanceof Duplex;\n  if (!isDuplex && !realHasInstance.call(Writable, this)) return new Writable(options);\n  this._writableState = new WritableState(options, this, isDuplex);\n\n  // legacy.\n  this.writable = true;\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n    if (typeof options.writev === 'function') this._writev = options.writev;\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function () {\n  errorOrDestroy(this, new ERR_STREAM_CANNOT_PIPE());\n};\nfunction writeAfterEnd(stream, cb) {\n  var er = new ERR_STREAM_WRITE_AFTER_END();\n  // TODO: defer error events consistently everywhere, not just the cb\n  errorOrDestroy(stream, er);\n  process.nextTick(cb, er);\n}\n\n// Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\nfunction validChunk(stream, state, chunk, cb) {\n  var er;\n  if (chunk === null) {\n    er = new ERR_STREAM_NULL_VALUES();\n  } else if (typeof chunk !== 'string' && !state.objectMode) {\n    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer'], chunk);\n  }\n  if (er) {\n    errorOrDestroy(stream, er);\n    process.nextTick(cb, er);\n    return false;\n  }\n  return true;\n}\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n  if (typeof cb !== 'function') cb = nop;\n  if (state.ending) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n  return ret;\n};\nWritable.prototype.cork = function () {\n  this._writableState.corked++;\n};\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n  if (state.corked) {\n    state.corked--;\n    if (!state.writing && !state.corked && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new ERR_UNKNOWN_ENCODING(encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\nObject.defineProperty(Writable.prototype, 'writableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState && this._writableState.getBuffer();\n  }\n});\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n  return chunk;\n}\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n  var len = state.objectMode ? 1 : chunk.length;\n  state.length += len;\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret) state.needDrain = true;\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n  return ret;\n}\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (state.destroyed) state.onwrite(new ERR_STREAM_DESTROYED('write'));else if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    process.nextTick(cb, er);\n    // this can emit finish, and it will always happen\n    // after error\n    process.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    errorOrDestroy(stream, er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    errorOrDestroy(stream, er);\n    // this can emit finish, but finish must\n    // always follow error\n    finishMaybe(stream, state);\n  }\n}\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n  if (typeof cb !== 'function') throw new ERR_MULTIPLE_CALLBACK();\n  onwriteStateUpdate(state);\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state) || stream.destroyed;\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n    if (sync) {\n      process.nextTick(afterWrite, stream, state, finished, cb);\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n    var count = 0;\n    var allBuffers = true;\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n    buffer.allBuffers = allBuffers;\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish);\n\n    // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--;\n      // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n      if (state.writing) {\n        break;\n      }\n    }\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new ERR_METHOD_NOT_IMPLEMENTED('_write()'));\n};\nWritable.prototype._writev = null;\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding);\n\n  // .end() fully uncorks\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  }\n\n  // ignore unnecessary end() calls.\n  if (!state.ending) endWritable(this, state, cb);\n  return this;\n};\nObject.defineProperty(Writable.prototype, 'writableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.length;\n  }\n});\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n    if (err) {\n      errorOrDestroy(stream, err);\n    }\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function' && !state.destroyed) {\n      state.pendingcb++;\n      state.finalCalled = true;\n      process.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n  if (need) {\n    prefinish(stream, state);\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n      if (state.autoDestroy) {\n        // In case of duplex streams we need a way to detect\n        // if the readable side is ready for autoDestroy as well\n        var rState = stream._readableState;\n        if (!rState || rState.autoDestroy && rState.endEmitted) {\n          stream.destroy();\n        }\n      }\n    }\n  }\n  return need;\n}\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished) process.nextTick(cb);else stream.once('finish', cb);\n  }\n  state.ended = true;\n  stream.writable = false;\n}\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  }\n\n  // reuse the free corkReq.\n  state.corkedRequestsFree.next = corkReq;\n}\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._writableState === undefined) {\n      return false;\n    }\n    return this._writableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._writableState.destroyed = value;\n  }\n});\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\nWritable.prototype._destroy = function (err, cb) {\n  cb(err);\n};\n\n//# sourceURL=webpack://dapp/./node_modules/readable-stream/lib/_stream_writable.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/async_iterator.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/async_iterator.js ***!
  \*****************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar _Object$setPrototypeO;\nfunction _defineProperty(obj, key, value) { key = _toPropertyKey(key); if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\nfunction _toPropertyKey(arg) { var key = _toPrimitive(arg, \"string\"); return typeof key === \"symbol\" ? key : String(key); }\nfunction _toPrimitive(input, hint) { if (typeof input !== \"object\" || input === null) return input; var prim = input[Symbol.toPrimitive]; if (prim !== undefined) { var res = prim.call(input, hint || \"default\"); if (typeof res !== \"object\") return res; throw new TypeError(\"@@toPrimitive must return a primitive value.\"); } return (hint === \"string\" ? String : Number)(input); }\nvar finished = __webpack_require__(/*! ./end-of-stream */ \"./node_modules/readable-stream/lib/internal/streams/end-of-stream.js\");\nvar kLastResolve = Symbol('lastResolve');\nvar kLastReject = Symbol('lastReject');\nvar kError = Symbol('error');\nvar kEnded = Symbol('ended');\nvar kLastPromise = Symbol('lastPromise');\nvar kHandlePromise = Symbol('handlePromise');\nvar kStream = Symbol('stream');\nfunction createIterResult(value, done) {\n  return {\n    value: value,\n    done: done\n  };\n}\nfunction readAndResolve(iter) {\n  var resolve = iter[kLastResolve];\n  if (resolve !== null) {\n    var data = iter[kStream].read();\n    // we defer if data is null\n    // we can be expecting either 'end' or\n    // 'error'\n    if (data !== null) {\n      iter[kLastPromise] = null;\n      iter[kLastResolve] = null;\n      iter[kLastReject] = null;\n      resolve(createIterResult(data, false));\n    }\n  }\n}\nfunction onReadable(iter) {\n  // we wait for the next tick, because it might\n  // emit an error with process.nextTick\n  process.nextTick(readAndResolve, iter);\n}\nfunction wrapForNext(lastPromise, iter) {\n  return function (resolve, reject) {\n    lastPromise.then(function () {\n      if (iter[kEnded]) {\n        resolve(createIterResult(undefined, true));\n        return;\n      }\n      iter[kHandlePromise](resolve, reject);\n    }, reject);\n  };\n}\nvar AsyncIteratorPrototype = Object.getPrototypeOf(function () {});\nvar ReadableStreamAsyncIteratorPrototype = Object.setPrototypeOf((_Object$setPrototypeO = {\n  get stream() {\n    return this[kStream];\n  },\n  next: function next() {\n    var _this = this;\n    // if we have detected an error in the meanwhile\n    // reject straight away\n    var error = this[kError];\n    if (error !== null) {\n      return Promise.reject(error);\n    }\n    if (this[kEnded]) {\n      return Promise.resolve(createIterResult(undefined, true));\n    }\n    if (this[kStream].destroyed) {\n      // We need to defer via nextTick because if .destroy(err) is\n      // called, the error will be emitted via nextTick, and\n      // we cannot guarantee that there is no error lingering around\n      // waiting to be emitted.\n      return new Promise(function (resolve, reject) {\n        process.nextTick(function () {\n          if (_this[kError]) {\n            reject(_this[kError]);\n          } else {\n            resolve(createIterResult(undefined, true));\n          }\n        });\n      });\n    }\n\n    // if we have multiple next() calls\n    // we will wait for the previous Promise to finish\n    // this logic is optimized to support for await loops,\n    // where next() is only called once at a time\n    var lastPromise = this[kLastPromise];\n    var promise;\n    if (lastPromise) {\n      promise = new Promise(wrapForNext(lastPromise, this));\n    } else {\n      // fast path needed to support multiple this.push()\n      // without triggering the next() queue\n      var data = this[kStream].read();\n      if (data !== null) {\n        return Promise.resolve(createIterResult(data, false));\n      }\n      promise = new Promise(this[kHandlePromise]);\n    }\n    this[kLastPromise] = promise;\n    return promise;\n  }\n}, _defineProperty(_Object$setPrototypeO, Symbol.asyncIterator, function () {\n  return this;\n}), _defineProperty(_Object$setPrototypeO, \"return\", function _return() {\n  var _this2 = this;\n  // destroy(err, cb) is a private API\n  // we can guarantee we have that here, because we control the\n  // Readable class this is attached to\n  return new Promise(function (resolve, reject) {\n    _this2[kStream].destroy(null, function (err) {\n      if (err) {\n        reject(err);\n        return;\n      }\n      resolve(createIterResult(undefined, true));\n    });\n  });\n}), _Object$setPrototypeO), AsyncIteratorPrototype);\nvar createReadableStreamAsyncIterator = function createReadableStreamAsyncIterator(stream) {\n  var _Object$create;\n  var iterator = Object.create(ReadableStreamAsyncIteratorPrototype, (_Object$create = {}, _defineProperty(_Object$create, kStream, {\n    value: stream,\n    writable: true\n  }), _defineProperty(_Object$create, kLastResolve, {\n    value: null,\n    writable: true\n  }), _defineProperty(_Object$create, kLastReject, {\n    value: null,\n    writable: true\n  }), _defineProperty(_Object$create, kError, {\n    value: null,\n    writable: true\n  }), _defineProperty(_Object$create, kEnded, {\n    value: stream._readableState.endEmitted,\n    writable: true\n  }), _defineProperty(_Object$create, kHandlePromise, {\n    value: function value(resolve, reject) {\n      var data = iterator[kStream].read();\n      if (data) {\n        iterator[kLastPromise] = null;\n        iterator[kLastResolve] = null;\n        iterator[kLastReject] = null;\n        resolve(createIterResult(data, false));\n      } else {\n        iterator[kLastResolve] = resolve;\n        iterator[kLastReject] = reject;\n      }\n    },\n    writable: true\n  }), _Object$create));\n  iterator[kLastPromise] = null;\n  finished(stream, function (err) {\n    if (err && err.code !== 'ERR_STREAM_PREMATURE_CLOSE') {\n      var reject = iterator[kLastReject];\n      // reject if we are waiting for data in the Promise\n      // returned by next() and store the error\n      if (reject !== null) {\n        iterator[kLastPromise] = null;\n        iterator[kLastResolve] = null;\n        iterator[kLastReject] = null;\n        reject(err);\n      }\n      iterator[kError] = err;\n      return;\n    }\n    var resolve = iterator[kLastResolve];\n    if (resolve !== null) {\n      iterator[kLastPromise] = null;\n      iterator[kLastResolve] = null;\n      iterator[kLastReject] = null;\n      resolve(createIterResult(undefined, true));\n    }\n    iterator[kEnded] = true;\n  });\n  stream.on('readable', onReadable.bind(null, iterator));\n  return iterator;\n};\nmodule.exports = createReadableStreamAsyncIterator;\n\n//# sourceURL=webpack://dapp/./node_modules/readable-stream/lib/internal/streams/async_iterator.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/buffer_list.js":
/*!**************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/buffer_list.js ***!
  \**************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nfunction ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); enumerableOnly && (symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; })), keys.push.apply(keys, symbols); } return keys; }\nfunction _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = null != arguments[i] ? arguments[i] : {}; i % 2 ? ownKeys(Object(source), !0).forEach(function (key) { _defineProperty(target, key, source[key]); }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)) : ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } return target; }\nfunction _defineProperty(obj, key, value) { key = _toPropertyKey(key); if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, _toPropertyKey(descriptor.key), descriptor); } }\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, \"prototype\", { writable: false }); return Constructor; }\nfunction _toPropertyKey(arg) { var key = _toPrimitive(arg, \"string\"); return typeof key === \"symbol\" ? key : String(key); }\nfunction _toPrimitive(input, hint) { if (typeof input !== \"object\" || input === null) return input; var prim = input[Symbol.toPrimitive]; if (prim !== undefined) { var res = prim.call(input, hint || \"default\"); if (typeof res !== \"object\") return res; throw new TypeError(\"@@toPrimitive must return a primitive value.\"); } return (hint === \"string\" ? String : Number)(input); }\nvar _require = __webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\"),\n  Buffer = _require.Buffer;\nvar _require2 = __webpack_require__(/*! util */ \"?ed1b\"),\n  inspect = _require2.inspect;\nvar custom = inspect && inspect.custom || 'inspect';\nfunction copyBuffer(src, target, offset) {\n  Buffer.prototype.copy.call(src, target, offset);\n}\nmodule.exports = /*#__PURE__*/function () {\n  function BufferList() {\n    _classCallCheck(this, BufferList);\n    this.head = null;\n    this.tail = null;\n    this.length = 0;\n  }\n  _createClass(BufferList, [{\n    key: \"push\",\n    value: function push(v) {\n      var entry = {\n        data: v,\n        next: null\n      };\n      if (this.length > 0) this.tail.next = entry;else this.head = entry;\n      this.tail = entry;\n      ++this.length;\n    }\n  }, {\n    key: \"unshift\",\n    value: function unshift(v) {\n      var entry = {\n        data: v,\n        next: this.head\n      };\n      if (this.length === 0) this.tail = entry;\n      this.head = entry;\n      ++this.length;\n    }\n  }, {\n    key: \"shift\",\n    value: function shift() {\n      if (this.length === 0) return;\n      var ret = this.head.data;\n      if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n      --this.length;\n      return ret;\n    }\n  }, {\n    key: \"clear\",\n    value: function clear() {\n      this.head = this.tail = null;\n      this.length = 0;\n    }\n  }, {\n    key: \"join\",\n    value: function join(s) {\n      if (this.length === 0) return '';\n      var p = this.head;\n      var ret = '' + p.data;\n      while (p = p.next) ret += s + p.data;\n      return ret;\n    }\n  }, {\n    key: \"concat\",\n    value: function concat(n) {\n      if (this.length === 0) return Buffer.alloc(0);\n      var ret = Buffer.allocUnsafe(n >>> 0);\n      var p = this.head;\n      var i = 0;\n      while (p) {\n        copyBuffer(p.data, ret, i);\n        i += p.data.length;\n        p = p.next;\n      }\n      return ret;\n    }\n\n    // Consumes a specified amount of bytes or characters from the buffered data.\n  }, {\n    key: \"consume\",\n    value: function consume(n, hasStrings) {\n      var ret;\n      if (n < this.head.data.length) {\n        // `slice` is the same for buffers and strings.\n        ret = this.head.data.slice(0, n);\n        this.head.data = this.head.data.slice(n);\n      } else if (n === this.head.data.length) {\n        // First chunk is a perfect match.\n        ret = this.shift();\n      } else {\n        // Result spans more than one buffer.\n        ret = hasStrings ? this._getString(n) : this._getBuffer(n);\n      }\n      return ret;\n    }\n  }, {\n    key: \"first\",\n    value: function first() {\n      return this.head.data;\n    }\n\n    // Consumes a specified amount of characters from the buffered data.\n  }, {\n    key: \"_getString\",\n    value: function _getString(n) {\n      var p = this.head;\n      var c = 1;\n      var ret = p.data;\n      n -= ret.length;\n      while (p = p.next) {\n        var str = p.data;\n        var nb = n > str.length ? str.length : n;\n        if (nb === str.length) ret += str;else ret += str.slice(0, n);\n        n -= nb;\n        if (n === 0) {\n          if (nb === str.length) {\n            ++c;\n            if (p.next) this.head = p.next;else this.head = this.tail = null;\n          } else {\n            this.head = p;\n            p.data = str.slice(nb);\n          }\n          break;\n        }\n        ++c;\n      }\n      this.length -= c;\n      return ret;\n    }\n\n    // Consumes a specified amount of bytes from the buffered data.\n  }, {\n    key: \"_getBuffer\",\n    value: function _getBuffer(n) {\n      var ret = Buffer.allocUnsafe(n);\n      var p = this.head;\n      var c = 1;\n      p.data.copy(ret);\n      n -= p.data.length;\n      while (p = p.next) {\n        var buf = p.data;\n        var nb = n > buf.length ? buf.length : n;\n        buf.copy(ret, ret.length - n, 0, nb);\n        n -= nb;\n        if (n === 0) {\n          if (nb === buf.length) {\n            ++c;\n            if (p.next) this.head = p.next;else this.head = this.tail = null;\n          } else {\n            this.head = p;\n            p.data = buf.slice(nb);\n          }\n          break;\n        }\n        ++c;\n      }\n      this.length -= c;\n      return ret;\n    }\n\n    // Make sure the linked list only shows the minimal necessary information.\n  }, {\n    key: custom,\n    value: function value(_, options) {\n      return inspect(this, _objectSpread(_objectSpread({}, options), {}, {\n        // Only inspect one level.\n        depth: 0,\n        // It should not recurse.\n        customInspect: false\n      }));\n    }\n  }]);\n  return BufferList;\n}();\n\n//# sourceURL=webpack://dapp/./node_modules/readable-stream/lib/internal/streams/buffer_list.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/destroy.js":
/*!**********************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/destroy.js ***!
  \**********************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n// undocumented cb() API, needed for core, not for public API\nfunction destroy(err, cb) {\n  var _this = this;\n  var readableDestroyed = this._readableState && this._readableState.destroyed;\n  var writableDestroyed = this._writableState && this._writableState.destroyed;\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err) {\n      if (!this._writableState) {\n        process.nextTick(emitErrorNT, this, err);\n      } else if (!this._writableState.errorEmitted) {\n        this._writableState.errorEmitted = true;\n        process.nextTick(emitErrorNT, this, err);\n      }\n    }\n    return this;\n  }\n\n  // we set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  }\n\n  // if this is a duplex stream mark the writable part as destroyed as well\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n  this._destroy(err || null, function (err) {\n    if (!cb && err) {\n      if (!_this._writableState) {\n        process.nextTick(emitErrorAndCloseNT, _this, err);\n      } else if (!_this._writableState.errorEmitted) {\n        _this._writableState.errorEmitted = true;\n        process.nextTick(emitErrorAndCloseNT, _this, err);\n      } else {\n        process.nextTick(emitCloseNT, _this);\n      }\n    } else if (cb) {\n      process.nextTick(emitCloseNT, _this);\n      cb(err);\n    } else {\n      process.nextTick(emitCloseNT, _this);\n    }\n  });\n  return this;\n}\nfunction emitErrorAndCloseNT(self, err) {\n  emitErrorNT(self, err);\n  emitCloseNT(self);\n}\nfunction emitCloseNT(self) {\n  if (self._writableState && !self._writableState.emitClose) return;\n  if (self._readableState && !self._readableState.emitClose) return;\n  self.emit('close');\n}\nfunction undestroy() {\n  if (this._readableState) {\n    this._readableState.destroyed = false;\n    this._readableState.reading = false;\n    this._readableState.ended = false;\n    this._readableState.endEmitted = false;\n  }\n  if (this._writableState) {\n    this._writableState.destroyed = false;\n    this._writableState.ended = false;\n    this._writableState.ending = false;\n    this._writableState.finalCalled = false;\n    this._writableState.prefinished = false;\n    this._writableState.finished = false;\n    this._writableState.errorEmitted = false;\n  }\n}\nfunction emitErrorNT(self, err) {\n  self.emit('error', err);\n}\nfunction errorOrDestroy(stream, err) {\n  // We have tests that rely on errors being emitted\n  // in the same tick, so changing this is semver major.\n  // For now when you opt-in to autoDestroy we allow\n  // the error to be emitted nextTick. In a future\n  // semver major update we should change the default to this.\n\n  var rState = stream._readableState;\n  var wState = stream._writableState;\n  if (rState && rState.autoDestroy || wState && wState.autoDestroy) stream.destroy(err);else stream.emit('error', err);\n}\nmodule.exports = {\n  destroy: destroy,\n  undestroy: undestroy,\n  errorOrDestroy: errorOrDestroy\n};\n\n//# sourceURL=webpack://dapp/./node_modules/readable-stream/lib/internal/streams/destroy.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/end-of-stream.js":
/*!****************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/end-of-stream.js ***!
  \****************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Ported from https://github.com/mafintosh/end-of-stream with\n// permission from the author, Mathias Buus (@mafintosh).\n\n\n\nvar ERR_STREAM_PREMATURE_CLOSE = (__webpack_require__(/*! ../../../errors */ \"./node_modules/readable-stream/errors-browser.js\").codes.ERR_STREAM_PREMATURE_CLOSE);\nfunction once(callback) {\n  var called = false;\n  return function () {\n    if (called) return;\n    called = true;\n    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n      args[_key] = arguments[_key];\n    }\n    callback.apply(this, args);\n  };\n}\nfunction noop() {}\nfunction isRequest(stream) {\n  return stream.setHeader && typeof stream.abort === 'function';\n}\nfunction eos(stream, opts, callback) {\n  if (typeof opts === 'function') return eos(stream, null, opts);\n  if (!opts) opts = {};\n  callback = once(callback || noop);\n  var readable = opts.readable || opts.readable !== false && stream.readable;\n  var writable = opts.writable || opts.writable !== false && stream.writable;\n  var onlegacyfinish = function onlegacyfinish() {\n    if (!stream.writable) onfinish();\n  };\n  var writableEnded = stream._writableState && stream._writableState.finished;\n  var onfinish = function onfinish() {\n    writable = false;\n    writableEnded = true;\n    if (!readable) callback.call(stream);\n  };\n  var readableEnded = stream._readableState && stream._readableState.endEmitted;\n  var onend = function onend() {\n    readable = false;\n    readableEnded = true;\n    if (!writable) callback.call(stream);\n  };\n  var onerror = function onerror(err) {\n    callback.call(stream, err);\n  };\n  var onclose = function onclose() {\n    var err;\n    if (readable && !readableEnded) {\n      if (!stream._readableState || !stream._readableState.ended) err = new ERR_STREAM_PREMATURE_CLOSE();\n      return callback.call(stream, err);\n    }\n    if (writable && !writableEnded) {\n      if (!stream._writableState || !stream._writableState.ended) err = new ERR_STREAM_PREMATURE_CLOSE();\n      return callback.call(stream, err);\n    }\n  };\n  var onrequest = function onrequest() {\n    stream.req.on('finish', onfinish);\n  };\n  if (isRequest(stream)) {\n    stream.on('complete', onfinish);\n    stream.on('abort', onclose);\n    if (stream.req) onrequest();else stream.on('request', onrequest);\n  } else if (writable && !stream._writableState) {\n    // legacy streams\n    stream.on('end', onlegacyfinish);\n    stream.on('close', onlegacyfinish);\n  }\n  stream.on('end', onend);\n  stream.on('finish', onfinish);\n  if (opts.error !== false) stream.on('error', onerror);\n  stream.on('close', onclose);\n  return function () {\n    stream.removeListener('complete', onfinish);\n    stream.removeListener('abort', onclose);\n    stream.removeListener('request', onrequest);\n    if (stream.req) stream.req.removeListener('finish', onfinish);\n    stream.removeListener('end', onlegacyfinish);\n    stream.removeListener('close', onlegacyfinish);\n    stream.removeListener('finish', onfinish);\n    stream.removeListener('end', onend);\n    stream.removeListener('error', onerror);\n    stream.removeListener('close', onclose);\n  };\n}\nmodule.exports = eos;\n\n//# sourceURL=webpack://dapp/./node_modules/readable-stream/lib/internal/streams/end-of-stream.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/from-browser.js":
/*!***************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/from-browser.js ***!
  \***************************************************************************/
/***/ ((module) => {

eval("module.exports = function () {\n  throw new Error('Readable.from is not available in the browser')\n};\n\n\n//# sourceURL=webpack://dapp/./node_modules/readable-stream/lib/internal/streams/from-browser.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/pipeline.js":
/*!***********************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/pipeline.js ***!
  \***********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Ported from https://github.com/mafintosh/pump with\n// permission from the author, Mathias Buus (@mafintosh).\n\n\n\nvar eos;\nfunction once(callback) {\n  var called = false;\n  return function () {\n    if (called) return;\n    called = true;\n    callback.apply(void 0, arguments);\n  };\n}\nvar _require$codes = (__webpack_require__(/*! ../../../errors */ \"./node_modules/readable-stream/errors-browser.js\").codes),\n  ERR_MISSING_ARGS = _require$codes.ERR_MISSING_ARGS,\n  ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED;\nfunction noop(err) {\n  // Rethrow the error if it exists to avoid swallowing it\n  if (err) throw err;\n}\nfunction isRequest(stream) {\n  return stream.setHeader && typeof stream.abort === 'function';\n}\nfunction destroyer(stream, reading, writing, callback) {\n  callback = once(callback);\n  var closed = false;\n  stream.on('close', function () {\n    closed = true;\n  });\n  if (eos === undefined) eos = __webpack_require__(/*! ./end-of-stream */ \"./node_modules/readable-stream/lib/internal/streams/end-of-stream.js\");\n  eos(stream, {\n    readable: reading,\n    writable: writing\n  }, function (err) {\n    if (err) return callback(err);\n    closed = true;\n    callback();\n  });\n  var destroyed = false;\n  return function (err) {\n    if (closed) return;\n    if (destroyed) return;\n    destroyed = true;\n\n    // request.destroy just do .end - .abort is what we want\n    if (isRequest(stream)) return stream.abort();\n    if (typeof stream.destroy === 'function') return stream.destroy();\n    callback(err || new ERR_STREAM_DESTROYED('pipe'));\n  };\n}\nfunction call(fn) {\n  fn();\n}\nfunction pipe(from, to) {\n  return from.pipe(to);\n}\nfunction popCallback(streams) {\n  if (!streams.length) return noop;\n  if (typeof streams[streams.length - 1] !== 'function') return noop;\n  return streams.pop();\n}\nfunction pipeline() {\n  for (var _len = arguments.length, streams = new Array(_len), _key = 0; _key < _len; _key++) {\n    streams[_key] = arguments[_key];\n  }\n  var callback = popCallback(streams);\n  if (Array.isArray(streams[0])) streams = streams[0];\n  if (streams.length < 2) {\n    throw new ERR_MISSING_ARGS('streams');\n  }\n  var error;\n  var destroys = streams.map(function (stream, i) {\n    var reading = i < streams.length - 1;\n    var writing = i > 0;\n    return destroyer(stream, reading, writing, function (err) {\n      if (!error) error = err;\n      if (err) destroys.forEach(call);\n      if (reading) return;\n      destroys.forEach(call);\n      callback(error);\n    });\n  });\n  return streams.reduce(pipe);\n}\nmodule.exports = pipeline;\n\n//# sourceURL=webpack://dapp/./node_modules/readable-stream/lib/internal/streams/pipeline.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/state.js":
/*!********************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/state.js ***!
  \********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar ERR_INVALID_OPT_VALUE = (__webpack_require__(/*! ../../../errors */ \"./node_modules/readable-stream/errors-browser.js\").codes.ERR_INVALID_OPT_VALUE);\nfunction highWaterMarkFrom(options, isDuplex, duplexKey) {\n  return options.highWaterMark != null ? options.highWaterMark : isDuplex ? options[duplexKey] : null;\n}\nfunction getHighWaterMark(state, options, duplexKey, isDuplex) {\n  var hwm = highWaterMarkFrom(options, isDuplex, duplexKey);\n  if (hwm != null) {\n    if (!(isFinite(hwm) && Math.floor(hwm) === hwm) || hwm < 0) {\n      var name = isDuplex ? duplexKey : 'highWaterMark';\n      throw new ERR_INVALID_OPT_VALUE(name, hwm);\n    }\n    return Math.floor(hwm);\n  }\n\n  // Default value\n  return state.objectMode ? 16 : 16 * 1024;\n}\nmodule.exports = {\n  getHighWaterMark: getHighWaterMark\n};\n\n//# sourceURL=webpack://dapp/./node_modules/readable-stream/lib/internal/streams/state.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/stream-browser.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/stream-browser.js ***!
  \*****************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("module.exports = __webpack_require__(/*! events */ \"./node_modules/events/events.js\").EventEmitter;\n\n\n//# sourceURL=webpack://dapp/./node_modules/readable-stream/lib/internal/streams/stream-browser.js?");

/***/ }),

/***/ "./node_modules/stream-browserify/index.js":
/*!*************************************************!*\
  !*** ./node_modules/stream-browserify/index.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nmodule.exports = Stream;\n\nvar EE = (__webpack_require__(/*! events */ \"./node_modules/events/events.js\").EventEmitter);\nvar inherits = __webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits_browser.js\");\n\ninherits(Stream, EE);\nStream.Readable = __webpack_require__(/*! readable-stream/lib/_stream_readable.js */ \"./node_modules/readable-stream/lib/_stream_readable.js\");\nStream.Writable = __webpack_require__(/*! readable-stream/lib/_stream_writable.js */ \"./node_modules/readable-stream/lib/_stream_writable.js\");\nStream.Duplex = __webpack_require__(/*! readable-stream/lib/_stream_duplex.js */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\nStream.Transform = __webpack_require__(/*! readable-stream/lib/_stream_transform.js */ \"./node_modules/readable-stream/lib/_stream_transform.js\");\nStream.PassThrough = __webpack_require__(/*! readable-stream/lib/_stream_passthrough.js */ \"./node_modules/readable-stream/lib/_stream_passthrough.js\");\nStream.finished = __webpack_require__(/*! readable-stream/lib/internal/streams/end-of-stream.js */ \"./node_modules/readable-stream/lib/internal/streams/end-of-stream.js\")\nStream.pipeline = __webpack_require__(/*! readable-stream/lib/internal/streams/pipeline.js */ \"./node_modules/readable-stream/lib/internal/streams/pipeline.js\")\n\n// Backwards-compat with node 0.4.x\nStream.Stream = Stream;\n\n\n\n// old-style streams.  Note that the pipe method (the only relevant\n// part of this class) is overridden in the Readable class.\n\nfunction Stream() {\n  EE.call(this);\n}\n\nStream.prototype.pipe = function(dest, options) {\n  var source = this;\n\n  function ondata(chunk) {\n    if (dest.writable) {\n      if (false === dest.write(chunk) && source.pause) {\n        source.pause();\n      }\n    }\n  }\n\n  source.on('data', ondata);\n\n  function ondrain() {\n    if (source.readable && source.resume) {\n      source.resume();\n    }\n  }\n\n  dest.on('drain', ondrain);\n\n  // If the 'end' option is not supplied, dest.end() will be called when\n  // source gets the 'end' or 'close' events.  Only dest.end() once.\n  if (!dest._isStdio && (!options || options.end !== false)) {\n    source.on('end', onend);\n    source.on('close', onclose);\n  }\n\n  var didOnEnd = false;\n  function onend() {\n    if (didOnEnd) return;\n    didOnEnd = true;\n\n    dest.end();\n  }\n\n\n  function onclose() {\n    if (didOnEnd) return;\n    didOnEnd = true;\n\n    if (typeof dest.destroy === 'function') dest.destroy();\n  }\n\n  // don't leave dangling pipes when there are errors.\n  function onerror(er) {\n    cleanup();\n    if (EE.listenerCount(this, 'error') === 0) {\n      throw er; // Unhandled stream error in pipe.\n    }\n  }\n\n  source.on('error', onerror);\n  dest.on('error', onerror);\n\n  // remove all the event listeners that were added.\n  function cleanup() {\n    source.removeListener('data', ondata);\n    dest.removeListener('drain', ondrain);\n\n    source.removeListener('end', onend);\n    source.removeListener('close', onclose);\n\n    source.removeListener('error', onerror);\n    dest.removeListener('error', onerror);\n\n    source.removeListener('end', cleanup);\n    source.removeListener('close', cleanup);\n\n    dest.removeListener('close', cleanup);\n  }\n\n  source.on('end', cleanup);\n  source.on('close', cleanup);\n\n  dest.on('close', cleanup);\n\n  dest.emit('pipe', source);\n\n  // Allow for unix-like usage: A.pipe(B).pipe(C)\n  return dest;\n};\n\n\n//# sourceURL=webpack://dapp/./node_modules/stream-browserify/index.js?");

/***/ }),

/***/ "./node_modules/string_decoder/lib/string_decoder.js":
/*!***********************************************************!*\
  !*** ./node_modules/string_decoder/lib/string_decoder.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n/*<replacement>*/\n\nvar Buffer = (__webpack_require__(/*! safe-buffer */ \"./node_modules/safe-buffer/index.js\").Buffer);\n/*</replacement>*/\n\nvar isEncoding = Buffer.isEncoding || function (encoding) {\n  encoding = '' + encoding;\n  switch (encoding && encoding.toLowerCase()) {\n    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':\n      return true;\n    default:\n      return false;\n  }\n};\n\nfunction _normalizeEncoding(enc) {\n  if (!enc) return 'utf8';\n  var retried;\n  while (true) {\n    switch (enc) {\n      case 'utf8':\n      case 'utf-8':\n        return 'utf8';\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return 'utf16le';\n      case 'latin1':\n      case 'binary':\n        return 'latin1';\n      case 'base64':\n      case 'ascii':\n      case 'hex':\n        return enc;\n      default:\n        if (retried) return; // undefined\n        enc = ('' + enc).toLowerCase();\n        retried = true;\n    }\n  }\n};\n\n// Do not cache `Buffer.isEncoding` when checking encoding names as some\n// modules monkey-patch it to support additional encodings\nfunction normalizeEncoding(enc) {\n  var nenc = _normalizeEncoding(enc);\n  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);\n  return nenc || enc;\n}\n\n// StringDecoder provides an interface for efficiently splitting a series of\n// buffers into a series of JS strings without breaking apart multi-byte\n// characters.\nexports.StringDecoder = StringDecoder;\nfunction StringDecoder(encoding) {\n  this.encoding = normalizeEncoding(encoding);\n  var nb;\n  switch (this.encoding) {\n    case 'utf16le':\n      this.text = utf16Text;\n      this.end = utf16End;\n      nb = 4;\n      break;\n    case 'utf8':\n      this.fillLast = utf8FillLast;\n      nb = 4;\n      break;\n    case 'base64':\n      this.text = base64Text;\n      this.end = base64End;\n      nb = 3;\n      break;\n    default:\n      this.write = simpleWrite;\n      this.end = simpleEnd;\n      return;\n  }\n  this.lastNeed = 0;\n  this.lastTotal = 0;\n  this.lastChar = Buffer.allocUnsafe(nb);\n}\n\nStringDecoder.prototype.write = function (buf) {\n  if (buf.length === 0) return '';\n  var r;\n  var i;\n  if (this.lastNeed) {\n    r = this.fillLast(buf);\n    if (r === undefined) return '';\n    i = this.lastNeed;\n    this.lastNeed = 0;\n  } else {\n    i = 0;\n  }\n  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);\n  return r || '';\n};\n\nStringDecoder.prototype.end = utf8End;\n\n// Returns only complete characters in a Buffer\nStringDecoder.prototype.text = utf8Text;\n\n// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer\nStringDecoder.prototype.fillLast = function (buf) {\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);\n  this.lastNeed -= buf.length;\n};\n\n// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a\n// continuation byte. If an invalid byte is detected, -2 is returned.\nfunction utf8CheckByte(byte) {\n  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;\n  return byte >> 6 === 0x02 ? -1 : -2;\n}\n\n// Checks at most 3 bytes at the end of a Buffer in order to detect an\n// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)\n// needed to complete the UTF-8 character (if applicable) are returned.\nfunction utf8CheckIncomplete(self, buf, i) {\n  var j = buf.length - 1;\n  if (j < i) return 0;\n  var nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 1;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 2;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) {\n      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;\n    }\n    return nb;\n  }\n  return 0;\n}\n\n// Validates as many continuation bytes for a multi-byte UTF-8 character as\n// needed or are available. If we see a non-continuation byte where we expect\n// one, we \"replace\" the validated continuation bytes we've seen so far with\n// a single UTF-8 replacement character ('\\ufffd'), to match v8's UTF-8 decoding\n// behavior. The continuation byte check is included three times in the case\n// where all of the continuation bytes for a character exist in the same buffer.\n// It is also done this way as a slight performance increase instead of using a\n// loop.\nfunction utf8CheckExtraBytes(self, buf, p) {\n  if ((buf[0] & 0xC0) !== 0x80) {\n    self.lastNeed = 0;\n    return '\\ufffd';\n  }\n  if (self.lastNeed > 1 && buf.length > 1) {\n    if ((buf[1] & 0xC0) !== 0x80) {\n      self.lastNeed = 1;\n      return '\\ufffd';\n    }\n    if (self.lastNeed > 2 && buf.length > 2) {\n      if ((buf[2] & 0xC0) !== 0x80) {\n        self.lastNeed = 2;\n        return '\\ufffd';\n      }\n    }\n  }\n}\n\n// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.\nfunction utf8FillLast(buf) {\n  var p = this.lastTotal - this.lastNeed;\n  var r = utf8CheckExtraBytes(this, buf, p);\n  if (r !== undefined) return r;\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, p, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, p, 0, buf.length);\n  this.lastNeed -= buf.length;\n}\n\n// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a\n// partial character, the character's bytes are buffered until the required\n// number of bytes are available.\nfunction utf8Text(buf, i) {\n  var total = utf8CheckIncomplete(this, buf, i);\n  if (!this.lastNeed) return buf.toString('utf8', i);\n  this.lastTotal = total;\n  var end = buf.length - (total - this.lastNeed);\n  buf.copy(this.lastChar, 0, end);\n  return buf.toString('utf8', i, end);\n}\n\n// For UTF-8, a replacement character is added when ending on a partial\n// character.\nfunction utf8End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + '\\ufffd';\n  return r;\n}\n\n// UTF-16LE typically needs two bytes per character, but even if we have an even\n// number of bytes available, we need to check if we end on a leading/high\n// surrogate. In that case, we need to wait for the next two bytes in order to\n// decode the last character properly.\nfunction utf16Text(buf, i) {\n  if ((buf.length - i) % 2 === 0) {\n    var r = buf.toString('utf16le', i);\n    if (r) {\n      var c = r.charCodeAt(r.length - 1);\n      if (c >= 0xD800 && c <= 0xDBFF) {\n        this.lastNeed = 2;\n        this.lastTotal = 4;\n        this.lastChar[0] = buf[buf.length - 2];\n        this.lastChar[1] = buf[buf.length - 1];\n        return r.slice(0, -1);\n      }\n    }\n    return r;\n  }\n  this.lastNeed = 1;\n  this.lastTotal = 2;\n  this.lastChar[0] = buf[buf.length - 1];\n  return buf.toString('utf16le', i, buf.length - 1);\n}\n\n// For UTF-16LE we do not explicitly append special replacement characters if we\n// end on a partial character, we simply let v8 handle that.\nfunction utf16End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) {\n    var end = this.lastTotal - this.lastNeed;\n    return r + this.lastChar.toString('utf16le', 0, end);\n  }\n  return r;\n}\n\nfunction base64Text(buf, i) {\n  var n = (buf.length - i) % 3;\n  if (n === 0) return buf.toString('base64', i);\n  this.lastNeed = 3 - n;\n  this.lastTotal = 3;\n  if (n === 1) {\n    this.lastChar[0] = buf[buf.length - 1];\n  } else {\n    this.lastChar[0] = buf[buf.length - 2];\n    this.lastChar[1] = buf[buf.length - 1];\n  }\n  return buf.toString('base64', i, buf.length - n);\n}\n\nfunction base64End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);\n  return r;\n}\n\n// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)\nfunction simpleWrite(buf) {\n  return buf.toString(this.encoding);\n}\n\nfunction simpleEnd(buf) {\n  return buf && buf.length ? this.write(buf) : '';\n}\n\n//# sourceURL=webpack://dapp/./node_modules/string_decoder/lib/string_decoder.js?");

/***/ }),

/***/ "./node_modules/util-deprecate/browser.js":
/*!************************************************!*\
  !*** ./node_modules/util-deprecate/browser.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("\n/**\n * Module exports.\n */\n\nmodule.exports = deprecate;\n\n/**\n * Mark that a method should not be used.\n * Returns a modified function which warns once by default.\n *\n * If `localStorage.noDeprecation = true` is set, then it is a no-op.\n *\n * If `localStorage.throwDeprecation = true` is set, then deprecated functions\n * will throw an Error when invoked.\n *\n * If `localStorage.traceDeprecation = true` is set, then deprecated functions\n * will invoke `console.trace()` instead of `console.error()`.\n *\n * @param {Function} fn - the function to deprecate\n * @param {String} msg - the string to print to the console when `fn` is invoked\n * @returns {Function} a new \"deprecated\" version of `fn`\n * @api public\n */\n\nfunction deprecate (fn, msg) {\n  if (config('noDeprecation')) {\n    return fn;\n  }\n\n  var warned = false;\n  function deprecated() {\n    if (!warned) {\n      if (config('throwDeprecation')) {\n        throw new Error(msg);\n      } else if (config('traceDeprecation')) {\n        console.trace(msg);\n      } else {\n        console.warn(msg);\n      }\n      warned = true;\n    }\n    return fn.apply(this, arguments);\n  }\n\n  return deprecated;\n}\n\n/**\n * Checks `localStorage` for boolean values for the given `name`.\n *\n * @param {String} name\n * @returns {Boolean}\n * @api private\n */\n\nfunction config (name) {\n  // accessing global.localStorage can trigger a DOMException in sandboxed iframes\n  try {\n    if (!__webpack_require__.g.localStorage) return false;\n  } catch (_) {\n    return false;\n  }\n  var val = __webpack_require__.g.localStorage[name];\n  if (null == val) return false;\n  return String(val).toLowerCase() === 'true';\n}\n\n\n//# sourceURL=webpack://dapp/./node_modules/util-deprecate/browser.js?");

/***/ })

}]);